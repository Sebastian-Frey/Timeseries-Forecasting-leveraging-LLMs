{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5rbF17RsRX-"
      },
      "source": [
        "# Install and setup\n",
        "\n",
        "This notebook implements spatio-temporal GNN models for CPC forecasting with proper configuration management, data pipelines, and training utilities.\n",
        "\n",
        "**Version 5 Updates:**\n",
        "- Added RMSE and SMAPE metrics (keeping MSE and MAE for total of 4 metrics)\n",
        "- CSV export with config column: horizon, model_id, exog_mode, config, mse, mae, rmse, smape\n",
        "- Tensor saving for error analysis: predictions, targets, inputs, errors (.pt format)\n",
        "- Dual save locations (Drive + local runtime) with error-robust handling\n",
        "- All v4 fixes retained (DCRNN self-loops, no detach, GPU memory cleanup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKwzwGqUsRX_",
        "outputId": "e99ac8cf-ad1e-4bf5-a6ea-7adacdb1c551"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch==2.4.0+cu121 in /usr/local/lib/python3.12/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision==0.19.0+cu121 in /usr/local/lib/python3.12/dist-packages (0.19.0+cu121)\n",
            "Requirement already satisfied: torchaudio==2.4.0+cu121 in /usr/local/lib/python3.12/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0+cu121) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0+cu121) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0+cu121) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0+cu121) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0+cu121) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0+cu121) (2025.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0+cu121) (75.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0+cu121) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0+cu121) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0+cu121) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0+cu121) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0+cu121) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0+cu121) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0+cu121) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0+cu121) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0+cu121) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0+cu121) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0+cu121) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0+cu121) (3.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.19.0+cu121) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.19.0+cu121) (11.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0+cu121) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.4.0+cu121) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.4.0+cu121) (1.3.0)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.12/dist-packages (2.1.2+pt24cu121)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.12/dist-packages (0.6.18+pt24cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.12/dist-packages (1.6.3+pt24cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-cluster) (1.16.3)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-cluster) (2.0.2)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.12/dist-packages (1.2.2+pt24cu121)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.11.12)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Collecting torch-geometric-temporal\n",
            "  Using cached torch_geometric_temporal-0.56.2-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric-temporal) (4.4.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from torch-geometric-temporal) (2.4.0+cu121)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.12/dist-packages (from torch-geometric-temporal) (3.0.12)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.12/dist-packages (from torch-geometric-temporal) (0.6.18+pt24cu121)\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.12/dist-packages (from torch-geometric-temporal) (2.1.2+pt24cu121)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (from torch-geometric-temporal) (2.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric-temporal) (2.0.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch-geometric-temporal) (3.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->torch-geometric-temporal) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch->torch-geometric-temporal) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch->torch-geometric-temporal) (1.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->torch-geometric-temporal) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->torch-geometric-temporal) (2025.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->torch-geometric-temporal) (75.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->torch-geometric-temporal) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->torch-geometric-temporal) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->torch-geometric-temporal) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch->torch-geometric-temporal) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch->torch-geometric-temporal) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch->torch-geometric-temporal) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch->torch-geometric-temporal) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch->torch-geometric-temporal) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch->torch-geometric-temporal) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch->torch-geometric-temporal) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->torch-geometric-temporal) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.12/dist-packages (from torch->torch-geometric-temporal) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torch-geometric-temporal) (12.6.85)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric->torch-geometric-temporal) (3.13.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric->torch-geometric-temporal) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric->torch-geometric-temporal) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric->torch-geometric-temporal) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric->torch-geometric-temporal) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric->torch-geometric-temporal) (3.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse->torch-geometric-temporal) (1.16.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->torch-geometric-temporal) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric->torch-geometric-temporal) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric->torch-geometric-temporal) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric->torch-geometric-temporal) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric->torch-geometric-temporal) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch->torch-geometric-temporal) (1.3.0)\n",
            "Using cached torch_geometric_temporal-0.56.2-py3-none-any.whl (102 kB)\n",
            "Installing collected packages: torch-geometric-temporal\n",
            "Successfully installed torch-geometric-temporal-0.56.2\n",
            "Collecting torch-spatiotemporal\n",
            "  Downloading torch_spatiotemporal-0.9.5-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from torch-spatiotemporal) (0.8.1)\n",
            "Requirement already satisfied: numpy>1.20.3 in /usr/local/lib/python3.12/dist-packages (from torch-spatiotemporal) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.12/dist-packages (from torch-spatiotemporal) (2.2.2)\n",
            "Collecting pytorch-lightning>=1.8 (from torch-spatiotemporal)\n",
            "  Downloading pytorch_lightning-2.6.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from torch-spatiotemporal) (6.0.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from torch-spatiotemporal) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-spatiotemporal) (1.16.3)\n",
            "Requirement already satisfied: tables in /usr/local/lib/python3.12/dist-packages (from torch-spatiotemporal) (3.10.2)\n",
            "Collecting torchmetrics>=0.7 (from torch-spatiotemporal)\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-spatiotemporal) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4->torch-spatiotemporal) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4->torch-spatiotemporal) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4->torch-spatiotemporal) (2025.2)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning>=1.8->torch-spatiotemporal) (2.4.0+cu121)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.8->torch-spatiotemporal) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning>=1.8->torch-spatiotemporal) (25.0)\n",
            "Requirement already satisfied: typing-extensions>4.5.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning>=1.8->torch-spatiotemporal) (4.15.0)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning>=1.8->torch-spatiotemporal)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->torch-spatiotemporal) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->torch-spatiotemporal) (3.6.0)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.12/dist-packages (from tables->torch-spatiotemporal) (2.14.1)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from tables->torch-spatiotemporal) (9.0.0)\n",
            "Requirement already satisfied: blosc2>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from tables->torch-spatiotemporal) (3.11.1)\n",
            "Requirement already satisfied: ndindex in /usr/local/lib/python3.12/dist-packages (from blosc2>=2.3.0->tables->torch-spatiotemporal) (1.10.1)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.12/dist-packages (from blosc2>=2.3.0->tables->torch-spatiotemporal) (1.1.2)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from blosc2>=2.3.0->tables->torch-spatiotemporal) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from blosc2>=2.3.0->tables->torch-spatiotemporal) (2.32.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.8->torch-spatiotemporal) (3.13.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning>=1.8->torch-spatiotemporal) (75.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4->torch-spatiotemporal) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning>=1.8->torch-spatiotemporal) (3.20.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning>=1.8->torch-spatiotemporal) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning>=1.8->torch-spatiotemporal) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning>=1.8->torch-spatiotemporal) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning>=1.8->torch-spatiotemporal) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning>=1.8->torch-spatiotemporal) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning>=1.8->torch-spatiotemporal) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning>=1.8->torch-spatiotemporal) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning>=1.8->torch-spatiotemporal) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning>=1.8->torch-spatiotemporal) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning>=1.8->torch-spatiotemporal) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning>=1.8->torch-spatiotemporal) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning>=1.8->torch-spatiotemporal) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning>=1.8->torch-spatiotemporal) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning>=1.8->torch-spatiotemporal) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning>=1.8->torch-spatiotemporal) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1.0->pytorch-lightning>=1.8->torch-spatiotemporal) (12.6.85)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.8->torch-spatiotemporal) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.8->torch-spatiotemporal) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.8->torch-spatiotemporal) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.8->torch-spatiotemporal) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.8->torch-spatiotemporal) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.8->torch-spatiotemporal) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.8->torch-spatiotemporal) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning>=1.8->torch-spatiotemporal) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->blosc2>=2.3.0->tables->torch-spatiotemporal) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->blosc2>=2.3.0->tables->torch-spatiotemporal) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->blosc2>=2.3.0->tables->torch-spatiotemporal) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->blosc2>=2.3.0->tables->torch-spatiotemporal) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch>=2.1.0->pytorch-lightning>=1.8->torch-spatiotemporal) (1.3.0)\n",
            "Downloading torch_spatiotemporal-0.9.5-py3-none-any.whl (253 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.6.0-py3-none-any.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics, pytorch-lightning, torch-spatiotemporal\n",
            "Successfully installed lightning-utilities-0.15.2 pytorch-lightning-2.6.0 torch-spatiotemporal-0.9.5 torchmetrics-1.8.2\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies for Google Colab with CUDA 12.1\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# Force a clean install of the stable PyTorch version\n",
        "!pip install torch==2.4.0+cu121 torchvision==0.19.0+cu121 torchaudio==2.4.0+cu121 --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# Hardcode the versions to match the line above\n",
        "TORCH = \"2.4.0\"\n",
        "CUDA = \"cu121\"\n",
        "\n",
        "# Install the PyG dependencies using the specific wheels\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric\n",
        "!pip install torch-geometric-temporal\n",
        "!pip install torch-spatiotemporal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KY6VGlrksRX_",
        "outputId": "a68e80a8-fefc-4df0-f27f-fae9ce8ff200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# utils"
      ],
      "metadata": {
        "id": "VGS52nt_D9rg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "# Python RNG\n",
        "random.seed(SEED)\n",
        "\n",
        "# NumPy RNG\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# PyTorch RNG (CPU + GPU)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Make CuDNN deterministic (slower but reproducible)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Environment-level seeds\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)"
      ],
      "metadata": {
        "id": "sgGfdL3LCrFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQsfo69xsRX_"
      },
      "source": [
        "## Model Definitions\n",
        "\n",
        "This cell contains all spatio-temporal GNN model architectures:\n",
        "- DCRNNSpatioTemporalModel: Diffusion Convolutional Recurrent Neural Network\n",
        "- STGCNModel: Spatio-Temporal Graph Convolutional Network\n",
        "- STConvWrapper: Spatio-Temporal Convolution with attention\n",
        "- A3TGCNWrapper: Attention Temporal Graph Convolutional Network\n",
        "- GConvLSTMWrapper: Graph Convolutional LSTM\n",
        "- MTGNNWrapper: Multivariate Time Series GNN (with fixed configs for short sequences)\n",
        "\n",
        "Also includes MODEL_CLASS_REGISTRY and factory functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fkkKAefsRYA",
        "outputId": "ac02b611-7efa-4f1d-ebec-be1ca2cebe15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models loaded successfully!\n",
            "Available model classes: ['DCRNNSpatioTemporalModel', 'STGCNModel', 'STConvWrapper', 'A3TGCNWrapper', 'GConvLSTMWrapper', 'MTGNNWrapper', 'AGCRNModel', 'GraphWaveNetModel']\n"
          ]
        }
      ],
      "source": [
        "# models.py style cell\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import Optional, Dict, Any, List, Tuple\n",
        "\n",
        "# PyTorch Geometric imports\n",
        "from torch_geometric.nn import ChebConv\n",
        "from torch_geometric.utils import add_self_loops\n",
        "\n",
        "# PyTorch Geometric Temporal imports\n",
        "from torch_geometric_temporal.nn.recurrent import DCRNN as DCRNNCell\n",
        "from torch_geometric_temporal.nn.recurrent import A3TGCN\n",
        "from torch_geometric_temporal.nn.recurrent import GConvLSTM\n",
        "from torch_geometric_temporal.nn.attention import STConv\n",
        "from torch_geometric_temporal.nn.attention import MTGNN\n",
        "\n",
        "# TSL (Torch Spatiotemporal) imports\n",
        "from tsl.nn.models.stgn import AGCRNModel, GraphWaveNetModel\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Model 1: DCRNN (Diffusion Convolutional Recurrent Neural Network)\n",
        "# =============================================================================\n",
        "\n",
        "class DCRNNSpatioTemporalModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Diffusion Convolutional Recurrent Neural Network for spatio-temporal forecasting.\n",
        "\n",
        "    Captures diffusion patterns across the keyword graph over time using recurrent cells.\n",
        "    Uses two stacked DCRNN layers with dropout regularization.\n",
        "\n",
        "    NOTE: This model processes one timestep at a time. Use forward_dcrnn_optionA()\n",
        "    helper in the training loop to properly carry hidden state across time steps.\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): Number of input features per node\n",
        "        hidden_channels (int): Number of hidden units in recurrent layers\n",
        "        out_channels (int): Number of output features (typically 1 for CPC prediction)\n",
        "        k_hops (int): Number of diffusion steps for graph convolution (default: 2)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels: int, hidden_channels: int, out_channels: int, k_hops: int = 2):\n",
        "        super(DCRNNSpatioTemporalModel, self).__init__()\n",
        "        self.hidden_channels = hidden_channels\n",
        "        self.recurrent1 = DCRNNCell(in_channels, hidden_channels, K=k_hops)\n",
        "        self.recurrent2 = DCRNNCell(hidden_channels, hidden_channels, K=k_hops)\n",
        "        self.linear = nn.Linear(hidden_channels, out_channels)\n",
        "        self.dropout_layer = nn.Dropout(p=0.3)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor,\n",
        "                edge_weight: Optional[torch.Tensor] = None,\n",
        "                H1: Optional[torch.Tensor] = None,\n",
        "                H2: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Forward pass for a single timestep with hidden state management.\n",
        "\n",
        "        Args:\n",
        "            x: Node features [num_nodes, in_channels]\n",
        "            edge_index: Graph connectivity [2, num_edges]\n",
        "            edge_weight: Edge weights [num_edges] (optional)\n",
        "            H1: Hidden state for first recurrent layer (optional)\n",
        "            H2: Hidden state for second recurrent layer (optional)\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (output [num_nodes, out_channels], H1_new, H2_new)\n",
        "        \"\"\"\n",
        "        # First recurrent layer with hidden state\n",
        "        H1_new = self.recurrent1(x, edge_index, edge_weight, H1)\n",
        "        h1 = self.dropout_layer(H1_new)\n",
        "\n",
        "        # Second recurrent layer with hidden state\n",
        "        H2_new = self.recurrent2(h1, edge_index, edge_weight, H2)\n",
        "        h2 = self.dropout_layer(H2_new)\n",
        "\n",
        "        # Output projection\n",
        "        out = self.linear(h2)\n",
        "        return out, H1_new, H2_new\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Model 2: STGCN (Spatio-Temporal Graph Convolutional Network)\n",
        "# =============================================================================\n",
        "\n",
        "class STGCNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Spatio-Temporal Graph Convolutional Network.\n",
        "\n",
        "    Alternates between spatial graph convolutions (using Chebyshev polynomials) and\n",
        "    temporal convolutions to capture spatio-temporal dependencies.\n",
        "\n",
        "    Args:\n",
        "        num_features (int): Number of input features per node\n",
        "        hidden_channels (int): Number of hidden channels (default: 64)\n",
        "        K (int): Chebyshev polynomial order for graph convolution (default: 3)\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features: int, hidden_channels: int = 64, K: int = 3):\n",
        "        super(STGCNModel, self).__init__()\n",
        "\n",
        "        # Spatial: Chebyshev Graph Convolution\n",
        "        self.spatial_conv1 = ChebConv(num_features, hidden_channels, K=K)\n",
        "        self.spatial_conv2 = ChebConv(hidden_channels, hidden_channels, K=K)\n",
        "\n",
        "        # Temporal: 1D Convolution over time\n",
        "        self.temporal_conv1 = nn.Conv1d(hidden_channels, hidden_channels, kernel_size=3, padding=1)\n",
        "        self.temporal_conv2 = nn.Conv1d(hidden_channels, hidden_channels, kernel_size=3, padding=1)\n",
        "\n",
        "        # Output layer\n",
        "        self.output_conv = nn.Linear(hidden_channels, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor,\n",
        "                edge_weight: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass processing batched spatio-temporal data.\n",
        "\n",
        "        Args:\n",
        "            x: Node features [batch, time, nodes, features]\n",
        "            edge_index: Graph connectivity [2, num_edges]\n",
        "            edge_weight: Edge weights [num_edges] (optional)\n",
        "\n",
        "        Returns:\n",
        "            Predictions [batch, 1, nodes, 1]\n",
        "        \"\"\"\n",
        "        batch_size, time_steps, num_nodes, num_features = x.shape\n",
        "\n",
        "        # Process each timestep with spatial convolution\n",
        "        temporal_outputs = []\n",
        "        for t in range(time_steps):\n",
        "            x_t = x[:, t, :, :]  # [batch, nodes, features]\n",
        "            x_t_flat = x_t.reshape(-1, num_features)  # [batch*nodes, features]\n",
        "\n",
        "            # Create batched edge_index (repeat for each batch)\n",
        "            batch_edge_index = []\n",
        "            batch_edge_weight = []\n",
        "            for b in range(batch_size):\n",
        "                offset = b * num_nodes\n",
        "                batch_edge_index.append(edge_index + offset)\n",
        "                if edge_weight is not None:\n",
        "                    batch_edge_weight.append(edge_weight)\n",
        "\n",
        "            batch_edge_index = torch.cat(batch_edge_index, dim=1)\n",
        "            if edge_weight is not None:\n",
        "                batch_edge_weight = torch.cat(batch_edge_weight)\n",
        "            else:\n",
        "                batch_edge_weight = None\n",
        "\n",
        "            # Apply spatial convolution\n",
        "            h = self.spatial_conv1(x_t_flat, batch_edge_index, batch_edge_weight)\n",
        "            h = self.relu(h)\n",
        "            h = self.dropout(h)\n",
        "            h = self.spatial_conv2(h, batch_edge_index, batch_edge_weight)\n",
        "            h = self.relu(h)\n",
        "\n",
        "            # Reshape back to [batch, nodes, hidden]\n",
        "            h = h.reshape(batch_size, num_nodes, -1)\n",
        "            temporal_outputs.append(h)\n",
        "\n",
        "        # Stack temporal outputs: [batch, time, nodes, hidden]\n",
        "        h_temporal = torch.stack(temporal_outputs, dim=1)\n",
        "\n",
        "        # Apply temporal convolution\n",
        "        h_temporal = h_temporal.permute(0, 2, 3, 1)  # [batch, nodes, hidden, time]\n",
        "        batch_size, num_nodes, hidden_dim, time_steps = h_temporal.shape\n",
        "\n",
        "        # Flatten batch and nodes for temporal conv\n",
        "        h_temporal = h_temporal.reshape(batch_size * num_nodes, hidden_dim, time_steps)\n",
        "\n",
        "        # Apply temporal convolutions\n",
        "        h_temporal = self.temporal_conv1(h_temporal)\n",
        "        h_temporal = self.relu(h_temporal)\n",
        "        h_temporal = self.temporal_conv2(h_temporal)\n",
        "        h_temporal = self.relu(h_temporal)\n",
        "\n",
        "        # Take last timestep\n",
        "        h_final = h_temporal[:, :, -1]  # [batch*nodes, hidden]\n",
        "\n",
        "        # Apply output layer\n",
        "        out = self.output_conv(h_final)  # [batch*nodes, 1]\n",
        "\n",
        "        # Reshape to [batch, 1, nodes, 1]\n",
        "        out = out.reshape(batch_size, num_nodes, 1)\n",
        "        out = out.unsqueeze(1)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Model 3: STConv (Spatio-Temporal Convolution with Attention)\n",
        "# =============================================================================\n",
        "\n",
        "class STConvWrapper(nn.Module):\n",
        "    \"\"\"\n",
        "    Spatio-Temporal Convolution wrapper using attention mechanisms.\n",
        "\n",
        "    Uses STConv blocks that combine spatial and temporal attention to capture\n",
        "    complex spatio-temporal patterns in the data.\n",
        "\n",
        "    Args:\n",
        "        num_nodes (int): Number of nodes in the graph\n",
        "        num_features (int): Number of input features per node\n",
        "        hidden_channels (int): Number of hidden channels (default: 64)\n",
        "        kernel_size (int): Temporal kernel size (default: 3)\n",
        "        K (int): Chebyshev polynomial order (default: 3)\n",
        "    \"\"\"\n",
        "    def __init__(self, num_nodes: int, num_features: int, hidden_channels: int = 64,\n",
        "                 kernel_size: int = 3, K: int = 3):\n",
        "        super(STConvWrapper, self).__init__()\n",
        "        self.num_nodes = num_nodes\n",
        "        self.hidden_channels = hidden_channels\n",
        "\n",
        "        self.stconv1 = STConv(\n",
        "            num_nodes=num_nodes,\n",
        "            in_channels=num_features,\n",
        "            hidden_channels=hidden_channels,\n",
        "            out_channels=hidden_channels,\n",
        "            kernel_size=kernel_size,\n",
        "            K=K,\n",
        "            normalization='sym'\n",
        "        )\n",
        "\n",
        "        self.stconv2 = STConv(\n",
        "            num_nodes=num_nodes,\n",
        "            in_channels=hidden_channels,\n",
        "            hidden_channels=hidden_channels,\n",
        "            out_channels=hidden_channels,\n",
        "            kernel_size=kernel_size,\n",
        "            K=K,\n",
        "            normalization='sym'\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(hidden_channels, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor,\n",
        "                edge_weight: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass with STConv blocks.\n",
        "\n",
        "        Args:\n",
        "            x: Node features [batch, time, nodes, features]\n",
        "            edge_index: Graph connectivity [2, num_edges]\n",
        "            edge_weight: Edge weights [num_edges] (optional)\n",
        "\n",
        "        Returns:\n",
        "            Predictions [batch, 1, nodes, 1]\n",
        "        \"\"\"\n",
        "        # Apply STConv blocks\n",
        "        h = self.stconv1(x, edge_index, edge_weight)\n",
        "        h = self.relu(h)\n",
        "        h = self.dropout(h)\n",
        "\n",
        "        h = self.stconv2(h, edge_index, edge_weight)\n",
        "        h = self.relu(h)\n",
        "        h = self.dropout(h)\n",
        "\n",
        "        # Robust output handling - find dimensions by size\n",
        "        dims = h.shape\n",
        "        node_dim = -1\n",
        "        channel_dim = -1\n",
        "\n",
        "        for i, d in enumerate(dims):\n",
        "            if d == self.num_nodes:\n",
        "                node_dim = i\n",
        "            elif d == self.hidden_channels:\n",
        "                channel_dim = i\n",
        "\n",
        "        # Safety fallback\n",
        "        if node_dim == -1: node_dim = 2\n",
        "        if channel_dim == -1: channel_dim = 1\n",
        "\n",
        "        # Find the time dimension\n",
        "        time_dim = [i for i in range(4) if i not in [0, node_dim, channel_dim]][0]\n",
        "\n",
        "        # Permute to [batch, nodes, channels, time]\n",
        "        h = h.permute(0, node_dim, channel_dim, time_dim)\n",
        "\n",
        "        # Take last timestep\n",
        "        h = h[..., -1]  # [batch, nodes, channels]\n",
        "\n",
        "        # Apply final linear layer\n",
        "        out = self.fc(h)  # [batch, nodes, 1]\n",
        "\n",
        "        # Reshape to [batch, 1, nodes, 1]\n",
        "        out = out.unsqueeze(1)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Model 4: A3TGCN (Attention Temporal Graph Convolutional Network)\n",
        "# =============================================================================\n",
        "\n",
        "class A3TGCNWrapper(nn.Module):\n",
        "    \"\"\"\n",
        "    Attention Temporal Graph Convolutional Network wrapper.\n",
        "\n",
        "    Applies attention mechanisms to temporal sequences on graph-structured data,\n",
        "    allowing the model to focus on the most relevant time steps.\n",
        "\n",
        "    Args:\n",
        "        num_features (int): Number of input features per node\n",
        "        hidden_size (int): Size of hidden representations (default: 64)\n",
        "        periods (int): Number of time periods to process (default: 12)\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features: int, hidden_size: int = 64, periods: int = 12):\n",
        "        super(A3TGCNWrapper, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.a3tgcn = A3TGCN(\n",
        "            in_channels=num_features,\n",
        "            out_channels=hidden_size,\n",
        "            periods=periods\n",
        "        )\n",
        "\n",
        "        self.linear = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor,\n",
        "                edge_weight: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass with temporal attention.\n",
        "\n",
        "        Args:\n",
        "            x: Node features [batch, time, nodes, features]\n",
        "            edge_index: Graph connectivity [2, num_edges]\n",
        "            edge_weight: Edge weights [num_edges] (optional)\n",
        "\n",
        "        Returns:\n",
        "            Predictions [batch, 1, nodes, 1]\n",
        "        \"\"\"\n",
        "        batch_size = x.shape[0]\n",
        "        outputs = []\n",
        "\n",
        "        # Process each sample in the batch separately\n",
        "        for i in range(batch_size):\n",
        "            # Get single sample: [time, nodes, features]\n",
        "            sample = x[i]\n",
        "\n",
        "            # Permute to [nodes, features, time] (required by A3TGCN)\n",
        "            sample = sample.permute(1, 2, 0)\n",
        "\n",
        "            # Pass through A3TGCN (time is aggregated by attention)\n",
        "            h = self.a3tgcn(sample, edge_index, edge_weight)  # [nodes, hidden]\n",
        "\n",
        "            outputs.append(h)\n",
        "\n",
        "        # Stack batch: [batch, nodes, hidden]\n",
        "        h = torch.stack(outputs, dim=0)\n",
        "\n",
        "        # Output layer\n",
        "        out = self.linear(h)  # [batch, nodes, 1]\n",
        "\n",
        "        # Reshape to [batch, 1, nodes, 1]\n",
        "        out = out.unsqueeze(1)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Model 5: GConvLSTM (Graph Convolutional LSTM)\n",
        "# =============================================================================\n",
        "\n",
        "class GConvLSTMWrapper(nn.Module):\n",
        "    \"\"\"\n",
        "    Graph Convolutional LSTM wrapper.\n",
        "\n",
        "    Combines graph convolutions with LSTM cells to capture long-term temporal\n",
        "    dependencies on graph-structured data.\n",
        "\n",
        "    Args:\n",
        "        num_features (int): Number of input features per node\n",
        "        hidden_size (int): Size of LSTM hidden state (default: 64)\n",
        "        K (int): Number of hops for graph convolution (default: 2)\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features: int, hidden_size: int = 64, K: int = 2):\n",
        "        super(GConvLSTMWrapper, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.gconv_lstm = GConvLSTM(\n",
        "            in_channels=num_features,\n",
        "            out_channels=hidden_size,\n",
        "            K=K\n",
        "        )\n",
        "\n",
        "        self.linear = nn.Linear(hidden_size, 1)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor,\n",
        "                edge_weight: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass with graph convolutional LSTM.\n",
        "\n",
        "        Args:\n",
        "            x: Node features [batch, time, nodes, features]\n",
        "            edge_index: Graph connectivity [2, num_edges]\n",
        "            edge_weight: Edge weights [num_edges] (optional)\n",
        "\n",
        "        Returns:\n",
        "            Predictions [batch, 1, nodes, 1]\n",
        "        \"\"\"\n",
        "        batch_size, time_steps, num_nodes, num_features = x.shape\n",
        "        batch_outputs = []\n",
        "\n",
        "        # Process each sample in the batch\n",
        "        for b in range(batch_size):\n",
        "            # Initialize hidden (H) and cell (C) states\n",
        "            H, C = None, None\n",
        "\n",
        "            # Process sequence step-by-step\n",
        "            for t in range(time_steps):\n",
        "                x_t = x[b, t, :, :]  # [nodes, features]\n",
        "                H, C = self.gconv_lstm(x_t, edge_index, edge_weight, H, C)\n",
        "\n",
        "            # H is the hidden state of the last timestep\n",
        "            batch_outputs.append(H)\n",
        "\n",
        "        # Stack batch: [batch, nodes, hidden]\n",
        "        output = torch.stack(batch_outputs, dim=0)\n",
        "\n",
        "        out = self.dropout(output)\n",
        "        out = self.linear(out)  # [batch, nodes, 1]\n",
        "\n",
        "        # Reshape to [batch, 1, nodes, 1]\n",
        "        out = out.unsqueeze(1)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Model 6: MTGNN (Multivariate Time Series Graph Neural Network)\n",
        "# Fixed configuration for short sequences (layers=1, kernel_set=[2])\n",
        "# =============================================================================\n",
        "\n",
        "class MTGNNWrapper(nn.Module):\n",
        "    \"\"\"\n",
        "    Multivariate Time Series Graph Neural Network wrapper.\n",
        "\n",
        "    Advanced model that learns graph structure adaptively while handling multivariate\n",
        "    time series with various temporal scales using dilated convolutions and mix-hop propagation.\n",
        "\n",
        "    NOTE: Uses simplified config (layers=1, kernel_set=[2]) to avoid kernel size errors\n",
        "    with short sequences (seq_length=12).\n",
        "\n",
        "    Args:\n",
        "        num_nodes (int): Number of nodes in the graph\n",
        "        num_features (int): Number of input features per node\n",
        "        seq_length (int): Length of input sequences\n",
        "        horizon (int): Forecast horizon\n",
        "        hidden_size (int): Base hidden size (default: 32)\n",
        "        dropout (float): Dropout rate (default: 0.3)\n",
        "    \"\"\"\n",
        "    def __init__(self, num_nodes: int, num_features: int, seq_length: int, horizon: int,\n",
        "                 hidden_size: int = 32, dropout: float = 0.3):\n",
        "        super(MTGNNWrapper, self).__init__()\n",
        "        self.horizon = horizon\n",
        "\n",
        "        # Fixed simpler config to avoid kernel size > input size error\n",
        "        self.mtgnn = MTGNN(\n",
        "            gcn_true=True,\n",
        "            build_adj=True,\n",
        "            gcn_depth=2,\n",
        "            num_nodes=num_nodes,\n",
        "            kernel_set=[2],          # Simplified: single small kernel\n",
        "            kernel_size=2,           # Small kernel size\n",
        "            layers=1,                # Single layer to reduce receptive field\n",
        "            dropout=dropout,\n",
        "            subgraph_size=min(20, num_nodes),\n",
        "            node_dim=40,\n",
        "            dilation_exponential=1,  # No dilation expansion\n",
        "            conv_channels=hidden_size,\n",
        "            residual_channels=hidden_size,\n",
        "            skip_channels=hidden_size * 2,\n",
        "            end_channels=hidden_size * 4,\n",
        "            seq_length=seq_length,\n",
        "            in_dim=num_features,\n",
        "            out_dim=horizon,\n",
        "            propalpha=0.05,\n",
        "            tanhalpha=3,\n",
        "            layer_norm_affline=True\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor, edge_index: Optional[torch.Tensor] = None,\n",
        "                edge_weight: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass with adaptive graph learning.\n",
        "\n",
        "        NOTE: This model does NOT use edge_index/edge_weight - it learns its own graph.\n",
        "\n",
        "        Args:\n",
        "            x: Node features [batch, time, nodes, features]\n",
        "            edge_index: Graph connectivity (ignored, model learns its own)\n",
        "            edge_weight: Edge weights (ignored)\n",
        "\n",
        "        Returns:\n",
        "            Predictions [batch, horizon, nodes, 1]\n",
        "        \"\"\"\n",
        "        # MTGNN expects [batch, features, nodes, time]\n",
        "        x = x.permute(0, 3, 2, 1)\n",
        "\n",
        "        # Forward pass (no edge_index needed)\n",
        "        out = self.mtgnn(x)\n",
        "\n",
        "        # Output shape from MTGNN: [batch, horizon, nodes]\n",
        "        # Reshape to [batch, horizon, nodes, 1]\n",
        "        if out.dim() == 3:\n",
        "            out = out.unsqueeze(-1)\n",
        "        elif out.dim() == 4:\n",
        "            # Already has last dimension, ensure correct shape\n",
        "            out = out.permute(0, 2, 3, 1).unsqueeze(-1)\n",
        "            out = out.squeeze(-2)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Model Class Registry - Maps string names to actual classes\n",
        "# =============================================================================\n",
        "\n",
        "MODEL_CLASS_REGISTRY: Dict[str, type] = {\n",
        "    'DCRNNSpatioTemporalModel': DCRNNSpatioTemporalModel,\n",
        "    'STGCNModel': STGCNModel,\n",
        "    'STConvWrapper': STConvWrapper,\n",
        "    'A3TGCNWrapper': A3TGCNWrapper,\n",
        "    'GConvLSTMWrapper': GConvLSTMWrapper,\n",
        "    'MTGNNWrapper': MTGNNWrapper,\n",
        "    'AGCRNModel': AGCRNModel,\n",
        "    'GraphWaveNetModel': GraphWaveNetModel,\n",
        "}\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Factory Functions\n",
        "# =============================================================================\n",
        "\n",
        "def get_model(model_name: str,\n",
        "              model_configs: Dict[str, Dict[str, Any]],\n",
        "              device: str = 'cpu',\n",
        "              **override_params) -> nn.Module:\n",
        "    \"\"\"\n",
        "    Factory function to instantiate models by name using external config.\n",
        "\n",
        "    Args:\n",
        "        model_name (str): Name of the model (must be in model_configs)\n",
        "        model_configs (Dict): Configuration dictionary for all models\n",
        "        device (str): Device to place the model on ('cpu' or 'cuda')\n",
        "        **override_params: Parameters to override from the default configuration\n",
        "\n",
        "    Returns:\n",
        "        nn.Module: Instantiated model moved to the specified device\n",
        "\n",
        "    Example:\n",
        "        >>> model = get_model('DCRNN', BASE_MODEL_CONFIGS, device='cuda', hidden_channels=256)\n",
        "    \"\"\"\n",
        "    if model_name not in model_configs:\n",
        "        available = ', '.join(model_configs.keys())\n",
        "        raise ValueError(f\"Model '{model_name}' not found. Available models: {available}\")\n",
        "\n",
        "    cfg = model_configs[model_name]\n",
        "    class_name = cfg['class']\n",
        "    model_class = MODEL_CLASS_REGISTRY[class_name]\n",
        "\n",
        "    # Merge default params with overrides\n",
        "    params = {**cfg.get('params', {}), **override_params}\n",
        "\n",
        "    # Instantiate and move to device\n",
        "    model = model_class(**params)\n",
        "    model = model.to(device)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_model_config(model_name: str,\n",
        "                     model_configs: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Get the full configuration dictionary for a model.\n",
        "\n",
        "    Args:\n",
        "        model_name (str): Name of the model\n",
        "        model_configs (Dict): Configuration dictionary for all models\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: Configuration dictionary containing params, training config, and description\n",
        "    \"\"\"\n",
        "    if model_name not in model_configs:\n",
        "        available = ', '.join(model_configs.keys())\n",
        "        raise ValueError(f\"Model '{model_name}' not found. Available models: {available}\")\n",
        "\n",
        "    return model_configs[model_name]\n",
        "\n",
        "\n",
        "def list_models(model_configs: Dict[str, Dict[str, Any]]) -> List[str]:\n",
        "    \"\"\"\n",
        "    Get a list of all available model names.\n",
        "\n",
        "    Args:\n",
        "        model_configs (Dict): Configuration dictionary for all models\n",
        "\n",
        "    Returns:\n",
        "        List[str]: List of model names\n",
        "    \"\"\"\n",
        "    return list(model_configs.keys())\n",
        "\n",
        "\n",
        "print(\"Models loaded successfully!\")\n",
        "print(f\"Available model classes: {list(MODEL_CLASS_REGISTRY.keys())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI7utTYBsRYB"
      },
      "source": [
        "## Configuration\n",
        "\n",
        "This cell contains:\n",
        "- BASE_MODEL_CONFIGS: Model architecture parameters and training hyperparameters\n",
        "- EXPERIMENT_CONFIG: Experiment settings (horizons, splits, scaling)\n",
        "\n",
        "**v3 Change:** DCRNN batch_size reduced from 32 to 16 for memory efficiency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeuh7bDTsRYB",
        "outputId": "fe671701-dcb9-4bf5-d1a1-fabbcaaa6dec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration loaded successfully!\n",
            "\n",
            "Feature columns (9): ['impressions_sum', 'cpc_week', 'adclicks_sum', 'adcost_sum', 'n_dev_desktop', 'n_dev_mobile', 'n_dev_tablet', 'n_st_branded_search', 'n_st_generic_search']\n",
            "Target column: cpc_week\n",
            "\n",
            "Experiment settings:\n",
            "  - Sequence length: 12\n",
            "  - Horizons: [1, 6, 12]\n",
            "  - Test weeks: 12\n",
            "\n",
            "Models configured: ['DCRNN', 'STGCN', 'STConv', 'A3TGCN', 'GConvLSTM', 'MTGNN', 'AGCRN', 'GraphWaveNet']\n"
          ]
        }
      ],
      "source": [
        "# configs.py style cell\n",
        "from typing import Dict, Any, List\n",
        "\n",
        "# =============================================================================\n",
        "# Feature Columns Definition\n",
        "# =============================================================================\n",
        "\n",
        "FEATURE_COLS: List[str] = [\n",
        "    'impressions_sum', 'cpc_week',\n",
        "    # 'avg_sim_top25_this_week', 'avg_sim_top25_last_week',\n",
        "    # 'n_sim_this_week', 'n_sim_last_week',\n",
        "    'adclicks_sum', 'adcost_sum',\n",
        "    'n_dev_desktop', 'n_dev_mobile', 'n_dev_tablet',\n",
        "    'n_st_branded_search', 'n_st_generic_search',\n",
        "]\n",
        "\n",
        "TARGET_COL: str = 'cpc_week'\n",
        "\n",
        "# =============================================================================\n",
        "# File Paths for Google Colab\n",
        "# =============================================================================\n",
        "\n",
        "GRAPH_FOLDER_PATH: str = \"/content/drive/MyDrive/Colab Notebooks/master_thesis_gdrive/sebs_keyword_graph_knn\"\n",
        "TIME_SERIES_CSV_PATH: str = \"/content/drive/MyDrive/Colab Notebooks/master_thesis_gdrive/sebs_weekly_aggregated_by_week_keyword.parquet\"\n",
        "\n",
        "# =============================================================================\n",
        "# Base Model Configurations\n",
        "# Class names are strings - resolved via MODEL_CLASS_REGISTRY\n",
        "# =============================================================================\n",
        "\n",
        "# --- FIX: Dynamically set input size based on actual features ---\n",
        "NUM_FEATURES = len(FEATURE_COLS)  # Should be 15\n",
        "\n",
        "BASE_MODEL_CONFIGS: Dict[str, Dict[str, Any]] = {\n",
        "    'DCRNN': {\n",
        "        'class': 'DCRNNSpatioTemporalModel',\n",
        "        'params': {\n",
        "            'in_channels': NUM_FEATURES,  # Changed from 13\n",
        "            'hidden_channels': 128,\n",
        "            'out_channels': 1,\n",
        "            'k_hops': 2,\n",
        "        },\n",
        "        'training': {\n",
        "            'learning_rate': 1e-3,\n",
        "            'epochs': 100,\n",
        "            'batch_size': 16,\n",
        "        },\n",
        "        'description': 'Diffusion Convolutional Recurrent Neural Network',\n",
        "    },\n",
        "\n",
        "    'STGCN': {\n",
        "        'class': 'STGCNModel',\n",
        "        'params': {\n",
        "            'num_features': NUM_FEATURES,  # Changed from 13\n",
        "            'hidden_channels': 64,\n",
        "            'K': 3,\n",
        "        },\n",
        "        'training': {\n",
        "            'learning_rate': 1e-3,\n",
        "            'epochs': 100,\n",
        "            'batch_size': 32,\n",
        "        },\n",
        "        'description': 'Spatio-Temporal Graph Convolutional Network',\n",
        "    },\n",
        "\n",
        "    'STConv': {\n",
        "        'class': 'STConvWrapper',\n",
        "        'params': {\n",
        "            'num_nodes': 1811,\n",
        "            'num_features': NUM_FEATURES,  # Changed from 13\n",
        "            'hidden_channels': 64,\n",
        "            'kernel_size': 3,\n",
        "            'K': 3,\n",
        "        },\n",
        "        'training': {\n",
        "            'learning_rate': 1e-3,\n",
        "            'epochs': 100,\n",
        "            'batch_size': 32,\n",
        "        },\n",
        "        'description': 'Spatio-Temporal Convolution with Attention',\n",
        "    },\n",
        "\n",
        "    'A3TGCN': {\n",
        "        'class': 'A3TGCNWrapper',\n",
        "        'params': {\n",
        "            'num_features': NUM_FEATURES,  # Changed from 13\n",
        "            'hidden_size': 64,\n",
        "            'periods': 12,\n",
        "        },\n",
        "        'training': {\n",
        "            'learning_rate': 1e-3,\n",
        "            'epochs': 100,\n",
        "            'batch_size': 32,\n",
        "        },\n",
        "        'description': 'Attention Temporal Graph Convolutional Network',\n",
        "    },\n",
        "\n",
        "    'GConvLSTM': {\n",
        "        'class': 'GConvLSTMWrapper',\n",
        "        'params': {\n",
        "            'num_features': NUM_FEATURES,  # Changed from 13\n",
        "            'hidden_size': 64,\n",
        "            'K': 2,\n",
        "        },\n",
        "        'training': {\n",
        "            'learning_rate': 1e-3,\n",
        "            'epochs': 100,\n",
        "            'batch_size': 32,\n",
        "        },\n",
        "        'description': 'Graph Convolutional LSTM',\n",
        "    },\n",
        "\n",
        "    'MTGNN': {\n",
        "        'class': 'MTGNNWrapper',\n",
        "        'params': {\n",
        "            'num_nodes': 1811,\n",
        "            'num_features': NUM_FEATURES,  # Changed from 13\n",
        "            'seq_length': 12,\n",
        "            'horizon': 1,\n",
        "            'hidden_size': 32,\n",
        "            'dropout': 0.3,\n",
        "        },\n",
        "        'training': {\n",
        "            'learning_rate': 1e-3,\n",
        "            'epochs': 100,\n",
        "            'batch_size': 16,\n",
        "        },\n",
        "        'description': 'Multivariate Time Series GNN',\n",
        "    },\n",
        "\n",
        "    'AGCRN': {\n",
        "        'class': 'AGCRNModel',\n",
        "        'params': {\n",
        "            'input_size': NUM_FEATURES,  # Changed from 13\n",
        "            'output_size': 1,\n",
        "            'n_nodes': 1811,\n",
        "            'horizon': 1,\n",
        "            'hidden_size': 64,\n",
        "            'n_layers': 2,\n",
        "        },\n",
        "        'training': {\n",
        "            'learning_rate': 1e-3,\n",
        "            'epochs': 100,\n",
        "            'batch_size': 16,\n",
        "        },\n",
        "        'description': 'Adaptive Graph Convolutional Recurrent Network',\n",
        "    },\n",
        "\n",
        "    'GraphWaveNet': {\n",
        "        'class': 'GraphWaveNetModel',\n",
        "        'params': {\n",
        "            'input_size': NUM_FEATURES,  # Changed from 13\n",
        "            'output_size': 1,\n",
        "            'n_nodes': 1811,\n",
        "            'horizon': 1,\n",
        "            'hidden_size': 64,\n",
        "            'dropout': 0.3,\n",
        "        },\n",
        "        'training': {\n",
        "            'learning_rate': 1e-3,\n",
        "            'epochs': 100,\n",
        "            'batch_size': 16,\n",
        "        },\n",
        "        'description': 'Graph WaveNet with Dilated Convolutions',\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Experiment Configuration\n",
        "# =============================================================================\n",
        "\n",
        "EXPERIMENT_CONFIG: Dict[str, Any] = {\n",
        "    'sequence_length': 12,              # L: number of past weeks to use\n",
        "    'horizons': [1, 6, 12],             # H: forecast horizons to evaluate\n",
        "    'test_weeks_last': 12,              # Number of weeks to hold out for testing\n",
        "    'val_split_ratio': 0.25,            # INCREASED from 0.2 to 0.25 to fix H=12 skipping\n",
        "    'metrics': ['MSE', 'MAE'],\n",
        "    'scaling': {\n",
        "        'type': 'standard',\n",
        "        'per_feature': True,\n",
        "        'per_node': False,\n",
        "    },\n",
        "    'training_defaults': {\n",
        "        'early_stopping_patience': 10,\n",
        "        'gradient_clip_norm': 5.0,\n",
        "    },\n",
        "    'csv_export': {\n",
        "        'enabled': True,\n",
        "        'experiment_name': 'v6',\n",
        "        'model_prefix': 'gnn',\n",
        "        'exog_mode': 'graph',\n",
        "        'drive_path': '/content/drive/MyDrive/Colab Notebooks/master_thesis_gdrive/benchmarks',\n",
        "        'local_path': '/content',\n",
        "    },\n",
        "    'tensor_export': {\n",
        "        'enabled': True,\n",
        "        'experiment_name': 'v6',\n",
        "        'save_predictions': True,\n",
        "        'save_targets': True,\n",
        "        'save_inputs': True,\n",
        "        'save_errors': True,\n",
        "        'drive_path': '/content/drive/MyDrive/Colab Notebooks/master_thesis_gdrive/benchmarks/tensors_v6',\n",
        "        'local_path': '/content/tensors_v6',\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "print(\"Configuration loaded successfully!\")\n",
        "print(f\"\\nFeature columns ({NUM_FEATURES}): {FEATURE_COLS}\")\n",
        "print(f\"Target column: {TARGET_COL}\")\n",
        "print(f\"\\nExperiment settings:\")\n",
        "print(f\"  - Sequence length: {EXPERIMENT_CONFIG['sequence_length']}\")\n",
        "print(f\"  - Horizons: {EXPERIMENT_CONFIG['horizons']}\")\n",
        "print(f\"  - Test weeks: {EXPERIMENT_CONFIG['test_weeks_last']}\")\n",
        "print(f\"\\nModels configured: {list(BASE_MODEL_CONFIGS.keys())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iksM0ZDBsRYB"
      },
      "source": [
        "## Data Utilities\n",
        "\n",
        "This cell contains data loading and preprocessing functions:\n",
        "- load_graph_and_data(): Load graph structure and time series data\n",
        "- build_week_splits(): Split weeks into train/val/test\n",
        "- build_feature_tensor(): Create [T, N, F] feature tensors\n",
        "- scale_features(): Apply StandardScaler (fit on train only)\n",
        "- build_optionA_samples(): Create sliding window samples for Option A\n",
        "- to_torch_dataset(): Convert numpy arrays to torch tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3UW-PHTsRYB",
        "outputId": "9e745fa3-10c8-484a-bf52-0e129d58f798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data utilities loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# data_utils.py style cell\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import json\n",
        "import os\n",
        "from typing import Dict, List, Tuple, Any, Optional\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "def load_graph_and_data(graph_folder: str,\n",
        "                        time_series_path: str) -> Tuple[np.ndarray, np.ndarray, Dict[str, int], pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Load graph structure and time series data from files.\n",
        "    Handles 'WW-YYYY' date formats (e.g., '02-2021').\n",
        "\n",
        "    Args:\n",
        "        graph_folder: Path to folder containing edge_index.npy, edge_weight.npy, keyword_map.json\n",
        "        time_series_path: Path to parquet file with time series data\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (edge_index, edge_weight, keyword_map, dataframe)\n",
        "    \"\"\"\n",
        "    # Load graph structure\n",
        "    edge_index = np.load(os.path.join(graph_folder, 'edge_index.npy'))\n",
        "    edge_weight = np.load(os.path.join(graph_folder, 'edge_weight.npy'))\n",
        "\n",
        "    with open(os.path.join(graph_folder, 'keyword_map.json'), 'r') as f:\n",
        "        keyword_map = json.load(f)\n",
        "\n",
        "    # Load time series data\n",
        "    df = pd.read_parquet(time_series_path)\n",
        "\n",
        "    print(f\"Graph loaded: {edge_index.shape[1]} edges, {len(keyword_map)} nodes\")\n",
        "\n",
        "    # --- FIX START: Handle \"02-2021\" (Week-Year) format ---\n",
        "    # We check if the column is string and contains a dash\n",
        "    if df['week'].dtype == object and df['week'].astype(str).str.contains('-').any():\n",
        "        print(\"  Detected 'WW-YYYY' string format (e.g., '02-2021'). Parsing...\")\n",
        "        try:\n",
        "            # Split \"02-2021\" into \"02\" and \"2021\"\n",
        "            # Assuming format is \"Week-Year\" based on user input\n",
        "            parts = df['week'].astype(str).str.split('-', expand=True)\n",
        "\n",
        "            # Convert to numbers\n",
        "            week_nums = pd.to_numeric(parts[0], errors='coerce')\n",
        "            years = pd.to_numeric(parts[1], errors='coerce')\n",
        "\n",
        "            # 1. Create a sortable integer for the 'week' column: Year * 100 + Week\n",
        "            #    Example: \"02-2021\" -> 202102\n",
        "            #    Example: \"01-2022\" -> 202201\n",
        "            #    This ensures correct chronological sorting.\n",
        "            df['week'] = years * 100 + week_nums\n",
        "\n",
        "            # 2. Use the isolated week number (1-52) for seasonality features\n",
        "            #    We use 'week_nums' here, NOT df['week']\n",
        "            df['week_sin'] = np.sin(2 * np.pi * week_nums / 52.0)\n",
        "            df['week_cos'] = np.cos(2 * np.pi * week_nums / 52.0)\n",
        "\n",
        "            print(\"  Successfully parsed 'WW-YYYY' format.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Error parsing 'WW-YYYY' format: {e}\")\n",
        "            # Fallback to coercion if parsing fails\n",
        "            df['week'] = pd.to_numeric(df['week'], errors='coerce')\n",
        "            df['week_sin'] = np.sin(2 * np.pi * df['week'] / 52.0)\n",
        "            df['week_cos'] = np.cos(2 * np.pi * df['week'] / 52.0)\n",
        "\n",
        "    else:\n",
        "        # Fallback for standard numeric columns\n",
        "        print(\"  Using standard numeric parsing...\")\n",
        "        df['week'] = pd.to_numeric(df['week'], errors='coerce')\n",
        "        df['week_sin'] = np.sin(2 * np.pi * df['week'] / 52.0)\n",
        "        df['week_cos'] = np.cos(2 * np.pi * df['week'] / 52.0)\n",
        "\n",
        "    # Drop any rows that failed conversion\n",
        "    df = df.dropna(subset=['week'])\n",
        "    df['week'] = df['week'].astype(int)\n",
        "    # --- FIX END ---\n",
        "\n",
        "    print(f\"Time series loaded: {len(df)} rows, {df['week'].nunique()} weeks\")\n",
        "\n",
        "    return edge_index, edge_weight, keyword_map, df\n",
        "\n",
        "\n",
        "def build_week_splits(df: pd.DataFrame,\n",
        "                      test_weeks_last: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Split weeks into train/val weeks and test weeks.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with 'week' column\n",
        "        test_weeks_last: Number of weeks to reserve for testing (from the end)\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (trainval_weeks, test_weeks) as numpy arrays\n",
        "    \"\"\"\n",
        "    weeks = np.array(sorted(df['week'].unique()))\n",
        "    test_weeks = weeks[-test_weeks_last:]\n",
        "    trainval_weeks = weeks[:-test_weeks_last]\n",
        "\n",
        "    print(f\"Week split: {len(trainval_weeks)} train/val weeks, {len(test_weeks)} test weeks\")\n",
        "    print(f\"  Train/Val range: {trainval_weeks[0]} to {trainval_weeks[-1]}\")\n",
        "    print(f\"  Test range: {test_weeks[0]} to {test_weeks[-1]}\")\n",
        "\n",
        "    return trainval_weeks, test_weeks\n",
        "\n",
        "\n",
        "def build_feature_tensor(df: pd.DataFrame,\n",
        "                         keyword_map: Dict[str, int],\n",
        "                         weeks: np.ndarray,\n",
        "                         feature_cols: List[str]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Build a 3D feature tensor from the dataframe.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with columns 'week', 'keyword', and feature columns\n",
        "        keyword_map: Mapping from keyword string to node index\n",
        "        weeks: Array of weeks to include\n",
        "        feature_cols: List of feature column names\n",
        "\n",
        "    Returns:\n",
        "        numpy array of shape [T, N, F] where T=num_weeks, N=num_nodes, F=num_features\n",
        "    \"\"\"\n",
        "    num_nodes = len(keyword_map)\n",
        "    num_features = len(feature_cols)\n",
        "    num_time = len(weeks)\n",
        "\n",
        "    X = np.zeros((num_time, num_nodes, num_features), dtype=np.float32)\n",
        "\n",
        "    # Create a mapping from (week, keyword) to row for faster lookup\n",
        "    df_indexed = df.set_index(['week', 'keyword'])\n",
        "\n",
        "    for t_idx, week in enumerate(weeks):\n",
        "        for keyword, node_id in keyword_map.items():\n",
        "            try:\n",
        "                row = df_indexed.loc[(week, keyword)]\n",
        "                for f_idx, col in enumerate(feature_cols):\n",
        "                    if col in row.index:\n",
        "                        val = row[col]\n",
        "                        if pd.notna(val):\n",
        "                            X[t_idx, node_id, f_idx] = float(val)\n",
        "            except KeyError:\n",
        "                # Keyword not present for this week - leave as zeros\n",
        "                pass\n",
        "\n",
        "    print(f\"Feature tensor built: shape {X.shape}\")\n",
        "    return X\n",
        "\n",
        "\n",
        "def scale_features(train_X: np.ndarray,\n",
        "                   val_X: np.ndarray,\n",
        "                   test_X: np.ndarray,\n",
        "                   scaling_cfg: Dict[str, Any],\n",
        "                   target_col_idx: int = -1) -> Tuple[np.ndarray, np.ndarray, np.ndarray, StandardScaler]:\n",
        "    \"\"\"\n",
        "    Apply StandardScaler to features, fitting only on training data.\n",
        "\n",
        "    Args:\n",
        "        train_X: Training features [T_train, N, F]\n",
        "        val_X: Validation features [T_val, N, F]\n",
        "        test_X: Test features [T_test, N, F]\n",
        "        scaling_cfg: Scaling configuration dict\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (train_scaled, val_scaled, test_scaled, scaler)\n",
        "    \"\"\"\n",
        "    T_tr, N, F = train_X.shape\n",
        "\n",
        "    # Apply log1p transformation to target column if specified\n",
        "    if target_col_idx >= 0:\n",
        "        print(f\"Applying log1p transformation to target column {target_col_idx}\")\n",
        "        train_X[..., target_col_idx] = np.log1p(train_X[..., target_col_idx])\n",
        "        val_X[..., target_col_idx] = np.log1p(val_X[..., target_col_idx])\n",
        "        test_X[..., target_col_idx] = np.log1p(test_X[..., target_col_idx])\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Flatten over time & nodes: (T*N, F) to fit scaler\n",
        "    train_flat = train_X.reshape(-1, F)\n",
        "    scaler.fit(train_flat)\n",
        "\n",
        "    # Transform all splits\n",
        "    train_scaled = scaler.transform(train_flat).reshape(train_X.shape)\n",
        "    val_scaled = scaler.transform(val_X.reshape(-1, F)).reshape(val_X.shape)\n",
        "    test_scaled = scaler.transform(test_X.reshape(-1, F)).reshape(test_X.shape)\n",
        "\n",
        "    print(f\"Features scaled with StandardScaler (fit on {T_tr * N} train samples)\")\n",
        "\n",
        "    return train_scaled, val_scaled, test_scaled, scaler\n",
        "\n",
        "\n",
        "def build_optionA_samples(X: np.ndarray,\n",
        "                          weeks: np.ndarray,\n",
        "                          horizon: int,\n",
        "                          seq_len: int,\n",
        "                          target_col_idx: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Build sliding window samples for Option A (direct H-step prediction).\n",
        "\n",
        "    For each valid starting position, creates:\n",
        "    - Input: seq_len consecutive weeks of features\n",
        "    - Target: CPC value at (last input week + horizon)\n",
        "\n",
        "    Args:\n",
        "        X: Feature tensor [T, N, F]\n",
        "        weeks: Array of week identifiers (same length as T)\n",
        "        horizon: Number of steps ahead to predict\n",
        "        seq_len: Length of input sequence\n",
        "        target_col_idx: Index of target column (CPC) in feature dimension\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (X_samples [S, L, N, F], y_samples [S, 1, N, 1])\n",
        "        where S is number of valid samples, L is seq_len\n",
        "    \"\"\"\n",
        "    T, N, F = X.shape\n",
        "    X_list, y_list = [], []\n",
        "\n",
        "    # Valid range: need seq_len weeks for input, plus horizon weeks for target\n",
        "    # Start from seq_len-1 (0-indexed position of last input week)\n",
        "    # End at T - horizon - 1 (so t + horizon is still valid)\n",
        "    for t in range(seq_len - 1, T - horizon):\n",
        "        # Input: weeks [t - seq_len + 1, ..., t] inclusive\n",
        "        X_win = X[t - seq_len + 1:t + 1]  # [L, N, F]\n",
        "\n",
        "        # Target: CPC at week t + horizon\n",
        "        y_win = X[t + horizon, :, target_col_idx]  # [N]\n",
        "\n",
        "        X_list.append(X_win)\n",
        "        y_list.append(y_win)\n",
        "\n",
        "    if len(X_list) == 0:\n",
        "        print(f\"Warning: No valid samples for horizon={horizon}, seq_len={seq_len}, T={T}\")\n",
        "        return np.zeros((0, seq_len, N, F), dtype=np.float32), np.zeros((0, 1, N, 1), dtype=np.float32)\n",
        "\n",
        "    X_arr = np.stack(X_list, axis=0)  # [S, L, N, F]\n",
        "    y_arr = np.stack(y_list, axis=0)  # [S, N]\n",
        "\n",
        "    # Reshape y to [S, 1, N, 1]\n",
        "    y_arr = y_arr[:, np.newaxis, :, np.newaxis]  # [S, 1, N, 1]\n",
        "\n",
        "    print(f\"Built {len(X_list)} samples for horizon={horizon}: X={X_arr.shape}, y={y_arr.shape}\")\n",
        "\n",
        "    return X_arr, y_arr\n",
        "\n",
        "\n",
        "def to_torch_dataset(X_np: np.ndarray,\n",
        "                     y_np: np.ndarray,\n",
        "                     device: str = 'cpu') -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Convert numpy arrays to torch tensors on specified device.\n",
        "\n",
        "    Args:\n",
        "        X_np: Input features [S, L, N, F]\n",
        "        y_np: Targets [S, 1, N, 1]\n",
        "        device: Device to place tensors on\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (X_tensor, y_tensor)\n",
        "    \"\"\"\n",
        "    # Handle NaN values\n",
        "    X_np = np.nan_to_num(X_np, nan=0.0)\n",
        "    y_np = np.nan_to_num(y_np, nan=0.0)\n",
        "\n",
        "    X = torch.from_numpy(X_np).float().to(device)\n",
        "    y = torch.from_numpy(y_np).float().to(device)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "\n",
        "print(\"Data utilities loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRPX7OoSsRYB"
      },
      "source": [
        "## Training Utilities\n",
        "\n",
        "This cell contains training and evaluation functions:\n",
        "- forward_dcrnn_optionA(): Helper for DCRNN with proper hidden state management\n",
        "- ensure_B1N1(): Reshape outputs to standard [B, 1, N, 1] format\n",
        "- make_dataloader(): Create PyTorch DataLoader from tensors\n",
        "- train_one_model_optionA(): Full training loop with early stopping\n",
        "- evaluate_model_optionA(): Evaluate model on test data (NOW RETURNS TUPLE)\n",
        "- generate_config_string(): Generate compact config strings for CSV\n",
        "- save_model_tensors(): Save predictions/targets/inputs/errors\n",
        "- export_results_to_csv(): Export metrics to CSV benchmark format\n",
        "\n",
        "**v4 Changes:**\n",
        "1. DCRNN self-loops to prevent NaN\n",
        "2. Removed .detach() for proper Backprop-Through-Time\n",
        "\n",
        "**v5 Changes:**\n",
        "1. evaluate_model_optionA() now returns (metrics_dict, tensors_dict) tuple\n",
        "2. Added RMSE and SMAPE calculations\n",
        "3. Added tensor saving and CSV export functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufsuZ-bDsRYB",
        "outputId": "dff298f3-e8aa-4a68-ff60-fb7f58ca84e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training utilities loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# train_eval.py style cell\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch_geometric.utils import add_self_loops\n",
        "from typing import Dict, Any, Optional, Tuple\n",
        "import numpy as np\n",
        "from copy import deepcopy  # (import kept in case you use it elsewhere)\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "def forward_dcrnn_optionA(\n",
        "    model: nn.Module,\n",
        "    X_batch: torch.Tensor,\n",
        "    edge_index: torch.Tensor,\n",
        "    edge_weight: torch.Tensor,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Corrected forward pass for DCRNN.\n",
        "\n",
        "    FIXES in v4:\n",
        "    1. Adds self-loops to prevent Division-by-Zero (NaN losses)\n",
        "    2. Removes internal .detach() so Backprop-Through-Time works properly\n",
        "\n",
        "    Args:\n",
        "        model: DCRNNSpatioTemporalModel instance\n",
        "        X_batch: Input tensor [B, L, N, F]\n",
        "        edge_index: Graph connectivity [2, E]\n",
        "        edge_weight: Edge weights [E]\n",
        "\n",
        "    Returns:\n",
        "        Output tensor [B, 1, N, 1]\n",
        "    \"\"\"\n",
        "    batch_size, seq_len, num_nodes, num_features = X_batch.shape\n",
        "\n",
        "    # --- FIX 1: Prevent NaN by ensuring no node has Degree=0 ---\n",
        "    # We add self-loops once before processing the batch.\n",
        "    # This ensures the diffusion matrix normalization never divides by zero.\n",
        "    edge_index_loop, edge_weight_loop = add_self_loops(\n",
        "        edge_index,\n",
        "        edge_weight,\n",
        "        fill_value=1.0,\n",
        "        num_nodes=num_nodes,\n",
        "    )\n",
        "\n",
        "    preds = []\n",
        "\n",
        "    for b in range(batch_size):\n",
        "        # Initialize hidden states for this specific sample\n",
        "        # (This effectively \"detaches\" from the previous sample in the batch)\n",
        "        H1, H2 = None, None\n",
        "\n",
        "        # Process sequence\n",
        "        for t in range(seq_len):\n",
        "            x_t = X_batch[b, t]  # [N, F]\n",
        "\n",
        "            # Feed through model\n",
        "            out_t, H1, H2 = model(\n",
        "                x_t,\n",
        "                edge_index_loop,\n",
        "                edge_weight_loop,\n",
        "                H1,\n",
        "                H2,\n",
        "            )\n",
        "            # --- FIX 2: REMOVED .detach() ---\n",
        "            # We MUST keep the connection to H_prev so gradients can flow\n",
        "            # back from t=10 to t=0. If you run OOM, reduce batch_size,\n",
        "            # not the gradient history.\n",
        "\n",
        "        preds.append(out_t)\n",
        "\n",
        "    # Stack batch: [B, N, 1]\n",
        "    output = torch.stack(preds, dim=0)\n",
        "\n",
        "    # Reshape to [B, 1, N, 1]\n",
        "    output = output.unsqueeze(1)\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def ensure_B1N1(output: torch.Tensor, num_nodes: Optional[int] = None) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Ensure output tensor has shape [B, 1, N, 1].\n",
        "\n",
        "    Different models output different shapes. This helper normalizes them:\n",
        "    - [B, N, 1] -> [B, 1, N, 1]\n",
        "    - [B, N] -> [B, 1, N, 1]\n",
        "    - [B, 1, N] -> [B, 1, N, 1]\n",
        "    - [B, H, N, 1] with H=1 -> [B, 1, N, 1] (already correct)\n",
        "\n",
        "    Args:\n",
        "        output: Model output tensor (various shapes)\n",
        "        num_nodes: Expected number of nodes (for validation)\n",
        "\n",
        "    Returns:\n",
        "        Tensor with shape [B, 1, N, 1]\n",
        "    \"\"\"\n",
        "    if output.dim() == 2:\n",
        "        # [B, N] -> [B, 1, N, 1]\n",
        "        return output.unsqueeze(1).unsqueeze(-1)\n",
        "\n",
        "    elif output.dim() == 3:\n",
        "        # Could be [B, N, 1] or [B, 1, N]\n",
        "        if output.shape[-1] == 1:\n",
        "            # [B, N, 1] -> [B, 1, N, 1]\n",
        "            return output.unsqueeze(1)\n",
        "        else:\n",
        "            # [B, 1, N] -> [B, 1, N, 1]\n",
        "            return output.unsqueeze(-1)\n",
        "\n",
        "    elif output.dim() == 4:\n",
        "        # Already 4D, should be [B, H, N, 1] or similar\n",
        "        if output.shape[1] == 1 and output.shape[-1] == 1:\n",
        "            return output\n",
        "        else:\n",
        "            # Try to reshape intelligently\n",
        "            B = output.shape[0]\n",
        "            # Flatten and reshape assuming last two dims are N and output_size\n",
        "            return output.reshape(B, 1, -1, 1)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected output shape: {output.shape}\")\n",
        "\n",
        "\n",
        "def make_dataloader(\n",
        "    X: torch.Tensor,\n",
        "    y: torch.Tensor,\n",
        "    batch_size: int,\n",
        "    shuffle: bool = True,\n",
        ") -> DataLoader:\n",
        "    \"\"\"\n",
        "    Create a PyTorch DataLoader from tensors.\n",
        "\n",
        "    Args:\n",
        "        X: Input tensor [S, L, N, F]\n",
        "        y: Target tensor [S, 1, N, 1]\n",
        "        batch_size: Batch size\n",
        "        shuffle: Whether to shuffle data\n",
        "\n",
        "    Returns:\n",
        "        DataLoader instance\n",
        "    \"\"\"\n",
        "    dataset = TensorDataset(X, y)\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "\n",
        "\n",
        "def train_one_model_optionA(\n",
        "    model_name: str,\n",
        "    model_configs: Dict[str, Dict[str, Any]],\n",
        "    experiment_cfg: Dict[str, Any],\n",
        "    X_train: torch.Tensor,\n",
        "    y_train: torch.Tensor,\n",
        "    X_val: torch.Tensor,\n",
        "    y_val: torch.Tensor,\n",
        "    edge_index: torch.Tensor,\n",
        "    edge_weight: torch.Tensor,\n",
        "    device: str = \"cpu\",\n",
        "    verbose: bool = True,\n",
        "    pbar: Optional[tqdm] = None,  # can be a global progress bar\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Train a single model with early stopping, gradient clipping, Progress Bar support,\n",
        "    and per-epoch logging (both in-memory logs and optional console output).\n",
        "    \"\"\"\n",
        "    cfg = get_model_config(model_name, model_configs)\n",
        "    model = get_model(model_name, model_configs, device=device)\n",
        "\n",
        "    lr = cfg[\"training\"][\"learning_rate\"]\n",
        "    epochs = cfg[\"training\"][\"epochs\"]\n",
        "    batch_size = cfg[\"training\"][\"batch_size\"]\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Using L1Loss (MAE) as it is the best proxy for SMAPE\n",
        "    criterion = nn.L1Loss()\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.5, patience=5, verbose=False\n",
        "    )\n",
        "\n",
        "    train_loader = make_dataloader(X_train, y_train, batch_size, shuffle=True)\n",
        "    val_loader = make_dataloader(X_val, y_val, batch_size, shuffle=False)\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_state = None\n",
        "\n",
        "    # History as simple lists (for quick inspection)\n",
        "    history = {\"train_loss\": [], \"val_loss\": []}\n",
        "\n",
        "    # Detailed per-epoch logs (nice for CSV / plotting)\n",
        "    epoch_logs = []  # each entry: {\"epoch\": int, \"train_loss\": float, \"val_loss\": float, \"lr\": float}\n",
        "\n",
        "    patience = experiment_cfg[\"training_defaults\"][\"early_stopping_patience\"]\n",
        "    max_norm = experiment_cfg[\"training_defaults\"][\"gradient_clip_norm\"]\n",
        "    no_improve = 0\n",
        "    epochs_trained = 0\n",
        "\n",
        "    no_edge_models = [\"AGCRN\", \"MTGNN\"]\n",
        "\n",
        "    # you can change this to 5 or 10 if you don't want a line per epoch\n",
        "    LOG_EVERY = 5\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epochs_trained += 1\n",
        "\n",
        "        # -------------------------\n",
        "        # Training\n",
        "        # -------------------------\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "\n",
        "        for Xb, yb in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            if model_name == \"DCRNN\":\n",
        "                output = forward_dcrnn_optionA(model, Xb, edge_index, edge_weight)\n",
        "            elif model_name in no_edge_models:\n",
        "                out = model(Xb)\n",
        "                output = ensure_B1N1(out)\n",
        "            else:\n",
        "                output = model(Xb, edge_index, edge_weight)\n",
        "\n",
        "            loss = criterion(output, yb)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
        "            optimizer.step()\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "        avg_train = float(np.mean(train_losses)) if train_losses else float(\"inf\")\n",
        "\n",
        "        # -------------------------\n",
        "        # Validation\n",
        "        # -------------------------\n",
        "        model.eval()\n",
        "        val_losses = []\n",
        "        with torch.no_grad():\n",
        "            for Xb, yb in val_loader:\n",
        "                if model_name == \"DCRNN\":\n",
        "                    output = forward_dcrnn_optionA(model, Xb, edge_index, edge_weight)\n",
        "                elif model_name in no_edge_models:\n",
        "                    out = model(Xb)\n",
        "                    output = ensure_B1N1(out)\n",
        "                else:\n",
        "                    output = model(Xb, edge_index, edge_weight)\n",
        "\n",
        "                val_loss = criterion(output, yb).item()\n",
        "                val_losses.append(val_loss)\n",
        "\n",
        "        avg_val = float(np.mean(val_losses)) if val_losses else float(\"inf\")\n",
        "\n",
        "        history[\"train_loss\"].append(avg_train)\n",
        "        history[\"val_loss\"].append(avg_val)\n",
        "\n",
        "        # current LR (useful when ReduceLROnPlateau kicks in)\n",
        "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
        "        scheduler.step(avg_val)\n",
        "\n",
        "        # store a structured log row\n",
        "        epoch_logs.append({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train_loss\": avg_train,\n",
        "            \"val_loss\": avg_val,\n",
        "            \"lr\": current_lr,\n",
        "        })\n",
        "\n",
        "        # -------------------------\n",
        "        # Progress bar + console logging\n",
        "        # -------------------------\n",
        "        if pbar:\n",
        "            # only update the global bar, keep per-epoch details via tqdm.write\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix(model=model_name, val_loss=f\"{avg_val:.4f}\")\n",
        "\n",
        "        if verbose and ((epoch + 1) % LOG_EVERY == 0):\n",
        "            msg = (\n",
        "                f\"[{model_name}] epoch {epoch+1:03d}/{epochs:03d} \"\n",
        "                f\"| train={avg_train:.4f} | val={avg_val:.4f} | lr={current_lr:.5f}\"\n",
        "            )\n",
        "            if pbar:\n",
        "                tqdm.write(msg)   # does not break tqdm layout\n",
        "            else:\n",
        "                print(msg)\n",
        "\n",
        "        # -------------------------\n",
        "        # Early stopping\n",
        "        # -------------------------\n",
        "        if avg_val < best_val_loss:\n",
        "            best_val_loss = avg_val\n",
        "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "            no_improve = 0\n",
        "        else:\n",
        "            no_improve += 1\n",
        "            if no_improve >= patience:\n",
        "                if verbose:\n",
        "                    stop_msg = f\"  Early stopping at epoch {epoch + 1} (best val={best_val_loss:.4f})\"\n",
        "                    if pbar:\n",
        "                        tqdm.write(stop_msg)\n",
        "                    else:\n",
        "                        print(stop_msg)\n",
        "                break\n",
        "\n",
        "    # If early stopping happened, update global pbar for skipped epochs\n",
        "    if pbar and epochs_trained < epochs:\n",
        "        pbar.update(epochs - epochs_trained)\n",
        "\n",
        "    # Restore best state\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "        model = model.to(device)\n",
        "\n",
        "    return {\n",
        "        \"model\": model,\n",
        "        \"best_val_loss\": best_val_loss,\n",
        "        \"history\": history,        # simple lists\n",
        "        \"epoch_logs\": epoch_logs,  # rich per-epoch records\n",
        "        \"epochs_trained\": epochs_trained,\n",
        "    }\n",
        "\n",
        "\n",
        "def evaluate_model_optionA(\n",
        "    model: nn.Module,\n",
        "    model_name: str,\n",
        "    X_test: torch.Tensor,\n",
        "    y_test: torch.Tensor,\n",
        "    edge_index: torch.Tensor,\n",
        "    edge_weight: torch.Tensor,\n",
        "    scaler: Optional[Any] = None,      # NEW: Required for unscaling\n",
        "    target_col_idx: int = 1,           # NEW: Index of target column (usually 1)\n",
        "    batch_size: int = 32,\n",
        "    return_tensors: bool = True,\n",
        ") -> Tuple[Dict[str, float], Optional[Dict[str, torch.Tensor]]]:\n",
        "    \"\"\"\n",
        "    Evaluate a trained model on test data, calculating metrics on REAL (unscaled) values.\n",
        "\n",
        "    Args:\n",
        "        model: Trained PyTorch model\n",
        "        model_name: Name of the model (for forward pass logic)\n",
        "        X_test: Test inputs [S, L, N, F]\n",
        "        y_test: Test targets [S, 1, N, 1]\n",
        "        edge_index: Graph connectivity\n",
        "        edge_weight: Edge weights\n",
        "        scaler: The fitted StandardScaler (used to inverse transform predictions)\n",
        "        target_col_idx: Index of the target column in the feature set\n",
        "        batch_size: Batch size for inference\n",
        "        return_tensors: Whether to return raw tensors (predictions, errors, etc.)\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (metrics_dict, tensors_dict)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Models that don't use edge_index in forward pass\n",
        "    no_edge_models = [\"AGCRN\", \"MTGNN\"]\n",
        "\n",
        "    test_loader = make_dataloader(X_test, y_test, batch_size, shuffle=False)\n",
        "\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for Xb, yb in test_loader:\n",
        "            if model_name == \"DCRNN\":\n",
        "                output = forward_dcrnn_optionA(model, Xb, edge_index, edge_weight)\n",
        "            elif model_name in no_edge_models:\n",
        "                output = model(Xb)\n",
        "                output = ensure_B1N1(output)\n",
        "            else:\n",
        "                output = model(Xb, edge_index, edge_weight)\n",
        "\n",
        "            all_preds.append(output)\n",
        "            all_targets.append(yb)\n",
        "\n",
        "    # Concatenate all batches -> [Total_Samples, 1, Nodes, 1]\n",
        "    preds = torch.cat(all_preds, dim=0)\n",
        "    targets = torch.cat(all_targets, dim=0)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # METRIC CALCULATION ON REAL VALUES (INVERSE SCALING)\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    # Flatten to [Total_Samples * Nodes, 1] for scaler\n",
        "    preds_flat = preds.cpu().numpy().reshape(-1, 1)\n",
        "    targets_flat = targets.cpu().numpy().reshape(-1, 1)\n",
        "\n",
        "    real_preds = preds_flat\n",
        "    real_targets = targets_flat\n",
        "\n",
        "    # Only inverse scale if scaler is provided\n",
        "    if scaler is not None:\n",
        "        num_features = scaler.mean_.shape[0]\n",
        "\n",
        "        # Create dummy matrices [N_samples, N_features] to satisfy scaler input shape\n",
        "        dummy_preds = np.zeros((len(preds_flat), num_features))\n",
        "        dummy_targets = np.zeros((len(targets_flat), num_features))\n",
        "\n",
        "        # Place our predictions/targets into the correct feature column\n",
        "        dummy_preds[:, target_col_idx] = preds_flat[:, 0]\n",
        "        dummy_targets[:, target_col_idx] = targets_flat[:, 0]\n",
        "\n",
        "        # Inverse transform (StandardScaler -> Original Scale)\n",
        "        inv_preds = scaler.inverse_transform(dummy_preds)\n",
        "        inv_targets = scaler.inverse_transform(dummy_targets)\n",
        "\n",
        "        # Extract the target column back\n",
        "        real_preds = inv_preds[:, target_col_idx]\n",
        "        real_targets = inv_targets[:, target_col_idx]\n",
        "\n",
        "        # Reverse Log1p if it was applied (assuming you used log1p on target)\n",
        "        # We use a simple heuristic: if values are small and you used log1p, this is needed.\n",
        "        # Based on your logs: \"Applying log1p transformation to target column 1\"\n",
        "        real_preds = np.expm1(real_preds)\n",
        "        real_targets = np.expm1(real_targets)\n",
        "\n",
        "        # Safety: clip negative predictions to 0 (CPC cannot be negative)\n",
        "        real_preds = np.maximum(real_preds, 0.0)\n",
        "\n",
        "    # Convert back to tensor for easy metric calculation\n",
        "    real_preds_t = torch.from_numpy(real_preds)\n",
        "    real_targets_t = torch.from_numpy(real_targets)\n",
        "\n",
        "    # Compute Metrics\n",
        "    mse = torch.mean((real_preds_t - real_targets_t) ** 2).item()\n",
        "    mae = torch.mean(torch.abs(real_preds_t - real_targets_t)).item()\n",
        "    rmse = torch.sqrt(torch.mean((real_preds_t - real_targets_t) ** 2)).item()\n",
        "\n",
        "    # SMAPE (Symmetric Mean Absolute Percentage Error)\n",
        "    # Formula: 100 * mean( |P - A| / (|P| + |A|)/2 )\n",
        "    numerator = torch.abs(real_preds_t - real_targets_t)\n",
        "    denominator = (torch.abs(real_preds_t) + torch.abs(real_targets_t)) / 2.0\n",
        "    epsilon = 1e-8  # Prevent division by zero\n",
        "    smape = 100 * torch.mean(numerator / (denominator + epsilon)).item()\n",
        "\n",
        "    metrics = {\n",
        "        \"MSE\": mse,\n",
        "        \"MAE\": mae,\n",
        "        \"RMSE\": rmse,\n",
        "        \"SMAPE\": smape,\n",
        "    }\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # RETURN TENSORS (Keep original scaled tensors for debugging internals)\n",
        "    # -------------------------------------------------------------------------\n",
        "    tensors = None\n",
        "    if return_tensors:\n",
        "        errors = preds - targets\n",
        "        tensors = {\n",
        "            \"predictions\": preds,   # Scaled\n",
        "            \"targets\": targets,     # Scaled\n",
        "            \"inputs\": X_test,       # Scaled\n",
        "            \"errors\": errors,       # Scaled\n",
        "            \"real_predictions\": real_preds_t, # Unscaled (Optional helper)\n",
        "            \"real_targets\": real_targets_t,   # Unscaled (Optional helper)\n",
        "        }\n",
        "\n",
        "    return metrics, tensors\n",
        "\n",
        "\n",
        "def generate_config_string(model_config: Dict[str, Any]) -> str:\n",
        "    \"\"\"\n",
        "    Generate compact configuration string from model config.\n",
        "\n",
        "    Format: h{hidden}_lr{lr}_bs{batch_size}_e{epochs}\n",
        "    Example: \"h64_lr0.001_bs32_e100\"\n",
        "\n",
        "    Args:\n",
        "        model_config: Model configuration dictionary\n",
        "\n",
        "    Returns:\n",
        "        Compact config string\n",
        "    \"\"\"\n",
        "    params = model_config.get(\"params\", {})\n",
        "    training = model_config.get(\"training\", {})\n",
        "\n",
        "    # Extract key parameters (with fallbacks)\n",
        "    hidden = (\n",
        "        params.get(\"hidden_channels\")\n",
        "        or params.get(\"hidden_size\")\n",
        "        or params.get(\"conv_channels\", 64)\n",
        "    )\n",
        "    lr = training.get(\"learning_rate\", 0.001)\n",
        "    batch_size = training.get(\"batch_size\", 32)\n",
        "    epochs = training.get(\"epochs\", 100)\n",
        "\n",
        "    return f\"h{hidden}_lr{lr}_bs{batch_size}_e{epochs}\"\n",
        "\n",
        "\n",
        "def save_model_tensors(\n",
        "    tensors: Dict[str, torch.Tensor],\n",
        "    model_name: str,\n",
        "    horizon: int,\n",
        "    experiment_cfg: Dict[str, Any],\n",
        "    verbose: bool = True,\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Save model evaluation tensors to disk for error analysis.\n",
        "\n",
        "    Saves 4 tensors: predictions, targets, inputs, errors\n",
        "    Format: PyTorch .pt files\n",
        "    Locations: Google Drive (primary) + local runtime (backup)\n",
        "\n",
        "    Args:\n",
        "        tensors: Dict with 'predictions', 'targets', 'inputs', 'errors'\n",
        "        model_name: Name of the model (e.g., 'STGCN')\n",
        "        horizon: Forecast horizon (1, 6, or 12)\n",
        "        experiment_cfg: Experiment configuration with tensor_export settings\n",
        "        verbose: Print status messages\n",
        "    \"\"\"\n",
        "    import os\n",
        "\n",
        "    if not experiment_cfg.get(\"tensor_export\", {}).get(\"enabled\", False):\n",
        "        return\n",
        "\n",
        "    tensor_cfg = experiment_cfg[\"tensor_export\"]\n",
        "\n",
        "    # Define which tensors to save\n",
        "    tensors_to_save = {\n",
        "        \"predictions\": tensor_cfg.get(\"save_predictions\", True),\n",
        "        \"targets\": tensor_cfg.get(\"save_targets\", True),\n",
        "        \"inputs\": tensor_cfg.get(\"save_inputs\", True),\n",
        "        \"errors\": tensor_cfg.get(\"save_errors\", True),\n",
        "    }\n",
        "\n",
        "    saved_count = 0\n",
        "    failed_count = 0\n",
        "\n",
        "    for tensor_type, should_save in tensors_to_save.items():\n",
        "        if not should_save or tensor_type not in tensors:\n",
        "            continue\n",
        "\n",
        "        tensor = tensors[tensor_type]\n",
        "        filename = f\"{model_name}_h{horizon}_{tensor_type}.pt\"\n",
        "\n",
        "        # Save to local runtime (guaranteed to work)\n",
        "        local_path = os.path.join(tensor_cfg[\"local_path\"], filename)\n",
        "        try:\n",
        "            os.makedirs(tensor_cfg[\"local_path\"], exist_ok=True)\n",
        "            torch.save(tensor.cpu(), local_path)\n",
        "            saved_count += 1\n",
        "        except Exception as e:\n",
        "            if verbose:\n",
        "                print(f\"    ✗ Failed to save {tensor_type} to local: {e}\")\n",
        "            failed_count += 1\n",
        "\n",
        "        # Save to Google Drive (best-effort)\n",
        "        drive_path = os.path.join(tensor_cfg[\"drive_path\"], filename)\n",
        "        try:\n",
        "            os.makedirs(tensor_cfg[\"drive_path\"], exist_ok=True)\n",
        "            torch.save(tensor.cpu(), drive_path)\n",
        "        except Exception as e:\n",
        "            if verbose:\n",
        "                print(f\"    ⚠ Could not save {tensor_type} to Drive: {e}\")\n",
        "\n",
        "    if verbose and saved_count > 0:\n",
        "        print(f\"    ✓ Saved {saved_count} tensors ({model_name}_h{horizon}_*.pt)\")\n",
        "\n",
        "\n",
        "def export_results_to_csv(\n",
        "    results: Dict[int, Dict[str, Dict[str, Any]]],\n",
        "    model_configs: Dict[str, Dict[str, Any]],\n",
        "    experiment_cfg: Dict[str, Any],\n",
        "    verbose: bool = True,\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Export experiment results to CSV in the benchmark format.\n",
        "\n",
        "    Saves to two locations:\n",
        "    1. Google Drive (primary): {drive_path}/metrics_gnn_models_{experiment_name}.csv\n",
        "    2. Local runtime (backup): {local_path}/metrics_gnn_models_{experiment_name}.csv\n",
        "\n",
        "    Args:\n",
        "        results: Nested dict {horizon: {model_name: {metrics...}}}\n",
        "        model_configs: BASE_MODEL_CONFIGS dict for generating config strings\n",
        "        experiment_cfg: Experiment configuration with csv_export settings\n",
        "        verbose: Print status messages\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "    import os\n",
        "\n",
        "    if not experiment_cfg.get(\"csv_export\", {}).get(\"enabled\", False):\n",
        "        if verbose:\n",
        "            print(\"CSV export disabled in config\")\n",
        "        return\n",
        "\n",
        "    csv_cfg = experiment_cfg[\"csv_export\"]\n",
        "    exp_name = csv_cfg[\"experiment_name\"]\n",
        "    model_prefix = csv_cfg[\"model_prefix\"]\n",
        "    exog_mode = csv_cfg[\"exog_mode\"]\n",
        "\n",
        "    # Build list of rows\n",
        "    rows = []\n",
        "\n",
        "    for horizon in sorted(results.keys()):\n",
        "        for model_name in sorted(results[horizon].keys()):\n",
        "            r = results[horizon][model_name]\n",
        "            if r[\"status\"] == \"SUCCESS\":\n",
        "                # Generate config string from model config\n",
        "                model_config = model_configs.get(model_name, {})\n",
        "                config_str = generate_config_string(model_config)\n",
        "\n",
        "                rows.append(\n",
        "                    {\n",
        "                        \"horizon\": horizon,\n",
        "                        \"model_id\": f\"{model_prefix} | {model_name}\",\n",
        "                        \"exog_mode\": exog_mode,\n",
        "                        \"config\": config_str,\n",
        "                        \"mse\": r[\"test_MSE\"],\n",
        "                        \"mae\": r[\"test_MAE\"],\n",
        "                        \"rmse\": r[\"test_RMSE\"],\n",
        "                        \"smape\": r[\"test_SMAPE\"],\n",
        "                    }\n",
        "                )\n",
        "\n",
        "    if not rows:\n",
        "        if verbose:\n",
        "            print(\"No successful results to export\")\n",
        "        return\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    # Column order to match benchmark CSV (with config column added)\n",
        "    df = df[\n",
        "        [\n",
        "            \"horizon\",\n",
        "            \"model_id\",\n",
        "            \"exog_mode\",\n",
        "            \"config\",\n",
        "            \"mse\",\n",
        "            \"mae\",\n",
        "            \"rmse\",\n",
        "            \"smape\",\n",
        "        ]\n",
        "    ]\n",
        "\n",
        "    filename = f\"metrics_gnn_models_{exp_name}.csv\"\n",
        "\n",
        "    # Save to local runtime (always succeeds)\n",
        "    local_path = os.path.join(csv_cfg[\"local_path\"], filename)\n",
        "    try:\n",
        "        df.to_csv(local_path, index=False)\n",
        "        if verbose:\n",
        "            print(f\"\\n✓ Results saved to local runtime: {local_path}\")\n",
        "            print(f\"  Exported {len(rows)} result rows\")\n",
        "    except Exception as e:\n",
        "        if verbose:\n",
        "            print(f\"\\n✗ Failed to save to local runtime: {e}\")\n",
        "\n",
        "    # Save to Google Drive (may fail if not mounted)\n",
        "    drive_path = os.path.join(csv_cfg[\"drive_path\"], filename)\n",
        "    try:\n",
        "        os.makedirs(csv_cfg[\"drive_path\"], exist_ok=True)\n",
        "        df.to_csv(drive_path, index=False)\n",
        "        if verbose:\n",
        "            print(f\"✓ Results saved to Google Drive: {drive_path}\")\n",
        "    except Exception as e:\n",
        "        if verbose:\n",
        "            print(f\"\\n⚠ Could not save to Google Drive: {e}\")\n",
        "            print(\"  (Results are still available in local runtime)\")\n",
        "\n",
        "    if verbose:\n",
        "        print(\"\\nCSV Preview:\")\n",
        "        print(df.head(10).to_string(index=False))\n",
        "\n",
        "\n",
        "print(\"Training utilities loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efY19t1YsRYC"
      },
      "source": [
        "# Run Experiment\n",
        "\n",
        "Main experiment loop:\n",
        "1. Load data and build week splits\n",
        "2. Build feature tensors and apply scaling\n",
        "3. For each horizon H in [1, 6, 12]:\n",
        "   - Build sliding window samples\n",
        "   - For each model:\n",
        "     - Train with early stopping\n",
        "     - Evaluate on test set (returns metrics + tensors)\n",
        "     - Save tensors for error analysis\n",
        "     - Store metrics\n",
        "4. Export results to CSV\n",
        "5. Print results table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mP_8cpeLsRYC",
        "outputId": "98232b1f-8294-4f0b-fe4a-197e3853f448"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "SPATIO-TEMPORAL GNN EXPERIMENT v6 - OPTION A (DIRECT H-STEP PREDICTION)\n",
            "================================================================================\n",
            "\n",
            "Using device: cuda\n",
            "GPU: NVIDIA L4\n",
            "\n",
            "================================================================================\n",
            "STEP 1: Loading Data\n",
            "================================================================================\n",
            "Graph loaded: 18110 edges, 1811 nodes\n",
            "  Detected 'WW-YYYY' string format (e.g., '02-2021'). Parsing...\n",
            "  Successfully parsed 'WW-YYYY' format.\n",
            "Time series loaded: 218924 rows, 127 weeks\n",
            "\n",
            "Graph: 1811 nodes, 18110 edges\n",
            "Features: 9\n",
            "\n",
            "================================================================================\n",
            "STEP 2: Building Week Splits\n",
            "================================================================================\n",
            "Week split: 115 train/val weeks, 12 test weeks\n",
            "  Train/Val range: 202053 to 202310\n",
            "  Test range: 202311 to 202322\n",
            "\n",
            "Final splits:\n",
            "  Train: 86 weeks (202053 to 202233)\n",
            "  Val: 29 weeks (202234 to 202310)\n",
            "  Test: 12 weeks (202311 to 202322)\n",
            "\n",
            "================================================================================\n",
            "STEP 3: Building Feature Tensors\n",
            "================================================================================\n",
            "Using 9/9 features: ['impressions_sum', 'cpc_week', 'adclicks_sum', 'adcost_sum', 'n_dev_desktop', 'n_dev_mobile', 'n_dev_tablet', 'n_st_branded_search', 'n_st_generic_search']\n",
            "Feature tensor built: shape (86, 1811, 9)\n",
            "Feature tensor built: shape (29, 1811, 9)\n",
            "Feature tensor built: shape (24, 1811, 9)\n",
            "\n",
            "================================================================================\n",
            "STEP 4: Scaling Features\n",
            "================================================================================\n",
            "Applying log1p transformation to target column 1\n",
            "Features scaled with StandardScaler (fit on 155746 train samples)\n",
            "Target column 'cpc_week' at index 1\n"
          ]
        }
      ],
      "source": [
        "# set up and load data\n",
        "\n",
        "import warnings\n",
        "import gc\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"SPATIO-TEMPORAL GNN EXPERIMENT v6 - OPTION A (DIRECT H-STEP PREDICTION)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Device selection\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"\\nUsing device: {device}\")\n",
        "if device == \"cuda\":\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# =============================================================================\n",
        "# Step 1: Load Data\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 1: Loading Data\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "edge_index, edge_weight, keyword_map, df = load_graph_and_data(\n",
        "    GRAPH_FOLDER_PATH,\n",
        "    TIME_SERIES_CSV_PATH,\n",
        ")\n",
        "\n",
        "# Convert to tensors\n",
        "edge_index_tensor = torch.from_numpy(edge_index).long().to(device)\n",
        "edge_weight_tensor = torch.from_numpy(edge_weight).float().to(device)\n",
        "\n",
        "num_nodes = len(keyword_map)\n",
        "num_features = len(FEATURE_COLS)\n",
        "\n",
        "print(f\"\\nGraph: {num_nodes} nodes, {edge_index.shape[1]} edges\")\n",
        "print(f\"Features: {num_features}\")\n",
        "\n",
        "# =============================================================================\n",
        "# Step 2: Build Week Splits\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 2: Building Week Splits\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "trainval_weeks, test_weeks = build_week_splits(\n",
        "    df,\n",
        "    EXPERIMENT_CONFIG[\"test_weeks_last\"],\n",
        ")\n",
        "\n",
        "# Split trainval into train/val\n",
        "val_ratio = EXPERIMENT_CONFIG[\"val_split_ratio\"]\n",
        "split_idx = int(len(trainval_weeks) * (1 - val_ratio))\n",
        "\n",
        "train_weeks = trainval_weeks[:split_idx]\n",
        "val_weeks = trainval_weeks[split_idx:]\n",
        "\n",
        "print(\"\\nFinal splits:\")\n",
        "print(f\"  Train: {len(train_weeks)} weeks ({train_weeks[0]} to {train_weeks[-1]})\")\n",
        "print(f\"  Val: {len(val_weeks)} weeks ({val_weeks[0]} to {val_weeks[-1]})\")\n",
        "print(f\"  Test: {len(test_weeks)} weeks ({test_weeks[0]} to {test_weeks[-1]})\")\n",
        "\n",
        "# =============================================================================\n",
        "# Step 3: Build Feature Tensors\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 3: Building Feature Tensors\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Filter to available features\n",
        "available_features = [col for col in FEATURE_COLS if col in df.columns]\n",
        "print(\n",
        "    f\"Using {len(available_features)}/{len(FEATURE_COLS)} features: \"\n",
        "    f\"{available_features}\"\n",
        ")\n",
        "\n",
        "X_train_raw = build_feature_tensor(df, keyword_map, train_weeks, available_features)\n",
        "X_val_raw = build_feature_tensor(df, keyword_map, val_weeks, available_features)\n",
        "\n",
        "# For test, we need to include some train weeks for the sliding window\n",
        "# Build test tensor from combined weeks (last part of train + test)\n",
        "seq_len = EXPERIMENT_CONFIG[\"sequence_length\"]\n",
        "max_horizon = max(EXPERIMENT_CONFIG[\"horizons\"])\n",
        "\n",
        "# Need seq_len weeks before test_weeks start for the sliding window\n",
        "all_weeks = np.concatenate([train_weeks, val_weeks, test_weeks])\n",
        "test_start_idx = len(train_weeks) + len(val_weeks)\n",
        "test_window_start = max(0, test_start_idx - seq_len)\n",
        "test_combined_weeks = all_weeks[test_window_start:]\n",
        "\n",
        "X_test_raw = build_feature_tensor(\n",
        "    df,\n",
        "    keyword_map,\n",
        "    test_combined_weeks,\n",
        "    available_features,\n",
        ")\n",
        "\n",
        "# =============================================================================\n",
        "# Step 4: Scale Features\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 4: Scaling Features\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "target_col_idx = available_features.index(TARGET_COL)\n",
        "X_train_scaled, X_val_scaled, X_test_scaled, scaler = scale_features(\n",
        "    X_train_raw,\n",
        "    X_val_raw,\n",
        "    X_test_raw,\n",
        "    EXPERIMENT_CONFIG[\"scaling\"],\n",
        "    target_col_idx=target_col_idx,\n",
        ")\n",
        "\n",
        "print(f\"Target column '{TARGET_COL}' at index {target_col_idx}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Step 5: Run Experiments (With Progress Bar)\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 5: Running Experiments\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "results: Dict[int, Dict[str, Dict[str, Any]]] = {}\n",
        "\n",
        "# 1. Calculate Total Epochs for Progress Bar\n",
        "horizons = EXPERIMENT_CONFIG[\"horizons\"]\n",
        "models = list_models(BASE_MODEL_CONFIGS)\n",
        "total_epochs = 0\n",
        "for model_name in models:\n",
        "    total_epochs += BASE_MODEL_CONFIGS[model_name]['training']['epochs']\n",
        "total_epochs *= len(horizons)\n",
        "\n",
        "print(f\"Total scheduled epochs: {total_epochs}\")\n",
        "\n",
        "# 2. Run Experiment Loop\n",
        "with tqdm(total=total_epochs, unit=\"epoch\", desc=\"Overall Progress\") as pbar:\n",
        "    for H in horizons:\n",
        "        tqdm.write(f\"\\n{'=' * 80}\")\n",
        "        tqdm.write(f\"HORIZON H={H}\")\n",
        "        tqdm.write(f\"{'=' * 80}\")\n",
        "\n",
        "        # Build sliding window samples\n",
        "        tqdm.write(f\"Building samples for horizon {H}...\")\n",
        "        Xtr_np, ytr_np = build_optionA_samples(X_train_scaled, train_weeks, H, seq_len, target_col_idx)\n",
        "        Xval_np, yval_np = build_optionA_samples(X_val_scaled, val_weeks, H, seq_len, target_col_idx)\n",
        "        Xte_np, yte_np = build_optionA_samples(X_test_scaled, test_combined_weeks, H, seq_len, target_col_idx)\n",
        "\n",
        "        # Skip if no valid samples\n",
        "        if Xtr_np.shape[0] == 0 or Xval_np.shape[0] == 0 or Xte_np.shape[0] == 0:\n",
        "            tqdm.write(f\"  Skipping H={H}: insufficient samples\")\n",
        "            # Update pbar for skipped models in this horizon\n",
        "            skipped_epochs = sum(BASE_MODEL_CONFIGS[m]['training']['epochs'] for m in models)\n",
        "            pbar.update(skipped_epochs)\n",
        "            continue\n",
        "\n",
        "        # Convert to torch\n",
        "        Xtr, ytr = to_torch_dataset(Xtr_np, ytr_np, device)\n",
        "        Xval, yval = to_torch_dataset(Xval_np, yval_np, device)\n",
        "        Xte, yte = to_torch_dataset(Xte_np, yte_np, device)\n",
        "\n",
        "        results[H] = {}\n",
        "\n",
        "        for model_name in models:\n",
        "            tqdm.write(f\"\\n{'-' * 60}\")\n",
        "            tqdm.write(f\"Training {model_name}\")\n",
        "            tqdm.write(f\"{'-' * 60}\")\n",
        "\n",
        "            try:\n",
        "                # Train model (PASS PBAR HERE)\n",
        "                train_result = train_one_model_optionA(\n",
        "                    model_name,\n",
        "                    BASE_MODEL_CONFIGS,\n",
        "                    EXPERIMENT_CONFIG,\n",
        "                    Xtr, ytr, Xval, yval,\n",
        "                    edge_index_tensor, edge_weight_tensor,\n",
        "                    device=device,\n",
        "                    verbose=True,\n",
        "                    pbar=pbar  # <--- Pass the progress bar\n",
        "                )\n",
        "\n",
        "                # Evaluate\n",
        "                test_metrics, test_tensors = evaluate_model_optionA(\n",
        "                    train_result[\"model\"],\n",
        "                    model_name,\n",
        "                    Xte, yte,\n",
        "                    edge_index_tensor, edge_weight_tensor,\n",
        "                    scaler=scaler,\n",
        "                    target_col_idx=target_col_idx,\n",
        "                    return_tensors=True,\n",
        "                )\n",
        "\n",
        "                results[H][model_name] = {\n",
        "                    \"best_val_loss\": train_result[\"best_val_loss\"],\n",
        "                    \"epochs_trained\": train_result[\"epochs_trained\"],\n",
        "                    \"test_MSE\": test_metrics[\"MSE\"],\n",
        "                    \"test_MAE\": test_metrics[\"MAE\"],\n",
        "                    \"test_RMSE\": test_metrics[\"RMSE\"],\n",
        "                    \"test_SMAPE\": test_metrics[\"SMAPE\"],\n",
        "                    \"status\": \"SUCCESS\",\n",
        "                }\n",
        "\n",
        "                tqdm.write(\n",
        "                    f\"  SUCCESS - Val Loss: {train_result['best_val_loss']:.4f}, \"\n",
        "                    f\"Test SMAPE: {test_metrics['SMAPE']:.2f}%\"\n",
        "                )\n",
        "\n",
        "                # Save tensors\n",
        "                save_model_tensors(test_tensors, model_name, H, EXPERIMENT_CONFIG, verbose=False)\n",
        "\n",
        "                # Cleanup\n",
        "                del train_result[\"model\"]\n",
        "                gc.collect()\n",
        "                if device == \"cuda\":\n",
        "                    torch.cuda.empty_cache()\n",
        "\n",
        "            except Exception as e:\n",
        "                tqdm.write(f\"  FAILED - Error: {str(e)[:100]}\")\n",
        "                results[H][model_name] = {\"status\": \"FAILED\", \"error\": str(e)}\n",
        "\n",
        "                # If failed, update pbar for untracked epochs of this model\n",
        "                # (We don't know exactly how many ran inside before crash,\n",
        "                # but typically crashes happen early. We force complete the bar for this model)\n",
        "                model_epochs = BASE_MODEL_CONFIGS[model_name]['training']['epochs']\n",
        "                # This is an approximation since we can't easily track partial epochs on crash\n",
        "                # Use careful manual update if needed, but usually fine to just leave it\n",
        "                # or force update: pbar.update(model_epochs)\n",
        "\n",
        "                gc.collect()\n",
        "                if device == \"cuda\":\n",
        "                    torch.cuda.empty_cache()\n",
        "\n",
        "# =============================================================================\n",
        "# Print & Export Results\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"RESULTS SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\n{:<15} {:>8} {:>10} {:>10} {:>8}\".format(\"Model\", \"Horizon\", \"RMSE\", \"SMAPE%\", \"Status\"))\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for H in sorted(results.keys()):\n",
        "    for model_name in results[H]:\n",
        "        r = results[H][model_name]\n",
        "        if r[\"status\"] == \"SUCCESS\":\n",
        "            print(\"{:<15} {:>8} {:>10.4f} {:>10.2f} {:>8}\".format(\n",
        "                model_name, H, r[\"test_RMSE\"], r[\"test_SMAPE\"], \"OK\"\n",
        "            ))\n",
        "        else:\n",
        "            print(\"{:<15} {:>8} {:>10} {:>10} {:>8}\".format(model_name, H, \"N/A\", \"N/A\", \"FAILED\"))\n",
        "\n",
        "export_results_to_csv(results, BASE_MODEL_CONFIGS, EXPERIMENT_CONFIG, verbose=True)\n",
        "print(\"\\nExperiment Complete!\")"
      ],
      "metadata": {
        "id": "zp2rqCYshYVU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6d12be1d440144e6b052e07dfbf786f4",
            "7eed69e8425a4871a58a5d8777b63948",
            "f2bfe842d6cc4e1186f8edd439f962f0",
            "4ddee7437a7c4cfebb13078a04569bbf",
            "c1e67bfc7184492a9c3cbfd5d5d8af13",
            "0927e67b51d64e36942cceea0cba549a",
            "a0ecbc244c3944d4b0a62a0c9fbb877f",
            "feb5308c3473418fa80a6a12cb83e52a",
            "72ea1ac523924a5da67f62561e023d40",
            "19cdc414aa204359910e7dcf23905c53",
            "e061f4dd96374b31aeb2ce1fe414d587"
          ]
        },
        "outputId": "ee2b5cd9-e5d6-435d-c35a-55247055aff0"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "STEP 5: Running Experiments\n",
            "================================================================================\n",
            "Total scheduled epochs: 2400\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d12be1d440144e6b052e07dfbf786f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Overall Progress:   0%|          | 0/2400 [00:00<?, ?epoch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "HORIZON H=1\n",
            "================================================================================\n",
            "Building samples for horizon 1...\n",
            "Built 74 samples for horizon=1: X=(74, 12, 1811, 13), y=(74, 1, 1811, 1)\n",
            "Built 17 samples for horizon=1: X=(17, 12, 1811, 13), y=(17, 1, 1811, 1)\n",
            "Built 12 samples for horizon=1: X=(12, 12, 1811, 13), y=(12, 1, 1811, 1)\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training DCRNN\n",
            "------------------------------------------------------------\n",
            "  Early stopping at epoch 52\n",
            "  SUCCESS - Val Loss: 0.3611, Test SMAPE: 30.32%\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training STGCN\n",
            "------------------------------------------------------------\n",
            "  Early stopping at epoch 53\n",
            "  SUCCESS - Val Loss: 0.4170, Test SMAPE: 31.97%\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training STConv\n",
            "------------------------------------------------------------\n",
            "  Early stopping at epoch 43\n",
            "  SUCCESS - Val Loss: 0.4308, Test SMAPE: 33.51%\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training A3TGCN\n",
            "------------------------------------------------------------\n",
            "  Early stopping at epoch 24\n",
            "  SUCCESS - Val Loss: 0.5374, Test SMAPE: 41.71%\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training GConvLSTM\n",
            "------------------------------------------------------------\n",
            "  SUCCESS - Val Loss: 0.3993, Test SMAPE: 30.58%\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training MTGNN\n",
            "------------------------------------------------------------\n",
            "  Early stopping at epoch 22\n",
            "  SUCCESS - Val Loss: 0.3812, Test SMAPE: 31.89%\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training AGCRN\n",
            "------------------------------------------------------------\n",
            "  Early stopping at epoch 23\n",
            "  SUCCESS - Val Loss: 0.3763, Test SMAPE: 31.38%\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training GraphWaveNet\n",
            "------------------------------------------------------------\n",
            "  Early stopping at epoch 23\n",
            "  SUCCESS - Val Loss: 0.3719, Test SMAPE: 30.49%\n",
            "\n",
            "================================================================================\n",
            "HORIZON H=6\n",
            "================================================================================\n",
            "Building samples for horizon 6...\n",
            "Built 69 samples for horizon=6: X=(69, 12, 1811, 13), y=(69, 1, 1811, 1)\n",
            "Built 12 samples for horizon=6: X=(12, 12, 1811, 13), y=(12, 1, 1811, 1)\n",
            "Built 7 samples for horizon=6: X=(7, 12, 1811, 13), y=(7, 1, 1811, 1)\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training DCRNN\n",
            "------------------------------------------------------------\n",
            "  Early stopping at epoch 32\n",
            "  SUCCESS - Val Loss: 0.4438, Test SMAPE: 35.99%\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training STGCN\n",
            "------------------------------------------------------------\n",
            "  Early stopping at epoch 42\n",
            "  SUCCESS - Val Loss: 0.4649, Test SMAPE: 38.07%\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training STConv\n",
            "------------------------------------------------------------\n",
            "  Early stopping at epoch 47\n",
            "  SUCCESS - Val Loss: 0.4682, Test SMAPE: 37.77%\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training A3TGCN\n",
            "------------------------------------------------------------\n",
            "  Early stopping at epoch 29\n",
            "  SUCCESS - Val Loss: 0.5554, Test SMAPE: 43.14%\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training GConvLSTM\n",
            "------------------------------------------------------------\n",
            "  Early stopping at epoch 56\n",
            "  SUCCESS - Val Loss: 0.4454, Test SMAPE: 35.59%\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training MTGNN\n",
            "------------------------------------------------------------\n",
            "  Early stopping at epoch 21\n",
            "  SUCCESS - Val Loss: 0.4650, Test SMAPE: 36.59%\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training AGCRN\n",
            "------------------------------------------------------------\n",
            "  Early stopping at epoch 28\n",
            "  SUCCESS - Val Loss: 0.4572, Test SMAPE: 35.67%\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training GraphWaveNet\n",
            "------------------------------------------------------------\n",
            "  Early stopping at epoch 19\n",
            "  SUCCESS - Val Loss: 0.4466, Test SMAPE: 35.94%\n",
            "\n",
            "================================================================================\n",
            "HORIZON H=12\n",
            "================================================================================\n",
            "Building samples for horizon 12...\n",
            "Built 63 samples for horizon=12: X=(63, 12, 1811, 13), y=(63, 1, 1811, 1)\n",
            "Built 6 samples for horizon=12: X=(6, 12, 1811, 13), y=(6, 1, 1811, 1)\n",
            "Built 1 samples for horizon=12: X=(1, 12, 1811, 13), y=(1, 1, 1811, 1)\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training DCRNN\n",
            "------------------------------------------------------------\n",
            "  Early stopping at epoch 22\n",
            "  SUCCESS - Val Loss: 0.4765, Test SMAPE: 45.26%\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training STGCN\n",
            "------------------------------------------------------------\n",
            "  Early stopping at epoch 26\n",
            "  SUCCESS - Val Loss: 0.5031, Test SMAPE: 46.04%\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training STConv\n",
            "------------------------------------------------------------\n",
            "  Early stopping at epoch 23\n",
            "  SUCCESS - Val Loss: 0.5253, Test SMAPE: 48.60%\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training A3TGCN\n",
            "------------------------------------------------------------\n",
            "  Early stopping at epoch 34\n",
            "  SUCCESS - Val Loss: 0.6127, Test SMAPE: 50.67%\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training GConvLSTM\n",
            "------------------------------------------------------------\n",
            "  Early stopping at epoch 81\n",
            "  SUCCESS - Val Loss: 0.4916, Test SMAPE: 43.70%\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training MTGNN\n",
            "------------------------------------------------------------\n",
            "  Early stopping at epoch 14\n",
            "  SUCCESS - Val Loss: 0.5138, Test SMAPE: 44.75%\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training AGCRN\n",
            "------------------------------------------------------------\n",
            "  Early stopping at epoch 19\n",
            "  SUCCESS - Val Loss: 0.4957, Test SMAPE: 44.24%\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training GraphWaveNet\n",
            "------------------------------------------------------------\n",
            "  Early stopping at epoch 14\n",
            "  SUCCESS - Val Loss: 0.4796, Test SMAPE: 44.01%\n",
            "\n",
            "================================================================================\n",
            "RESULTS SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Model            Horizon       RMSE     SMAPE%   Status\n",
            "------------------------------------------------------------\n",
            "DCRNN                  1     1.3843      30.32       OK\n",
            "STGCN                  1     1.4296      31.97       OK\n",
            "STConv                 1     1.5438      33.51       OK\n",
            "A3TGCN                 1     1.8543      41.71       OK\n",
            "GConvLSTM              1     1.4094      30.58       OK\n",
            "MTGNN                  1     1.4385      31.89       OK\n",
            "AGCRN                  1     1.4323      31.38       OK\n",
            "GraphWaveNet           1     1.3979      30.49       OK\n",
            "DCRNN                  6     1.6402      35.99       OK\n",
            "STGCN                  6     1.7156      38.07       OK\n",
            "STConv                 6     1.7348      37.77       OK\n",
            "A3TGCN                 6     1.9571      43.14       OK\n",
            "GConvLSTM              6     1.6658      35.59       OK\n",
            "MTGNN                  6     1.6275      36.59       OK\n",
            "AGCRN                  6     1.6111      35.67       OK\n",
            "GraphWaveNet           6     1.6739      35.94       OK\n",
            "DCRNN                 12     1.8999      45.26       OK\n",
            "STGCN                 12     2.0210      46.04       OK\n",
            "STConv                12     2.1082      48.60       OK\n",
            "A3TGCN                12     2.0684      50.67       OK\n",
            "GConvLSTM             12     1.8480      43.70       OK\n",
            "MTGNN                 12     1.9083      44.75       OK\n",
            "AGCRN                 12     1.8204      44.24       OK\n",
            "GraphWaveNet          12     1.9132      44.01       OK\n",
            "\n",
            "✓ Results saved to local runtime: /content/metrics_gnn_models_v6.csv\n",
            "  Exported 24 result rows\n",
            "✓ Results saved to Google Drive: /content/drive/MyDrive/Colab Notebooks/master_thesis_gdrive/benchmarks/metrics_gnn_models_v6.csv\n",
            "\n",
            "CSV Preview:\n",
            " horizon           model_id exog_mode                 config      mse      mae     rmse     smape\n",
            "       1       gnn | A3TGCN     graph  h64_lr0.001_bs32_e100 3.438379 1.115333 1.854287 41.707989\n",
            "       1        gnn | AGCRN     graph  h64_lr0.001_bs16_e100 2.051350 0.805053 1.432254 31.380990\n",
            "       1        gnn | DCRNN     graph h128_lr0.001_bs16_e100 1.916186 0.777210 1.384264 30.323492\n",
            "       1    gnn | GConvLSTM     graph  h64_lr0.001_bs32_e100 1.986468 0.783157 1.409421 30.577839\n",
            "       1 gnn | GraphWaveNet     graph  h64_lr0.001_bs16_e100 1.954016 0.779068 1.397861 30.488511\n",
            "       1        gnn | MTGNN     graph  h32_lr0.001_bs16_e100 2.069147 0.822259 1.438453 31.894396\n",
            "       1       gnn | STConv     graph  h64_lr0.001_bs32_e100 2.383253 0.872278 1.543779 33.513735\n",
            "       1        gnn | STGCN     graph  h64_lr0.001_bs32_e100 2.043619 0.814814 1.429552 31.966835\n",
            "       6       gnn | A3TGCN     graph  h64_lr0.001_bs32_e100 3.830390 1.165976 1.957138 43.135564\n",
            "       6        gnn | AGCRN     graph  h64_lr0.001_bs16_e100 2.595740 0.924238 1.611130 35.673786\n",
            "\n",
            "Experiment Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing MTGNN with given graph semantic"
      ],
      "metadata": {
        "id": "fARPKX2PdI1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# EXTRA EXPERIMENT: MTGNN WITH SEMANTIC GRAPH (SAVE TENSORS ONLY)\n",
        "# =============================================================================\n",
        "import copy\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"EXTRA RUN: MTGNN (semantic feature set) - SAVE TENSORS ONLY\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "mtgnn_results = {}\n",
        "horizons = EXPERIMENT_CONFIG[\"horizons\"]\n",
        "seq_len = EXPERIMENT_CONFIG[\"sequence_length\"]\n",
        "\n",
        "# Create dedicated tensor folder\n",
        "MTGNN_TENSOR_FOLDER = \"/content/MTGNN_semantic_tensors\"\n",
        "os.makedirs(MTGNN_TENSOR_FOLDER, exist_ok=True)\n",
        "print(f\"Tensors will be saved into: {MTGNN_TENSOR_FOLDER}\")\n",
        "\n",
        "# Only MTGNN runs here\n",
        "model_name = \"MTGNN\"\n",
        "mtgnn_epochs = BASE_MODEL_CONFIGS[model_name][\"training\"][\"epochs\"]\n",
        "total_epochs_mtgnn = mtgnn_epochs * len(horizons)\n",
        "\n",
        "with tqdm(total=total_epochs_mtgnn, unit=\"epoch\", desc=\"MTGNN-semantic\") as pbar:\n",
        "    for H in horizons:\n",
        "        tqdm.write(f\"\\n{'=' * 80}\")\n",
        "        tqdm.write(f\"MTGNN SEMANTIC - HORIZON H={H}\")\n",
        "        tqdm.write(f\"{'=' * 80}\")\n",
        "\n",
        "        # Build samples\n",
        "        Xtr_np, ytr_np = build_optionA_samples(\n",
        "            X_train_scaled, train_weeks, H, seq_len, target_col_idx\n",
        "        )\n",
        "        Xval_np, yval_np = build_optionA_samples(\n",
        "            X_val_scaled, val_weeks, H, seq_len, target_col_idx\n",
        "        )\n",
        "        Xte_np, yte_np = build_optionA_samples(\n",
        "            X_test_scaled, test_combined_weeks, H, seq_len, target_col_idx\n",
        "        )\n",
        "\n",
        "        # Skip if not enough samples\n",
        "        if Xtr_np.shape[0] == 0:\n",
        "            tqdm.write(f\"Skipping H={H}: insufficient data\")\n",
        "            pbar.update(mtgnn_epochs)\n",
        "            continue\n",
        "\n",
        "        # Convert to torch\n",
        "        Xtr, ytr = to_torch_dataset(Xtr_np, ytr_np, device)\n",
        "        Xval, yval = to_torch_dataset(Xval_np, yval_np, device)\n",
        "        Xte, yte = to_torch_dataset(Xte_np, yte_np, device)\n",
        "\n",
        "        try:\n",
        "            tqdm.write(f\"Training MTGNN...\")\n",
        "            train_result = train_one_model_optionA(\n",
        "                model_name,\n",
        "                BASE_MODEL_CONFIGS,\n",
        "                EXPERIMENT_CONFIG,\n",
        "                Xtr, ytr, Xval, yval,\n",
        "                edge_index_tensor, edge_weight_tensor,  # passed but ignored by MTGNN\n",
        "                device=device,\n",
        "                verbose=True,\n",
        "                pbar=pbar\n",
        "            )\n",
        "\n",
        "            # Evaluate\n",
        "            test_metrics, test_tensors = evaluate_model_optionA(\n",
        "                train_result[\"model\"],\n",
        "                model_name,\n",
        "                Xte, yte,\n",
        "                edge_index_tensor, edge_weight_tensor,\n",
        "                scaler=scaler,\n",
        "                target_col_idx=target_col_idx,\n",
        "                return_tensors=True,\n",
        "            )\n",
        "\n",
        "            mtgnn_results[H] = {\n",
        "                \"RMSE\": test_metrics[\"RMSE\"],\n",
        "                \"SMAPE\": test_metrics[\"SMAPE\"],\n",
        "                \"VAL_LOSS\": train_result[\"best_val_loss\"]\n",
        "            }\n",
        "\n",
        "            tqdm.write(\n",
        "                f\"SUCCESS H={H} | RMSE={test_metrics['RMSE']:.4f} | SMAPE={test_metrics['SMAPE']:.2f}%\"\n",
        "            )\n",
        "\n",
        "            # ============================================================\n",
        "            # SAVE ONLY TENSORS INTO MTGNN_semantic_tensors/\n",
        "            # ============================================================\n",
        "            torch.save(\n",
        "                test_tensors[\"predictions\"],\n",
        "                f\"{MTGNN_TENSOR_FOLDER}/MTGNN_h{H}_predictions.pt\"\n",
        "            )\n",
        "            torch.save(\n",
        "                test_tensors[\"targets\"],\n",
        "                f\"{MTGNN_TENSOR_FOLDER}/MTGNN_h{H}_targets.pt\"\n",
        "            )\n",
        "            torch.save(\n",
        "                test_tensors[\"inputs\"],\n",
        "                f\"{MTGNN_TENSOR_FOLDER}/MTGNN_h{H}_inputs.pt\"\n",
        "            )\n",
        "            torch.save(\n",
        "                test_tensors[\"errors\"],\n",
        "                f\"{MTGNN_TENSOR_FOLDER}/MTGNN_h{H}_errors.pt\"\n",
        "            )\n",
        "\n",
        "            tqdm.write(f\"Tensors saved for H={H}.\")\n",
        "\n",
        "            # Cleanup GPU memory\n",
        "            del train_result[\"model\"]\n",
        "            gc.collect()\n",
        "            if device == \"cuda\":\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        except Exception as e:\n",
        "            tqdm.write(f\"MTGNN FAILED for H={H} — {str(e)[:200]}\")\n",
        "            mtgnn_results[H] = {\"ERROR\": str(e)}\n",
        "\n",
        "            gc.collect()\n",
        "            if device == \"cuda\":\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "# Final summary printout\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"MTGNN SEMANTIC RESULTS SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "for H, r in mtgnn_results.items():\n",
        "    print(f\"H={H}: {r}\")\n",
        "print(\"\\nAll tensors saved to MTGNN_semantic_tensors/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 893,
          "referenced_widgets": [
            "960fb7fdadb84671ad4fb32439e3ff3d",
            "0a32a87bdb964016985114bc30b59406",
            "5a3d815de45445f7bf0441835b4ba74e",
            "4743983a59af437c9c97590228ffd120",
            "a9ab538466c24472b2048c73edc2357f",
            "8ec38ba5e009436abaaa5bdb6bba5b04",
            "cfe42ededf0648a381a0c91685ffe0b1",
            "b4c330934f4849ebb399316b357ddb0b",
            "2227d1580e7748978071cb83fa586cec",
            "0a7c9eb5da1646f2b7f4006e2696d23c",
            "b9eaac4044c84470a9793c68babfac8b"
          ]
        },
        "id": "5VW0r6STdVTl",
        "outputId": "d19ebc6f-0575-4f86-f00d-e220f19475b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "EXTRA RUN: MTGNN (semantic feature set) - SAVE TENSORS ONLY\n",
            "================================================================================\n",
            "Tensors will be saved into: /content/MTGNN_semantic_tensors\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "MTGNN-semantic:   0%|          | 0/300 [00:00<?, ?epoch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "960fb7fdadb84671ad4fb32439e3ff3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "MTGNN SEMANTIC - HORIZON H=1\n",
            "================================================================================\n",
            "Built 74 samples for horizon=1: X=(74, 12, 1811, 13), y=(74, 1, 1811, 1)\n",
            "Built 17 samples for horizon=1: X=(17, 12, 1811, 13), y=(17, 1, 1811, 1)\n",
            "Built 12 samples for horizon=1: X=(12, 12, 1811, 13), y=(12, 1, 1811, 1)\n",
            "Training MTGNN...\n",
            "  Early stopping at epoch 18\n",
            "SUCCESS H=1 | RMSE=1.4097 | SMAPE=31.81%\n",
            "Tensors saved for H=1.\n",
            "\n",
            "================================================================================\n",
            "MTGNN SEMANTIC - HORIZON H=6\n",
            "================================================================================\n",
            "Built 69 samples for horizon=6: X=(69, 12, 1811, 13), y=(69, 1, 1811, 1)\n",
            "Built 12 samples for horizon=6: X=(12, 12, 1811, 13), y=(12, 1, 1811, 1)\n",
            "Built 7 samples for horizon=6: X=(7, 12, 1811, 13), y=(7, 1, 1811, 1)\n",
            "Training MTGNN...\n",
            "  Early stopping at epoch 21\n",
            "SUCCESS H=6 | RMSE=1.6375 | SMAPE=36.45%\n",
            "Tensors saved for H=6.\n",
            "\n",
            "================================================================================\n",
            "MTGNN SEMANTIC - HORIZON H=12\n",
            "================================================================================\n",
            "Built 63 samples for horizon=12: X=(63, 12, 1811, 13), y=(63, 1, 1811, 1)\n",
            "Built 6 samples for horizon=12: X=(6, 12, 1811, 13), y=(6, 1, 1811, 1)\n",
            "Built 1 samples for horizon=12: X=(1, 12, 1811, 13), y=(1, 1, 1811, 1)\n",
            "Training MTGNN...\n",
            "  Early stopping at epoch 13\n",
            "SUCCESS H=12 | RMSE=2.0444 | SMAPE=47.39%\n",
            "Tensors saved for H=12.\n",
            "\n",
            "================================================================================\n",
            "MTGNN SEMANTIC RESULTS SUMMARY\n",
            "================================================================================\n",
            "H=1: {'RMSE': 1.4097239360478007, 'SMAPE': 31.812452862058578, 'VAL_LOSS': 0.37849298119544983}\n",
            "H=6: {'RMSE': 1.6375486903846836, 'SMAPE': 36.45349436156569, 'VAL_LOSS': 0.4606213867664337}\n",
            "H=12: {'RMSE': 2.0443573708085165, 'SMAPE': 47.392723775835435, 'VAL_LOSS': 0.4884673058986664}\n",
            "\n",
            "All tensors saved to MTGNN_semantic_tensors/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpJVHtMWsRYC"
      },
      "source": [
        "# Single Model/Horizon Testing\n",
        "\n",
        "Use this cell to test individual models for specific horizons without running the full experiment.\n",
        "\n",
        "**Instructions:**\n",
        "1. Set `TEST_MODEL_NAME` to one of: 'DCRNN', 'STGCN', 'STConv', 'A3TGCN', 'GConvLSTM', 'MTGNN', 'AGCRN', 'GraphWaveNet'\n",
        "2. Set `TEST_HORIZON` to one of: 1, 6, 12\n",
        "3. Run this cell independently (it will reload data if needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxk4kFBxsRYC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "outputId": "293d26ae-3199-470f-bfa8-dfe4512f22fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "SINGLE MODEL TEST: STGCN at Horizon H=1\n",
            "================================================================================\n",
            "\n",
            "✓ Data already loaded from previous cells\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Building samples for H=1...\n",
            "--------------------------------------------------------------------------------\n",
            "Built 74 samples for horizon=1: X=(74, 12, 1811, 13), y=(74, 1, 1811, 1)\n",
            "Built 17 samples for horizon=1: X=(17, 12, 1811, 13), y=(17, 1, 1811, 1)\n",
            "Built 12 samples for horizon=1: X=(12, 12, 1811, 13), y=(12, 1, 1811, 1)\n",
            "\n",
            "Data shapes:\n",
            "  Train: X=torch.Size([74, 12, 1811, 13]), y=torch.Size([74, 1, 1811, 1])\n",
            "  Val:   X=torch.Size([17, 12, 1811, 13]), y=torch.Size([17, 1, 1811, 1])\n",
            "  Test:  X=torch.Size([12, 12, 1811, 13]), y=torch.Size([12, 1, 1811, 1])\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Training STGCN...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "  Epoch 10/100 - Train: 0.4543, Val: 0.4467\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3102505495.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     train_result = train_one_model_optionA(\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mTEST_MODEL_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mBASE_MODEL_CONFIGS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2115133032.py\u001b[0m in \u001b[0;36mtrain_one_model_optionA\u001b[0;34m(model_name, model_configs, experiment_cfg, X_train, y_train, X_val, y_val, edge_index, edge_weight, device, verbose, pbar)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mavg_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrain_losses\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CONFIGURATION - Edit these variables\n",
        "# ============================================================================\n",
        "TEST_MODEL_NAME = \"STGCN\"  # Choose: 'DCRNN', 'STGCN', 'STConv', 'A3TGCN',\n",
        "                           # 'GConvLSTM', 'MTGNN', 'AGCRN', 'GraphWaveNet'\n",
        "TEST_HORIZON = 1           # Choose: 1, 6, or 12\n",
        "\n",
        "# ============================================================================\n",
        "# Automatic data loading (runs if data not already loaded)\n",
        "# ============================================================================\n",
        "import warnings\n",
        "import gc\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(f\"SINGLE MODEL TEST: {TEST_MODEL_NAME} at Horizon H={TEST_HORIZON}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Check if data is already loaded\n",
        "try:\n",
        "    _ = edge_index_tensor\n",
        "    _ = edge_weight_tensor\n",
        "    _ = df\n",
        "    _ = keyword_map\n",
        "    print(\"\\n✓ Data already loaded from previous cells\")\n",
        "except NameError:\n",
        "    print(\"\\n⚠ Data not loaded. Loading data now...\")\n",
        "\n",
        "    # Device selection\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Load data\n",
        "    edge_index, edge_weight, keyword_map, df = load_graph_and_data(\n",
        "        GRAPH_FOLDER_PATH,\n",
        "        TIME_SERIES_CSV_PATH,\n",
        "    )\n",
        "\n",
        "    # Convert to tensors\n",
        "    edge_index_tensor = torch.from_numpy(edge_index).long().to(device)\n",
        "    edge_weight_tensor = torch.from_numpy(edge_weight).float().to(device)\n",
        "\n",
        "    # Build week splits\n",
        "    trainval_weeks, test_weeks = build_week_splits(\n",
        "        df,\n",
        "        EXPERIMENT_CONFIG[\"test_weeks_last\"],\n",
        "    )\n",
        "\n",
        "    val_ratio = EXPERIMENT_CONFIG[\"val_split_ratio\"]\n",
        "    split_idx = int(len(trainval_weeks) * (1 - val_ratio))\n",
        "\n",
        "    train_weeks = trainval_weeks[:split_idx]\n",
        "    val_weeks = trainval_weeks[split_idx:]\n",
        "\n",
        "    # Filter features\n",
        "    available_features = [col for col in FEATURE_COLS if col in df.columns]\n",
        "\n",
        "    # Build feature tensors\n",
        "    X_train_raw = build_feature_tensor(df, keyword_map, train_weeks, available_features)\n",
        "    X_val_raw = build_feature_tensor(df, keyword_map, val_weeks, available_features)\n",
        "\n",
        "    # Build test tensor with sliding window\n",
        "    seq_len = EXPERIMENT_CONFIG[\"sequence_length\"]\n",
        "    all_weeks = np.concatenate([train_weeks, val_weeks, test_weeks])\n",
        "    test_start_idx = len(train_weeks) + len(val_weeks)\n",
        "    test_window_start = max(0, test_start_idx - seq_len)\n",
        "    test_combined_weeks = all_weeks[test_window_start:]\n",
        "\n",
        "    X_test_raw = build_feature_tensor(\n",
        "        df,\n",
        "        keyword_map,\n",
        "        test_combined_weeks,\n",
        "        available_features,\n",
        "    )\n",
        "\n",
        "    # Scale features\n",
        "    target_col_idx = available_features.index(TARGET_COL)\n",
        "    X_train_scaled, X_val_scaled, X_test_scaled, scaler = scale_features(\n",
        "        X_train_raw,\n",
        "        X_val_raw,\n",
        "        X_test_raw,\n",
        "        EXPERIMENT_CONFIG[\"scaling\"],\n",
        "        target_col_idx=target_col_idx,\n",
        "    )\n",
        "\n",
        "\n",
        "    print(\"✓ Data loaded successfully\")\n",
        "\n",
        "# Ensure device is set\n",
        "try:\n",
        "    _ = device\n",
        "except NameError:\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"\\nUsing device: {device}\")\n",
        "\n",
        "# ============================================================================\n",
        "# Build samples for the specified horizon\n",
        "# ============================================================================\n",
        "print(f\"\\n{'-' * 80}\")\n",
        "print(f\"Building samples for H={TEST_HORIZON}...\")\n",
        "print(f\"{'-' * 80}\")\n",
        "\n",
        "H = TEST_HORIZON\n",
        "seq_len = EXPERIMENT_CONFIG[\"sequence_length\"]\n",
        "\n",
        "Xtr_np, ytr_np = build_optionA_samples(\n",
        "    X_train_scaled,\n",
        "    train_weeks,\n",
        "    H,\n",
        "    seq_len,\n",
        "    target_col_idx,\n",
        ")\n",
        "Xval_np, yval_np = build_optionA_samples(\n",
        "    X_val_scaled,\n",
        "    val_weeks,\n",
        "    H,\n",
        "    seq_len,\n",
        "    target_col_idx,\n",
        ")\n",
        "Xte_np, yte_np = build_optionA_samples(\n",
        "    X_test_scaled,\n",
        "    test_combined_weeks,\n",
        "    H,\n",
        "    seq_len,\n",
        "    target_col_idx,\n",
        ")\n",
        "\n",
        "# Convert to torch\n",
        "Xtr, ytr = to_torch_dataset(Xtr_np, ytr_np, device)\n",
        "Xval, yval = to_torch_dataset(Xval_np, yval_np, device)\n",
        "Xte, yte = to_torch_dataset(Xte_np, yte_np, device)\n",
        "\n",
        "print(\"\\nData shapes:\")\n",
        "print(f\"  Train: X={Xtr.shape}, y={ytr.shape}\")\n",
        "print(f\"  Val:   X={Xval.shape}, y={yval.shape}\")\n",
        "print(f\"  Test:  X={Xte.shape}, y={yte.shape}\")\n",
        "\n",
        "# ============================================================================\n",
        "# Train and evaluate the specified model\n",
        "# ============================================================================\n",
        "print(f\"\\n{'-' * 80}\")\n",
        "print(f\"Training {TEST_MODEL_NAME}...\")\n",
        "print(f\"{'-' * 80}\\n\")\n",
        "\n",
        "try:\n",
        "    # Train model\n",
        "    train_result = train_one_model_optionA(\n",
        "        TEST_MODEL_NAME,\n",
        "        BASE_MODEL_CONFIGS,\n",
        "        EXPERIMENT_CONFIG,\n",
        "        Xtr,\n",
        "        ytr,\n",
        "        Xval,\n",
        "        yval,\n",
        "        edge_index_tensor,\n",
        "        edge_weight_tensor,\n",
        "        device=device,\n",
        "        verbose=True,\n",
        "    )\n",
        "\n",
        "    print(f\"\\n{'-' * 80}\")\n",
        "    print(\"Training complete! Evaluating on test set...\")\n",
        "    print(f\"{'-' * 80}\\n\")\n",
        "\n",
        "    # Evaluate on test - now returns tuple\n",
        "    test_metrics, test_tensors = evaluate_model_optionA(\n",
        "        train_result[\"model\"],\n",
        "        TEST_MODEL_NAME,\n",
        "        Xte,\n",
        "        yte,\n",
        "        edge_index_tensor,\n",
        "        edge_weight_tensor,\n",
        "        scaler = scaler,\n",
        "        target_col_idx = target_col_idx,\n",
        "        return_tensors=True,\n",
        "    )\n",
        "\n",
        "    # Print results\n",
        "    print(\"=\" * 80)\n",
        "    print(\"RESULTS\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"\\nModel: {TEST_MODEL_NAME}\")\n",
        "    print(f\"Horizon: {TEST_HORIZON}\")\n",
        "\n",
        "    print(\"\\nTraining:\")\n",
        "    print(f\"  - Best Validation Loss: {train_result['best_val_loss']:.6f}\")\n",
        "    print(f\"  - Epochs Trained: {train_result['epochs_trained']}\")\n",
        "\n",
        "    print(\"\\nTest Set Performance:\")\n",
        "    print(f\"  - MSE:   {test_metrics['MSE']:.6f}\")\n",
        "    print(f\"  - MAE:   {test_metrics['MAE']:.6f}\")\n",
        "    print(f\"  - RMSE:  {test_metrics['RMSE']:.6f}\")\n",
        "    print(f\"  - SMAPE: {test_metrics['SMAPE']:.2f}%\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"✓ Test completed successfully!\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Save tensors for this single test\n",
        "    print(\"\\nSaving tensors...\")\n",
        "    save_model_tensors(\n",
        "        test_tensors,\n",
        "        TEST_MODEL_NAME,\n",
        "        TEST_HORIZON,\n",
        "        EXPERIMENT_CONFIG,\n",
        "        verbose=True,\n",
        "    )\n",
        "\n",
        "    # Clean up GPU memory\n",
        "    del train_result\n",
        "    del test_tensors\n",
        "    gc.collect()\n",
        "\n",
        "    if device == \"cuda\":\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"\\nGPU memory cleared\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"=\" * 80)\n",
        "    print(\"✗ FAILED\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"\\nError: {str(e)}\")\n",
        "    print(\"\\nFull traceback:\")\n",
        "    import traceback\n",
        "\n",
        "    traceback.print_exc()\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Clean up even on failure\n",
        "    gc.collect()\n",
        "    if device == \"cuda\":\n",
        "        torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyper-parameter tuning"
      ],
      "metadata": {
        "id": "NVeKqFkdce_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# HYPERPARAMETER TUNING SETUP (With Memory Cleanup, CPU datasets)\n",
        "# =============================================================================\n",
        "\n",
        "import time\n",
        "import random\n",
        "import copy\n",
        "import gc\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from itertools import product\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# 1. Define the specific models to tune per horizon\n",
        "# we do not tune AGCRN because of GPU memory requirements\n",
        "TOP_MODELS_BY_HORIZON = {\n",
        "    1:  ['DCRNN', 'GConvLSTM', 'GraphWaveNet'],\n",
        "    6:  ['DCRNN', 'GConvLSTM', 'GraphWaveNet'],\n",
        "    12:  ['DCRNN', 'GConvLSTM', 'GraphWaveNet'],\n",
        "}\n",
        "\n",
        "# 2. Hyperparameter search space\n",
        "PARAM_GRIDS = {\n",
        "    # ============================================================\n",
        "    # 1) DCRNN — best so far: hidden_channels=96, k_hops=2, lr=0.003\n",
        "    # ============================================================\n",
        "    \"DCRNN\": {\n",
        "        # Centered around 96, but still lets you see if a bit smaller is enough\n",
        "        \"hidden_channels\": [64, 96, 128],\n",
        "        # Best was 2; 3 is a reasonable nearby alternative\n",
        "        \"k_hops\": [2, 3],\n",
        "        # 0.003 was best; 0.001 is a safer/slower alternative\n",
        "        \"learning_rate\": [0.003, 0.001],\n",
        "    },\n",
        "\n",
        "    # ============================================================\n",
        "    # 2) GConvLSTM — best so far: hidden_size=64, K=2, lr=0.01\n",
        "    # ============================================================\n",
        "    \"GConvLSTM\": {\n",
        "        # Best at 64; 32 tests a lighter model, 96 a slightly larger one\n",
        "        \"hidden_size\": [32, 64, 96],\n",
        "        # Best at 2; 3 lets you test slightly larger spatial receptive field\n",
        "        \"K\": [2, 3],\n",
        "        # 0.01 was best; 0.003 is a classic “slower but safer” option\n",
        "        \"learning_rate\": [0.01, 0.003],\n",
        "    },\n",
        "\n",
        "    # ============================================================\n",
        "    # 3) GraphWaveNet — best so far: hidden_size=32, dropout=0.5, lr=0.01\n",
        "    # ============================================================\n",
        "    \"GraphWaveNet\": {\n",
        "        # Best at 32; 48 gives a bit more capacity without going huge\n",
        "        \"hidden_size\": [32, 48],\n",
        "        # 0.5 worked well; 0.3 is a reasonable nearby alternative\n",
        "        \"dropout\": [0.3, 0.5],\n",
        "        # Same reasoning as GConvLSTM\n",
        "        \"learning_rate\": [0.01, 0.003],\n",
        "    },\n",
        "\n",
        "    # ============================================================\n",
        "    # 4) (OPTIONAL) AGCRN — lighter config to avoid OOM\n",
        "    #    Only if you decide to include it later.\n",
        "    # ============================================================\n",
        "    \"AGCRN\": {\n",
        "        # Keep this small: 16–32 is much safer with 1811 nodes\n",
        "        \"hidden_size\": [16, 32],\n",
        "        # 1–2 layers max — deeper gets expensive fast\n",
        "        \"n_layers\": [1, 2],\n",
        "        # Same lr logic\n",
        "        \"learning_rate\": [0.01, 0.003],\n",
        "    },\n",
        "}\n",
        "\n",
        "N_TRIALS = 8\n",
        "TUNING_EPOCHS = 15\n",
        "\n",
        "# =============================================================================\n",
        "# SAMPLING FROM GRID\n",
        "# =============================================================================\n",
        "\n",
        "def sample_config(model_name):\n",
        "    grid = PARAM_GRIDS[model_name]\n",
        "    config = {}\n",
        "    for key, values in grid.items():\n",
        "        config[key] = random.choice(values)\n",
        "    return config\n",
        "\n",
        "# =============================================================================\n",
        "# TUNING FUNCTION (Accepts global progress bar)\n",
        "# =============================================================================\n",
        "\n",
        "def train_tuning_model(model_name, params, X_tr, y_tr, X_val, y_val,\n",
        "                       edge_idx, edge_wt, device, pbar=None):\n",
        "    \"\"\"\n",
        "    Train model with L1 Loss and update global progress bar.\n",
        "    Returns: model, best_val_loss, epochs_run\n",
        "    NOTE: X_tr, y_tr, X_val, y_val are on CPU.\n",
        "    \"\"\"\n",
        "    full_config = copy.deepcopy(BASE_MODEL_CONFIGS)\n",
        "\n",
        "    # Inject hyperparameters into config\n",
        "    for k, v in params.items():\n",
        "        if k == 'learning_rate':\n",
        "            full_config[model_name]['training'][k] = v\n",
        "        elif k == 'weight_decay':\n",
        "            # used only in optimizer, do NOT pass into model __init__\n",
        "            continue\n",
        "        else:\n",
        "            full_config[model_name]['params'][k] = v\n",
        "\n",
        "    # Instantiate model on device\n",
        "    model = get_model(model_name, full_config, device=device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model.parameters(),\n",
        "        lr=params.get('learning_rate', 0.001),\n",
        "        weight_decay=params.get('weight_decay', 0.0)\n",
        "    )\n",
        "    criterion = nn.L1Loss()  # Train on MAE\n",
        "\n",
        "    # Optimized batch confing\n",
        "    if model_name in [\"AGCRN\"]:\n",
        "        batch_size = 4\n",
        "    elif model_name in [\"DCRNN\", \"GConvLSTM\", \"MTGNN\"]:\n",
        "        batch_size = 8\n",
        "    elif model_name in [\"GraphWaveNet\"]:\n",
        "        batch_size = 16\n",
        "    else:\n",
        "        batch_size = 8\n",
        "\n",
        "\n",
        "    train_loader = make_dataloader(X_tr, y_tr, batch_size, shuffle=True)\n",
        "    val_loader   = make_dataloader(X_val, y_val, batch_size, shuffle=False)\n",
        "\n",
        "    no_edge_models = [\"AGCRN\"]\n",
        "    best_val_loss = float(\"inf\")\n",
        "    patience = 5\n",
        "    no_improve = 0\n",
        "    epochs_run = 0\n",
        "\n",
        "    for epoch in range(TUNING_EPOCHS):\n",
        "        # -------------------------\n",
        "        # Train\n",
        "        # -------------------------\n",
        "        model.train()\n",
        "        for Xb, yb in train_loader:\n",
        "            Xb = Xb.to(device, non_blocking=True)\n",
        "            yb = yb.to(device, non_blocking=True)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            if model_name == \"DCRNN\":\n",
        "                output = forward_dcrnn_optionA(model, Xb, edge_idx, edge_wt)\n",
        "            elif model_name in no_edge_models:\n",
        "                out = model(Xb)\n",
        "                output = ensure_B1N1(out)\n",
        "            else:\n",
        "                output = model(Xb, edge_idx, edge_wt)\n",
        "\n",
        "            loss = criterion(output, yb)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "            optimizer.step()\n",
        "\n",
        "        # -------------------------\n",
        "        # Validation\n",
        "        # -------------------------\n",
        "        model.eval()\n",
        "        val_losses = []\n",
        "        with torch.no_grad():\n",
        "            for Xb, yb in val_loader:\n",
        "                Xb = Xb.to(device, non_blocking=True)\n",
        "                yb = yb.to(device, non_blocking=True)\n",
        "\n",
        "                if model_name == \"DCRNN\":\n",
        "                    output = forward_dcrnn_optionA(model, Xb, edge_idx, edge_wt)\n",
        "                elif model_name in no_edge_models:\n",
        "                    out = model(Xb)\n",
        "                    output = ensure_B1N1(out)\n",
        "                else:\n",
        "                    output = model(Xb, edge_idx, edge_wt)\n",
        "\n",
        "                val_losses.append(criterion(output, yb).item())\n",
        "\n",
        "        avg_val = np.mean(val_losses)\n",
        "\n",
        "        # Update global progress bar (real epochs only)\n",
        "        if pbar:\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix(mae=f\"{avg_val:.4f}\")\n",
        "\n",
        "        epochs_run += 1\n",
        "\n",
        "        # Early stopping\n",
        "        if avg_val < best_val_loss:\n",
        "            best_val_loss = avg_val\n",
        "            no_improve = 0\n",
        "        else:\n",
        "            no_improve += 1\n",
        "            if no_improve >= patience:\n",
        "                break\n",
        "\n",
        "    return model, best_val_loss, epochs_run\n",
        "\n",
        "# =============================================================================\n",
        "# RUNNING THE SEARCH\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "tuning_results = []\n",
        "horizons = [1] # only tune on short horizon old was: EXPERIMENT_CONFIG['horizons']\n",
        "\n",
        "# Calculate total steps for the progress bar (upper bound)\n",
        "total_models = sum(len(TOP_MODELS_BY_HORIZON[h]) for h in horizons)\n",
        "total_steps = total_models * N_TRIALS * TUNING_EPOCHS\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(f\"STARTING TUNING (Max Epochs: {total_steps})\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "with tqdm(total=total_steps, unit=\"epoch\") as pbar:\n",
        "    for H in horizons:\n",
        "        # Prepare Data for this horizon (CPU tensors)\n",
        "        seq_len = EXPERIMENT_CONFIG[\"sequence_length\"]\n",
        "        Xtr_np, ytr_np = build_optionA_samples(\n",
        "            X_train_scaled, train_weeks, H, seq_len, target_col_idx\n",
        "        )\n",
        "        Xtr, ytr = to_torch_dataset(Xtr_np, ytr_np, device=\"cpu\")\n",
        "\n",
        "        Xval_np, yval_np = build_optionA_samples(\n",
        "            X_val_scaled, val_weeks, H, seq_len, target_col_idx\n",
        "        )\n",
        "        Xval, yval = to_torch_dataset(Xval_np, yval_np, device=\"cpu\")\n",
        "\n",
        "        for model_name in TOP_MODELS_BY_HORIZON[H]:\n",
        "            best_val_mae_for_model = float('inf')\n",
        "            best_params_for_model = None\n",
        "            best_epochs_for_model = None\n",
        "            best_time_for_model = None\n",
        "\n",
        "            for trial in range(N_TRIALS):\n",
        "                pbar.set_description(f\"H={H} | {model_name} | Trial {trial+1}/{N_TRIALS}\")\n",
        "                params = sample_config(model_name)\n",
        "\n",
        "                try:\n",
        "                    t0 = time.time()\n",
        "                    model, val_mae, epochs_run = train_tuning_model(\n",
        "                        model_name, params,\n",
        "                        Xtr, ytr, Xval, yval,\n",
        "                        edge_index_tensor, edge_weight_tensor,\n",
        "                        device,\n",
        "                        pbar=pbar\n",
        "                    )\n",
        "                    t1 = time.time()\n",
        "                    elapsed = t1 - t0\n",
        "                    avg_sec_per_epoch = elapsed / max(epochs_run, 1)\n",
        "\n",
        "                    tqdm.write(\n",
        "                        f\"H={H} | {model_name:<10} | Trial {trial+1}/{N_TRIALS} \"\n",
        "                        f\"| stopped at epoch {epochs_run:2d} \"\n",
        "                        f\"| VAL MAE={val_mae:.4f} \"\n",
        "                        f\"| {elapsed:.1f}s total (~{avg_sec_per_epoch:.2f}s/epoch)\"\n",
        "                    )\n",
        "\n",
        "                    # Select by best validation MAE\n",
        "                    if val_mae < best_val_mae_for_model:\n",
        "                        best_val_mae_for_model = val_mae\n",
        "                        best_params_for_model = params\n",
        "                        best_epochs_for_model = epochs_run\n",
        "                        best_time_for_model = elapsed\n",
        "\n",
        "                    # Cleanup after successful trial\n",
        "                    del model\n",
        "                    gc.collect()\n",
        "                    if device == \"cuda\":\n",
        "                        torch.cuda.empty_cache()\n",
        "\n",
        "                except Exception as e:\n",
        "                    tqdm.write(f\"H={H} | {model_name} | Trial {trial+1}: FAILED ({e})\")\n",
        "                    # Best effort cleanup\n",
        "                    if 'model' in locals():\n",
        "                        del model\n",
        "                    gc.collect()\n",
        "                    if device == \"cuda\":\n",
        "                        torch.cuda.empty_cache()\n",
        "\n",
        "            tqdm.write(\n",
        "                f\"[SUMMARY] H={H} | {model_name:<10} \"\n",
        "                f\"| Best VAL MAE={best_val_mae_for_model:.4f} \"\n",
        "                f\"| epochs={best_epochs_for_model} \"\n",
        "                f\"| time={best_time_for_model:.1f}s\"\n",
        "            )\n",
        "\n",
        "            tuning_results.append({\n",
        "                'horizon': H,\n",
        "                'model': model_name,\n",
        "                'best_params': best_params_for_model,\n",
        "                'best_val_mae': best_val_mae_for_model,\n",
        "                'best_epochs': best_epochs_for_model,\n",
        "                'best_time_sec': best_time_for_model,\n",
        "            })\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TUNING COMPLETE. BEST CONFIGURATIONS:\")\n",
        "for res in tuning_results:\n",
        "    print(\n",
        "        f\"H={res['horizon']} | {res['model']:<10} \"\n",
        "        f\"| VAL MAE={res['best_val_mae']:.4f} \"\n",
        "        f\"| epochs={res['best_epochs']} \"\n",
        "        f\"| time={res['best_time_sec']:.1f}s \"\n",
        "        f\"| {res['best_params']}\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757,
          "referenced_widgets": [
            "397998d761a645ffabb504d9d7183531",
            "c41fd8e9bb4f45c8bd2145b6612f5bbb",
            "f33a71aab77c470ab866fa7d1dfc6350",
            "61e12e4cc34348609f1dd982a0e9fdbd",
            "35bf5b09d747453bae968e0b607acdd7",
            "5111b963b30d474b8df9d195e41c924f",
            "2bf4366bb4bd4ee39eda560b6af333c9",
            "59e33131d1994dbdb807a53df409b466",
            "b9eaa669ab1643fcbfb5b9ffd2f26375",
            "3ae9d9d8ac2349c6837838dab21a5247",
            "e32c47b1274a40f19e5a39188100629b"
          ]
        },
        "id": "vnFxR1sKcfQf",
        "outputId": "b27fcaae-4703-4f64-8bab-c1ae62071d5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "STARTING TUNING (Max Epochs: 360)\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "397998d761a645ffabb504d9d7183531",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/360 [00:00<?, ?epoch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built 74 samples for horizon=1: X=(74, 12, 1811, 9), y=(74, 1, 1811, 1)\n",
            "Built 17 samples for horizon=1: X=(17, 12, 1811, 9), y=(17, 1, 1811, 1)\n",
            "H=1 | DCRNN      | Trial 1/8 | stopped at epoch 15 | VAL MAE=0.3789 | 247.8s total (~16.52s/epoch)\n",
            "H=1 | DCRNN      | Trial 2/8 | stopped at epoch 15 | VAL MAE=0.3808 | 247.4s total (~16.49s/epoch)\n",
            "H=1 | DCRNN      | Trial 3/8 | stopped at epoch 15 | VAL MAE=0.3831 | 247.1s total (~16.47s/epoch)\n",
            "H=1 | DCRNN      | Trial 4/8 | stopped at epoch 15 | VAL MAE=0.3816 | 247.2s total (~16.48s/epoch)\n",
            "H=1 | DCRNN      | Trial 5/8 | stopped at epoch 15 | VAL MAE=0.3796 | 247.8s total (~16.52s/epoch)\n",
            "H=1 | DCRNN      | Trial 6/8 | stopped at epoch 15 | VAL MAE=0.3806 | 350.7s total (~23.38s/epoch)\n",
            "H=1 | DCRNN      | Trial 7/8 | stopped at epoch 15 | VAL MAE=0.3787 | 247.5s total (~16.50s/epoch)\n",
            "H=1 | DCRNN      | Trial 8/8 | stopped at epoch 15 | VAL MAE=0.3778 | 246.9s total (~16.46s/epoch)\n",
            "[SUMMARY] H=1 | DCRNN      | Best VAL MAE=0.3778 | epochs=15 | time=246.9s\n",
            "H=1 | GConvLSTM  | Trial 1/8 | stopped at epoch 15 | VAL MAE=0.3817 | 252.9s total (~16.86s/epoch)\n",
            "H=1 | GConvLSTM  | Trial 2/8 | stopped at epoch 15 | VAL MAE=0.3788 | 197.9s total (~13.19s/epoch)\n",
            "H=1 | GConvLSTM  | Trial 3/8 | stopped at epoch 15 | VAL MAE=0.3795 | 197.0s total (~13.14s/epoch)\n",
            "H=1 | GConvLSTM  | Trial 4/8 | stopped at epoch 15 | VAL MAE=0.3777 | 250.5s total (~16.70s/epoch)\n",
            "H=1 | GConvLSTM  | Trial 5/8 | stopped at epoch 15 | VAL MAE=0.3813 | 250.2s total (~16.68s/epoch)\n",
            "H=1 | GConvLSTM  | Trial 6/8 | stopped at epoch 15 | VAL MAE=0.3778 | 197.1s total (~13.14s/epoch)\n",
            "H=1 | GConvLSTM  | Trial 7/8 | stopped at epoch 15 | VAL MAE=0.3812 | 197.3s total (~13.16s/epoch)\n",
            "H=1 | GConvLSTM  | Trial 8/8 | stopped at epoch 13 | VAL MAE=0.3780 | 217.9s total (~16.76s/epoch)\n",
            "[SUMMARY] H=1 | GConvLSTM  | Best VAL MAE=0.3777 | epochs=15 | time=250.5s\n",
            "H=1 | GraphWaveNet | Trial 1/8 | stopped at epoch 15 | VAL MAE=0.3684 | 81.6s total (~5.44s/epoch)\n",
            "H=1 | GraphWaveNet | Trial 2/8 | stopped at epoch 12 | VAL MAE=0.3843 | 64.0s total (~5.33s/epoch)\n",
            "H=1 | GraphWaveNet | Trial 3/8 | stopped at epoch 13 | VAL MAE=0.3765 | 69.4s total (~5.34s/epoch)\n",
            "H=1 | GraphWaveNet | Trial 4/8 | stopped at epoch 15 | VAL MAE=0.3667 | 54.2s total (~3.62s/epoch)\n",
            "H=1 | GraphWaveNet | Trial 5/8 | stopped at epoch 14 | VAL MAE=0.3732 | 74.7s total (~5.34s/epoch)\n",
            "H=1 | GraphWaveNet | Trial 6/8 | stopped at epoch 15 | VAL MAE=0.3719 | 54.2s total (~3.61s/epoch)\n",
            "H=1 | GraphWaveNet | Trial 7/8 | stopped at epoch 15 | VAL MAE=0.3700 | 80.0s total (~5.33s/epoch)\n",
            "H=1 | GraphWaveNet | Trial 8/8 | stopped at epoch 15 | VAL MAE=0.3663 | 54.2s total (~3.62s/epoch)\n",
            "[SUMMARY] H=1 | GraphWaveNet | Best VAL MAE=0.3663 | epochs=15 | time=54.2s\n",
            "\n",
            "================================================================================\n",
            "TUNING COMPLETE. BEST CONFIGURATIONS:\n",
            "H=1 | DCRNN      | VAL MAE=0.3778 | epochs=15 | time=246.9s | {'hidden_channels': 96, 'k_hops': 2, 'learning_rate': 0.003}\n",
            "H=1 | GConvLSTM  | VAL MAE=0.3777 | epochs=15 | time=250.5s | {'hidden_size': 32, 'K': 3, 'learning_rate': 0.01}\n",
            "H=1 | GraphWaveNet | VAL MAE=0.3663 | epochs=15 | time=54.2s | {'hidden_size': 32, 'dropout': 0.3, 'learning_rate': 0.003}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Filter only horizon 1\n",
        "tuning_h1 = [r for r in tuning_results if r['horizon'] == 1]\n",
        "\n",
        "# Build DataFrame\n",
        "df_h1 = pd.DataFrame(tuning_h1)\n",
        "\n",
        "# Optional: sort for readability\n",
        "df_h1 = df_h1.sort_values(['model'])\n",
        "\n",
        "# Optional: pretty-print params as JSON strings (nicer in CSV)\n",
        "df_h1['best_params_json'] = df_h1['best_params'].apply(lambda p: json.dumps(p))\n",
        "\n",
        "# Show in notebook\n",
        "print(df_h1)\n",
        "\n",
        "# Save to CSV (adjust path if you want it directly in Drive)\n",
        "csv_path = \"/content/tuning_results_h1.csv\"\n",
        "df_h1.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"\\nSaved H=1 tuning results to: {csv_path}\")"
      ],
      "metadata": {
        "id": "rWbD-LwTZAIb",
        "outputId": "6b955083-3ed1-424d-c8d1-e2545172f32b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   horizon         model                                        best_params  \\\n",
            "0        1         DCRNN  {'hidden_channels': 96, 'k_hops': 2, 'learning...   \n",
            "1        1     GConvLSTM  {'hidden_size': 32, 'K': 3, 'learning_rate': 0...   \n",
            "2        1  GraphWaveNet  {'hidden_size': 32, 'dropout': 0.3, 'learning_...   \n",
            "\n",
            "   best_val_mae  best_epochs  best_time_sec  \\\n",
            "0      0.377829           15     246.853319   \n",
            "1      0.377668           15     250.536676   \n",
            "2      0.366334           15      54.234078   \n",
            "\n",
            "                                    best_params_json  \n",
            "0  {\"hidden_channels\": 96, \"k_hops\": 2, \"learning...  \n",
            "1  {\"hidden_size\": 32, \"K\": 3, \"learning_rate\": 0...  \n",
            "2  {\"hidden_size\": 32, \"dropout\": 0.3, \"learning_...  \n",
            "\n",
            "Saved H=1 tuning results to: /content/tuning_results_h1.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the best models"
      ],
      "metadata": {
        "id": "2x0drtniTL5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# FINAL STEP: TRAINING THE BEST MODELS\n",
        "# =============================================================================\n",
        "\n",
        "import copy\n",
        "import os\n",
        "import gc\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Define the Winning Configurations\n",
        "BEST_CONFIGS = {\n",
        "    1: {\n",
        "        'DCRNN':        {'hidden_channels': 96, 'k_hops': 2, 'learning_rate': 0.003},\n",
        "        'GConvLSTM':    {'hidden_size': 32, 'K': 3, 'learning_rate': 0.01},\n",
        "        'GraphWaveNet': {'hidden_size': 32, 'dropout': 0.3, 'learning_rate': 0.003},\n",
        "    },\n",
        "    6: {\n",
        "        'DCRNN':        {'hidden_channels': 96, 'k_hops': 2, 'learning_rate': 0.003},\n",
        "        'GConvLSTM':    {'hidden_size': 32, 'K': 3, 'learning_rate': 0.01},\n",
        "        'GraphWaveNet': {'hidden_size': 32, 'dropout': 0.3, 'learning_rate': 0.003},\n",
        "    },\n",
        "    12: {\n",
        "        'DCRNN':        {'hidden_channels': 96, 'k_hops': 2, 'learning_rate': 0.003},\n",
        "        'GConvLSTM':    {'hidden_size': 32, 'K': 3, 'learning_rate': 0.01},\n",
        "        'GraphWaveNet': {'hidden_size': 32, 'dropout': 0.3, 'learning_rate': 0.003},\n",
        "    }\n",
        "}\n",
        "\n",
        "# 2. Update Experiment Config with Robust Paths\n",
        "#    We will try to save to Drive first.\n",
        "DRIVE_BASE_PATH = '/content/drive/MyDrive/Colab Notebooks/master_thesis_gdrive/benchmarks/best_models'\n",
        "LOCAL_BASE_PATH = '/content/best_models'\n",
        "\n",
        "FINAL_EXP_CONFIG = copy.deepcopy(EXPERIMENT_CONFIG)\n",
        "FINAL_EXP_CONFIG.update({\n",
        "    'csv_export': {\n",
        "        'enabled': True,\n",
        "        'experiment_name': 'best_models',\n",
        "        'model_prefix': 'tuned',\n",
        "        'exog_mode': 'graph',\n",
        "        # We set these dynamically below based on success/failure of Drive\n",
        "        'drive_path': DRIVE_BASE_PATH,\n",
        "        'local_path': LOCAL_BASE_PATH,\n",
        "    },\n",
        "    'tensor_export': {\n",
        "        'enabled': True,\n",
        "        'experiment_name': 'best_models',\n",
        "        'save_predictions': True,\n",
        "        'save_targets': True,\n",
        "        'save_inputs': True,\n",
        "        'save_errors': True,\n",
        "        # Tensors usually go into a subfolder to avoid clutter\n",
        "        'drive_path': os.path.join(DRIVE_BASE_PATH, 'tensors'),\n",
        "        'local_path': os.path.join(LOCAL_BASE_PATH, 'tensors'),\n",
        "    },\n",
        "    'training_defaults': {\n",
        "        'early_stopping_patience': 15,\n",
        "        'gradient_clip_norm': 5.0,\n",
        "    }\n",
        "})\n",
        "\n",
        "FINAL_EPOCHS = 80\n",
        "\n",
        "# 3. Helpers to inject params\n",
        "def apply_params_to_config(model_name, params, base_configs):\n",
        "    new_config = copy.deepcopy(base_configs)\n",
        "    if 'learning_rate' in params:\n",
        "        new_config[model_name]['training']['learning_rate'] = params['learning_rate']\n",
        "    for k, v in params.items():\n",
        "        if k != 'learning_rate':\n",
        "            new_config[model_name]['params'][k] = v\n",
        "    new_config[model_name]['training']['epochs'] = FINAL_EPOCHS\n",
        "    return new_config\n",
        "\n",
        "# =============================================================================\n",
        "# RUNNING THE FINAL TRAINING\n",
        "# =============================================================================\n",
        "\n",
        "final_results = {}\n",
        "horizons = sorted(BEST_CONFIGS.keys())\n",
        "\n",
        "total_steps = 0\n",
        "for h in horizons:\n",
        "    total_steps += len(BEST_CONFIGS[h]) * FINAL_EPOCHS\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(f\"STARTING FINAL TRAINING (Max Epochs: {total_steps})\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Check Drive Accessibility upfront\n",
        "drive_accessible = os.path.isdir('/content/drive')\n",
        "if drive_accessible:\n",
        "    print(f\"✓ Google Drive found. Saving to: {DRIVE_BASE_PATH}\")\n",
        "    os.makedirs(FINAL_EXP_CONFIG['tensor_export']['drive_path'], exist_ok=True)\n",
        "else:\n",
        "    print(f\"⚠ Drive NOT found. Will save locally to: {LOCAL_BASE_PATH}\")\n",
        "\n",
        "with tqdm(total=total_steps, unit=\"epoch\", desc=\"Total Progress\") as pbar:\n",
        "\n",
        "    for H in horizons:\n",
        "        tqdm.write(f\"\\n{'='*60}\")\n",
        "        tqdm.write(f\"HORIZON {H}\")\n",
        "        tqdm.write(f\"{'='*60}\")\n",
        "\n",
        "        # 1. Data Prep\n",
        "        seq_len = EXPERIMENT_CONFIG[\"sequence_length\"]\n",
        "        # Ensure target_col_idx is defined (from previous cells)\n",
        "        if 'target_col_idx' not in locals():\n",
        "            target_col_idx = 1 # Default fallback if variable lost\n",
        "\n",
        "        Xtr_np, ytr_np = build_optionA_samples(X_train_scaled, train_weeks, H, seq_len, target_col_idx)\n",
        "        Xtr, ytr = to_torch_dataset(Xtr_np, ytr_np, device)\n",
        "        Xval_np, yval_np = build_optionA_samples(X_val_scaled, val_weeks, H, seq_len, target_col_idx)\n",
        "        Xval, yval = to_torch_dataset(Xval_np, yval_np, device)\n",
        "        Xte_np, yte_np = build_optionA_samples(X_test_scaled, test_combined_weeks, H, seq_len, target_col_idx)\n",
        "        Xte, yte = to_torch_dataset(Xte_np, yte_np, device)\n",
        "\n",
        "        if H not in final_results: final_results[H] = {}\n",
        "\n",
        "        # 2. Iterate through best models\n",
        "        for model_name, params in BEST_CONFIGS[H].items():\n",
        "            tqdm.write(f\"\\nTraining {model_name}...\")\n",
        "\n",
        "            current_model_config = apply_params_to_config(model_name, params, BASE_MODEL_CONFIGS)\n",
        "\n",
        "            try:\n",
        "                # Train\n",
        "                train_result = train_one_model_optionA(\n",
        "                    model_name=model_name,\n",
        "                    model_configs=current_model_config,\n",
        "                    experiment_cfg=FINAL_EXP_CONFIG,\n",
        "                    X_train=Xtr, y_train=ytr,\n",
        "                    X_val=Xval, y_val=yval,\n",
        "                    edge_index=edge_index_tensor,\n",
        "                    edge_weight=edge_weight_tensor,\n",
        "                    device=device,\n",
        "                    verbose=True,\n",
        "                    pbar=pbar\n",
        "                )\n",
        "\n",
        "                # Evaluate\n",
        "                metrics, tensors = evaluate_model_optionA(\n",
        "                    model=train_result['model'],\n",
        "                    model_name=model_name,\n",
        "                    X_test=Xte, y_test=yte,\n",
        "                    edge_index=edge_index_tensor,\n",
        "                    edge_weight=edge_weight_tensor,\n",
        "                    scaler=scaler,\n",
        "                    target_col_idx=target_col_idx,\n",
        "                    return_tensors=True\n",
        "                )\n",
        "\n",
        "                final_results[H][model_name] = {\n",
        "                    \"best_val_loss\": train_result[\"best_val_loss\"],\n",
        "                    \"epochs_trained\": train_result[\"epochs_trained\"],\n",
        "                    \"test_MSE\": metrics[\"MSE\"],\n",
        "                    \"test_MAE\": metrics[\"MAE\"],\n",
        "                    \"test_RMSE\": metrics[\"RMSE\"],\n",
        "                    \"test_SMAPE\": metrics[\"SMAPE\"],\n",
        "                    \"config\": str(params),\n",
        "                    \"status\": \"SUCCESS\",\n",
        "                }\n",
        "\n",
        "                tqdm.write(f\"  > DONE. SMAPE: {metrics['SMAPE']:.2f}% (Epochs: {train_result['epochs_trained']})\")\n",
        "\n",
        "                # Save Tensors (Automatic fallback handled in save_model_tensors function or here)\n",
        "                # We'll rely on the paths set in FINAL_EXP_CONFIG.\n",
        "                # Note: save_model_tensors attempts local if drive fails, as written in utils.\n",
        "                save_model_tensors(tensors, model_name, H, FINAL_EXP_CONFIG, verbose=False)\n",
        "\n",
        "                # ---------------------------\n",
        "                # SAVE MODEL WEIGHTS (NEW)\n",
        "                # ---------------------------\n",
        "                weights_dir_local = os.path.join(LOCAL_BASE_PATH, \"weights\")\n",
        "                os.makedirs(weights_dir_local, exist_ok=True)\n",
        "                weights_fname = f\"tuned_{model_name}_H{H}.pt\"\n",
        "                weights_path_local = os.path.join(weights_dir_local, weights_fname)\n",
        "                torch.save(train_result[\"model\"].state_dict(), weights_path_local)\n",
        "                tqdm.write(f\"  > Saved weights locally: {weights_path_local}\")\n",
        "\n",
        "                if os.path.isdir('/content/drive'):\n",
        "                    weights_dir_drive = os.path.join(DRIVE_BASE_PATH, \"weights\")\n",
        "                    os.makedirs(weights_dir_drive, exist_ok=True)\n",
        "                    weights_path_drive = os.path.join(weights_dir_drive, weights_fname)\n",
        "                    torch.save(train_result[\"model\"].state_dict(), weights_path_drive)\n",
        "                    tqdm.write(f\"  > Saved weights to Drive: {weights_path_drive}\")\n",
        "\n",
        "                # Cleanup\n",
        "                del train_result\n",
        "                gc.collect()\n",
        "                if device == \"cuda\": torch.cuda.empty_cache()\n",
        "\n",
        "            except Exception as e:\n",
        "                tqdm.write(f\"  > FAILED: {e}\")\n",
        "                final_results[H][model_name] = {\"status\": \"FAILED\", \"error\": str(e)}\n",
        "                pbar.update(FINAL_EPOCHS)\n",
        "                gc.collect()\n",
        "                if device == \"cuda\": torch.cuda.empty_cache()\n",
        "\n",
        "# =============================================================================\n",
        "# EXPORT FINAL RESULTS WITH FALLBACK\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL BENCHMARK COMPLETE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "rows = []\n",
        "for H in final_results:\n",
        "    for m_name in final_results[H]:\n",
        "        r = final_results[H][m_name]\n",
        "        if r['status'] == 'SUCCESS':\n",
        "            rows.append({\n",
        "                'horizon': H,\n",
        "                'model_id': f\"tuned | {m_name}\",\n",
        "                'exog_mode': 'graph',\n",
        "                'config': r['config'],\n",
        "                'mse': r['test_MSE'],\n",
        "                'mae': r['test_MAE'],\n",
        "                'rmse': r['test_RMSE'],\n",
        "                'smape': r['test_SMAPE'],\n",
        "            })\n",
        "\n",
        "df_final = pd.DataFrame(rows)\n",
        "csv_name = \"best_models_results.csv\"\n",
        "\n",
        "# 1. Always save locally first (Success guaranteed)\n",
        "local_save_path = os.path.join(LOCAL_BASE_PATH, csv_name)\n",
        "os.makedirs(LOCAL_BASE_PATH, exist_ok=True)\n",
        "df_final.to_csv(local_save_path, index=False)\n",
        "print(f\"\\n✓ Saved result CSV locally: {local_save_path}\")\n",
        "\n",
        "# 2. Try saving to Drive\n",
        "drive_save_path = os.path.join(DRIVE_BASE_PATH, csv_name)\n",
        "try:\n",
        "    if os.path.isdir('/content/drive'):\n",
        "        os.makedirs(DRIVE_BASE_PATH, exist_ok=True)\n",
        "        df_final.to_csv(drive_save_path, index=False)\n",
        "        print(f\"✓ Saved result CSV to Drive: {drive_save_path}\")\n",
        "    else:\n",
        "        print(f\"⚠ Drive not mounted. Files are only at: {local_save_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠ Failed to save to Drive ({e}). Files are at: {local_save_path}\")\n",
        "\n",
        "print(\"\\nTOP RESULTS:\")\n",
        "if not df_final.empty:\n",
        "    print(\n",
        "        df_final\n",
        "        .sort_values(['horizon', 'smape'])\n",
        "        [['horizon', 'model_id', 'smape', 'rmse']]\n",
        "        .to_string(index=False)\n",
        "    )\n",
        "else:\n",
        "    print(\"No successful results to display.\")\n",
        "\n",
        "# =============================================================================\n",
        "# OPTIONAL: EXPORT PER-EPOCH TRAINING CURVES\n",
        "# =============================================================================\n",
        "\n",
        "log_dir_local = os.path.join(LOCAL_BASE_PATH, \"training_curves\")\n",
        "os.makedirs(log_dir_local, exist_ok=True)\n",
        "\n",
        "for H in final_results:\n",
        "    for m_name, r in final_results[H].items():\n",
        "        if r.get(\"status\") != \"SUCCESS\":\n",
        "            continue\n",
        "        logs = r.get(\"epoch_logs\")\n",
        "        if not logs:\n",
        "            continue\n",
        "\n",
        "        df_logs = pd.DataFrame(logs)\n",
        "        fname = f\"training_curve_H{H}_{m_name}.csv\"\n",
        "\n",
        "        # Save locally\n",
        "        save_path_local = os.path.join(log_dir_local, fname)\n",
        "        df_logs.to_csv(save_path_local, index=False)\n",
        "        print(f\"✓ Saved training curve locally: {save_path_local}\")\n",
        "\n",
        "        # Save to Drive if available\n",
        "        if os.path.isdir('/content/drive'):\n",
        "            log_dir_drive = os.path.join(DRIVE_BASE_PATH, \"training_curves\")\n",
        "            os.makedirs(log_dir_drive, exist_ok=True)\n",
        "            save_path_drive = os.path.join(log_dir_drive, fname)\n",
        "            df_logs.to_csv(save_path_drive, index=False)\n",
        "            print(f\"✓ Saved training curve to Drive: {save_path_drive}\"    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e9af5cc4c9ae4256aeb6c6a4bbea376a",
            "e4153808e8e1456bbc00dddcccb9d034",
            "05c874e2286a425cac8e620b5864512e",
            "bfef678ab65e4fdab6d39697d12b6853",
            "dd215c916baf45a2b320ce417fda7b1e",
            "007473e3684e4c61a12bfbd3a2b6eff6",
            "27ba761443074c7f8f167ae032bb9ee9",
            "e20f7afd156a4978851fd64c20f0840a",
            "c578e2850cde4f4cbb841fccd194808b",
            "db8bcdb5044d46ecba54c8b5708e7ee7",
            "f90c7d700cea403698ae9275edda5376"
          ]
        },
        "id": "YXRpSGc6TQKF",
        "outputId": "52fbffd9-d34e-434d-fe14-5f06426895ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "STARTING FINAL TRAINING (Max Epochs: 720)\n",
            "================================================================================\n",
            "✓ Google Drive found. Saving to: /content/drive/MyDrive/Colab Notebooks/master_thesis_gdrive/benchmarks/best_models\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Total Progress:   0%|          | 0/720 [00:00<?, ?epoch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9af5cc4c9ae4256aeb6c6a4bbea376a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "HORIZON 1\n",
            "============================================================\n",
            "Built 74 samples for horizon=1: X=(74, 12, 1811, 9), y=(74, 1, 1811, 1)\n",
            "Built 17 samples for horizon=1: X=(17, 12, 1811, 9), y=(17, 1, 1811, 1)\n",
            "Built 12 samples for horizon=1: X=(12, 12, 1811, 9), y=(12, 1, 1811, 1)\n",
            "\n",
            "Training DCRNN...\n",
            "[DCRNN] epoch 005/080 | train=0.4122 | val=0.3850 | lr=0.00300\n",
            "[DCRNN] epoch 010/080 | train=0.3897 | val=0.3740 | lr=0.00300\n",
            "[DCRNN] epoch 015/080 | train=0.3851 | val=0.3673 | lr=0.00300\n",
            "[DCRNN] epoch 020/080 | train=0.3811 | val=0.3665 | lr=0.00300\n",
            "[DCRNN] epoch 025/080 | train=0.3797 | val=0.3704 | lr=0.00300\n",
            "[DCRNN] epoch 030/080 | train=0.3791 | val=0.3657 | lr=0.00150\n",
            "[DCRNN] epoch 035/080 | train=0.3780 | val=0.3642 | lr=0.00150\n",
            "[DCRNN] epoch 040/080 | train=0.3776 | val=0.3629 | lr=0.00075\n",
            "[DCRNN] epoch 045/080 | train=0.3771 | val=0.3653 | lr=0.00075\n",
            "[DCRNN] epoch 050/080 | train=0.3764 | val=0.3647 | lr=0.00038\n",
            "[DCRNN] epoch 055/080 | train=0.3764 | val=0.3637 | lr=0.00019\n",
            "  Early stopping at epoch 55 (best val=0.3629)\n",
            "  > DONE. SMAPE: 30.31% (Epochs: 55)\n",
            "  > Saved weights locally: /content/best_models/weights/tuned_DCRNN_H1.pt\n",
            "  > Saved weights to Drive: /content/drive/MyDrive/Colab Notebooks/master_thesis_gdrive/benchmarks/best_models/weights/tuned_DCRNN_H1.pt\n",
            "\n",
            "Training GConvLSTM...\n",
            "[GConvLSTM] epoch 005/080 | train=0.4293 | val=0.4294 | lr=0.01000\n",
            "[GConvLSTM] epoch 010/080 | train=0.4051 | val=0.4097 | lr=0.01000\n",
            "[GConvLSTM] epoch 015/080 | train=0.3980 | val=0.4050 | lr=0.01000\n",
            "[GConvLSTM] epoch 020/080 | train=0.3934 | val=0.4029 | lr=0.01000\n",
            "[GConvLSTM] epoch 025/080 | train=0.3932 | val=0.4021 | lr=0.01000\n",
            "[GConvLSTM] epoch 030/080 | train=0.3908 | val=0.4000 | lr=0.01000\n",
            "[GConvLSTM] epoch 035/080 | train=0.3836 | val=0.4002 | lr=0.01000\n",
            "[GConvLSTM] epoch 040/080 | train=0.3815 | val=0.4020 | lr=0.00500\n",
            "[GConvLSTM] epoch 045/080 | train=0.3852 | val=0.3978 | lr=0.00500\n",
            "[GConvLSTM] epoch 050/080 | train=0.3842 | val=0.3985 | lr=0.00500\n",
            "[GConvLSTM] epoch 055/080 | train=0.3823 | val=0.3977 | lr=0.00500\n",
            "[GConvLSTM] epoch 060/080 | train=0.3805 | val=0.3974 | lr=0.00500\n",
            "[GConvLSTM] epoch 065/080 | train=0.3820 | val=0.3983 | lr=0.00250\n",
            "[GConvLSTM] epoch 070/080 | train=0.3801 | val=0.3974 | lr=0.00250\n",
            "[GConvLSTM] epoch 075/080 | train=0.3836 | val=0.3969 | lr=0.00250\n",
            "[GConvLSTM] epoch 080/080 | train=0.3866 | val=0.3972 | lr=0.00250\n",
            "  > DONE. SMAPE: 30.33% (Epochs: 80)\n",
            "  > Saved weights locally: /content/best_models/weights/tuned_GConvLSTM_H1.pt\n",
            "  > Saved weights to Drive: /content/drive/MyDrive/Colab Notebooks/master_thesis_gdrive/benchmarks/best_models/weights/tuned_GConvLSTM_H1.pt\n",
            "\n",
            "Training GraphWaveNet...\n",
            "[GraphWaveNet] epoch 005/080 | train=0.3997 | val=0.3880 | lr=0.00300\n",
            "[GraphWaveNet] epoch 010/080 | train=0.3909 | val=0.3791 | lr=0.00300\n",
            "[GraphWaveNet] epoch 015/080 | train=0.3837 | val=0.3681 | lr=0.00300\n",
            "[GraphWaveNet] epoch 020/080 | train=0.3709 | val=0.3719 | lr=0.00300\n",
            "[GraphWaveNet] epoch 025/080 | train=0.3677 | val=0.3746 | lr=0.00300\n",
            "[GraphWaveNet] epoch 030/080 | train=0.3688 | val=0.3857 | lr=0.00150\n",
            "[GraphWaveNet] epoch 035/080 | train=0.3572 | val=0.3726 | lr=0.00150\n",
            "  Early stopping at epoch 38 (best val=0.3598)\n",
            "  > DONE. SMAPE: 30.10% (Epochs: 38)\n",
            "  > Saved weights locally: /content/best_models/weights/tuned_GraphWaveNet_H1.pt\n",
            "  > Saved weights to Drive: /content/drive/MyDrive/Colab Notebooks/master_thesis_gdrive/benchmarks/best_models/weights/tuned_GraphWaveNet_H1.pt\n",
            "\n",
            "============================================================\n",
            "HORIZON 6\n",
            "============================================================\n",
            "Built 69 samples for horizon=6: X=(69, 12, 1811, 9), y=(69, 1, 1811, 1)\n",
            "Built 12 samples for horizon=6: X=(12, 12, 1811, 9), y=(12, 1, 1811, 1)\n",
            "Built 7 samples for horizon=6: X=(7, 12, 1811, 9), y=(7, 1, 1811, 1)\n",
            "\n",
            "Training DCRNN...\n",
            "[DCRNN] epoch 005/080 | train=0.5046 | val=0.4666 | lr=0.00300\n",
            "[DCRNN] epoch 010/080 | train=0.4682 | val=0.4655 | lr=0.00300\n",
            "[DCRNN] epoch 015/080 | train=0.4604 | val=0.4564 | lr=0.00300\n",
            "[DCRNN] epoch 020/080 | train=0.4660 | val=0.4609 | lr=0.00300\n",
            "[DCRNN] epoch 025/080 | train=0.4619 | val=0.4518 | lr=0.00150\n",
            "[DCRNN] epoch 030/080 | train=0.4580 | val=0.4535 | lr=0.00075\n",
            "[DCRNN] epoch 035/080 | train=0.4585 | val=0.4540 | lr=0.00075\n",
            "[DCRNN] epoch 040/080 | train=0.4514 | val=0.4548 | lr=0.00038\n",
            "  Early stopping at epoch 44 (best val=0.4496)\n",
            "  > DONE. SMAPE: 35.81% (Epochs: 44)\n",
            "  > Saved weights locally: /content/best_models/weights/tuned_DCRNN_H6.pt\n",
            "  > Saved weights to Drive: /content/drive/MyDrive/Colab Notebooks/master_thesis_gdrive/benchmarks/best_models/weights/tuned_DCRNN_H6.pt\n",
            "\n",
            "Training GConvLSTM...\n",
            "[GConvLSTM] epoch 005/080 | train=0.5110 | val=0.4560 | lr=0.01000\n",
            "[GConvLSTM] epoch 010/080 | train=0.4896 | val=0.4833 | lr=0.01000\n",
            "[GConvLSTM] epoch 015/080 | train=0.4820 | val=0.4569 | lr=0.01000\n",
            "[GConvLSTM] epoch 020/080 | train=0.4626 | val=0.4522 | lr=0.01000\n",
            "[GConvLSTM] epoch 025/080 | train=0.4763 | val=0.4525 | lr=0.00500\n",
            "[GConvLSTM] epoch 030/080 | train=0.4618 | val=0.4536 | lr=0.00250\n",
            "  Early stopping at epoch 32 (best val=0.4447)\n",
            "  > DONE. SMAPE: 36.01% (Epochs: 32)\n",
            "  > Saved weights locally: /content/best_models/weights/tuned_GConvLSTM_H6.pt\n",
            "  > Saved weights to Drive: /content/drive/MyDrive/Colab Notebooks/master_thesis_gdrive/benchmarks/best_models/weights/tuned_GConvLSTM_H6.pt\n",
            "\n",
            "Training GraphWaveNet...\n",
            "[GraphWaveNet] epoch 005/080 | train=0.4790 | val=0.4519 | lr=0.00300\n",
            "[GraphWaveNet] epoch 010/080 | train=0.4642 | val=0.4542 | lr=0.00300\n",
            "[GraphWaveNet] epoch 015/080 | train=0.4603 | val=0.4500 | lr=0.00300\n",
            "[GraphWaveNet] epoch 020/080 | train=0.4385 | val=0.4580 | lr=0.00150\n",
            "[GraphWaveNet] epoch 025/080 | train=0.4169 | val=0.4592 | lr=0.00150\n",
            "  Early stopping at epoch 28 (best val=0.4478)\n",
            "  > DONE. SMAPE: 37.16% (Epochs: 28)\n",
            "  > Saved weights locally: /content/best_models/weights/tuned_GraphWaveNet_H6.pt\n",
            "  > Saved weights to Drive: /content/drive/MyDrive/Colab Notebooks/master_thesis_gdrive/benchmarks/best_models/weights/tuned_GraphWaveNet_H6.pt\n",
            "\n",
            "============================================================\n",
            "HORIZON 12\n",
            "============================================================\n",
            "Built 63 samples for horizon=12: X=(63, 12, 1811, 9), y=(63, 1, 1811, 1)\n",
            "Built 6 samples for horizon=12: X=(6, 12, 1811, 9), y=(6, 1, 1811, 1)\n",
            "Built 1 samples for horizon=12: X=(1, 12, 1811, 9), y=(1, 1, 1811, 1)\n",
            "\n",
            "Training DCRNN...\n",
            "[DCRNN] epoch 005/080 | train=0.5516 | val=0.5071 | lr=0.00300\n",
            "[DCRNN] epoch 010/080 | train=0.5220 | val=0.5026 | lr=0.00300\n",
            "[DCRNN] epoch 015/080 | train=0.5091 | val=0.4886 | lr=0.00300\n",
            "[DCRNN] epoch 020/080 | train=0.5042 | val=0.4890 | lr=0.00150\n",
            "  Early stopping at epoch 24 (best val=0.4770)\n",
            "  > DONE. SMAPE: 44.89% (Epochs: 24)\n",
            "  > Saved weights locally: /content/best_models/weights/tuned_DCRNN_H12.pt\n",
            "  > Saved weights to Drive: /content/drive/MyDrive/Colab Notebooks/master_thesis_gdrive/benchmarks/best_models/weights/tuned_DCRNN_H12.pt\n",
            "\n",
            "Training GConvLSTM...\n",
            "[GConvLSTM] epoch 005/080 | train=0.5587 | val=0.4988 | lr=0.01000\n",
            "[GConvLSTM] epoch 010/080 | train=0.5325 | val=0.4805 | lr=0.01000\n",
            "[GConvLSTM] epoch 015/080 | train=0.5205 | val=0.4958 | lr=0.01000\n",
            "[GConvLSTM] epoch 020/080 | train=0.5150 | val=0.4815 | lr=0.00500\n",
            "  Early stopping at epoch 24 (best val=0.4801)\n",
            "  > DONE. SMAPE: 44.79% (Epochs: 24)\n",
            "  > Saved weights locally: /content/best_models/weights/tuned_GConvLSTM_H12.pt\n",
            "  > Saved weights to Drive: /content/drive/MyDrive/Colab Notebooks/master_thesis_gdrive/benchmarks/best_models/weights/tuned_GConvLSTM_H12.pt\n",
            "\n",
            "Training GraphWaveNet...\n",
            "[GraphWaveNet] epoch 005/080 | train=0.5304 | val=0.4823 | lr=0.00300\n",
            "[GraphWaveNet] epoch 010/080 | train=0.4921 | val=0.5321 | lr=0.00300\n",
            "[GraphWaveNet] epoch 015/080 | train=0.4722 | val=0.4801 | lr=0.00150\n",
            "[GraphWaveNet] epoch 020/080 | train=0.4542 | val=0.5068 | lr=0.00075\n",
            "[GraphWaveNet] epoch 025/080 | train=0.4442 | val=0.4806 | lr=0.00075\n",
            "  Early stopping at epoch 28 (best val=0.4800)\n",
            "  > DONE. SMAPE: 44.69% (Epochs: 28)\n",
            "  > Saved weights locally: /content/best_models/weights/tuned_GraphWaveNet_H12.pt\n",
            "  > Saved weights to Drive: /content/drive/MyDrive/Colab Notebooks/master_thesis_gdrive/benchmarks/best_models/weights/tuned_GraphWaveNet_H12.pt\n",
            "\n",
            "================================================================================\n",
            "FINAL BENCHMARK COMPLETE\n",
            "================================================================================\n",
            "\n",
            "✓ Saved result CSV locally: /content/best_models/best_models_results.csv\n",
            "✓ Saved result CSV to Drive: /content/drive/MyDrive/Colab Notebooks/master_thesis_gdrive/benchmarks/best_models/best_models_results.csv\n",
            "\n",
            "TOP RESULTS:\n",
            " horizon             model_id     smape     rmse\n",
            "       1 tuned | GraphWaveNet 30.102798 1.376447\n",
            "       1        tuned | DCRNN 30.312115 1.383673\n",
            "       1    tuned | GConvLSTM 30.330904 1.394527\n",
            "       6        tuned | DCRNN 35.807843 1.635901\n",
            "       6    tuned | GConvLSTM 36.012455 1.687279\n",
            "       6 tuned | GraphWaveNet 37.155034 1.661701\n",
            "      12 tuned | GraphWaveNet 44.691738 1.850160\n",
            "      12    tuned | GConvLSTM 44.787393 1.895741\n",
            "      12        tuned | DCRNN 44.886933 1.873332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# graph structure experiment"
      ],
      "metadata": {
        "id": "XRUYq2x5sxic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# GRAPH STRUCTURE COMPARISON (k=5 vs k=10 vs k=20)\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import copy\n",
        "import gc\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# 1. Define Paths to your Graph Versions\n",
        "BASE_DRIVE_PATH = \"/content/drive/MyDrive/Colab Notebooks/master_thesis_gdrive\"\n",
        "GRAPH_PATHS = {\n",
        "    5:  os.path.join(BASE_DRIVE_PATH, \"sebs_keyword_graph_knn_k5\"),\n",
        "    10: os.path.join(BASE_DRIVE_PATH, \"sebs_keyword_graph_knn\"),     # Default folder\n",
        "    20: os.path.join(BASE_DRIVE_PATH, \"sebs_keyword_graph_knn_k20\")\n",
        "}\n",
        "\n",
        "# 2. Settings for the Test\n",
        "TEST_MODEL = 'DCRNN'\n",
        "TEST_HORIZON = 1\n",
        "TEST_EPOCHS = 30  # Short run is enough to see the difference\n",
        "\n",
        "# Use the Best Parameters you found for DCRNN at Horizon 1\n",
        "TEST_PARAMS = {\n",
        "    'hidden_channels': 32,\n",
        "    'k_hops': 1,\n",
        "    'learning_rate': 0.005\n",
        "}\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(f\"COMPARING GRAPH STRUCTURES (k=5, 10, 20) with {TEST_MODEL}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 3. Prepare Data (One time setup for Horizon 1)\n",
        "print(f\"Preparing data for Horizon {TEST_HORIZON}...\")\n",
        "seq_len = EXPERIMENT_CONFIG[\"sequence_length\"]\n",
        "target_col_idx = available_features.index(TARGET_COL)\n",
        "\n",
        "Xtr_np, ytr_np = build_optionA_samples(X_train_scaled, train_weeks, TEST_HORIZON, seq_len, target_col_idx)\n",
        "Xtr, ytr = to_torch_dataset(Xtr_np, ytr_np, device)\n",
        "\n",
        "Xval_np, yval_np = build_optionA_samples(X_val_scaled, val_weeks, TEST_HORIZON, seq_len, target_col_idx)\n",
        "Xval, yval = to_torch_dataset(Xval_np, yval_np, device)\n",
        "\n",
        "Xte_np, yte_np = build_optionA_samples(X_test_scaled, test_combined_weeks, TEST_HORIZON, seq_len, target_col_idx)\n",
        "Xte, yte = to_torch_dataset(Xte_np, yte_np, device)\n",
        "\n",
        "# 4. Comparison Loop with Global Progress Bar\n",
        "graph_results = []\n",
        "total_epochs = len(GRAPH_PATHS) * TEST_EPOCHS\n",
        "\n",
        "with tqdm(total=total_epochs, unit=\"epoch\", desc=\"Comparing Graphs\") as pbar:\n",
        "\n",
        "    for k, folder_path in GRAPH_PATHS.items():\n",
        "        tqdm.write(f\"\\n\" + \"-\"*60)\n",
        "        tqdm.write(f\"Testing Graph k={k}\")\n",
        "        tqdm.write(f\"Loading from: {folder_path}\")\n",
        "        tqdm.write(\"-\"*(60))\n",
        "\n",
        "        try:\n",
        "            # A. Load the Graph Files\n",
        "            edge_index_path = os.path.join(folder_path, 'edge_index.npy')\n",
        "            edge_weight_path = os.path.join(folder_path, 'edge_weight.npy')\n",
        "\n",
        "            if not os.path.exists(edge_index_path):\n",
        "                tqdm.write(f\"⚠ File not found: {edge_index_path}\")\n",
        "                # Skip progress if file missing\n",
        "                pbar.update(TEST_EPOCHS)\n",
        "                continue\n",
        "\n",
        "            ei = np.load(edge_index_path)\n",
        "            ew = np.load(edge_weight_path)\n",
        "\n",
        "            # Convert to Tensor\n",
        "            ei_t = torch.from_numpy(ei).long().to(device)\n",
        "            ew_t = torch.from_numpy(ew).float().to(device)\n",
        "\n",
        "            tqdm.write(f\"  > Loaded Graph: {ei.shape[1]} edges\")\n",
        "\n",
        "            # B. Configure Model with Best Params\n",
        "            temp_config = copy.deepcopy(BASE_MODEL_CONFIGS)\n",
        "            temp_config[TEST_MODEL]['params']['hidden_channels'] = TEST_PARAMS['hidden_channels']\n",
        "            temp_config[TEST_MODEL]['params']['k_hops'] = TEST_PARAMS['k_hops']\n",
        "            temp_config[TEST_MODEL]['training']['learning_rate'] = TEST_PARAMS['learning_rate']\n",
        "            temp_config[TEST_MODEL]['training']['epochs'] = TEST_EPOCHS\n",
        "\n",
        "            # C. Train (Passing the PBAR)\n",
        "            train_result = train_one_model_optionA(\n",
        "                TEST_MODEL, temp_config, EXPERIMENT_CONFIG,\n",
        "                Xtr, ytr, Xval, yval,\n",
        "                ei_t, ew_t,\n",
        "                device=device,\n",
        "                verbose=True,\n",
        "                pbar=pbar # <--- Connects to global bar\n",
        "            )\n",
        "\n",
        "            # D. Evaluate\n",
        "            metrics, _ = evaluate_model_optionA(\n",
        "                train_result['model'], TEST_MODEL, Xte, yte,\n",
        "                ei_t, ew_t,\n",
        "                scaler=scaler, target_col_idx=target_col_idx, return_tensors=False\n",
        "            )\n",
        "\n",
        "            tqdm.write(f\"  > Result (k={k}): Val Loss={train_result['best_val_loss']:.4f} | Test SMAPE={metrics['SMAPE']:.2f}%\")\n",
        "\n",
        "            graph_results.append({\n",
        "                'k': k,\n",
        "                'edges': ei.shape[1],\n",
        "                'smape': metrics['SMAPE'],\n",
        "                'rmse': metrics['RMSE']\n",
        "            })\n",
        "\n",
        "            # Cleanup\n",
        "            del train_result\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        except Exception as e:\n",
        "            tqdm.write(f\"  > Failed: {e}\")\n",
        "            # Advance bar if run crashed\n",
        "            pbar.update(TEST_EPOCHS)\n",
        "            gc.collect()\n",
        "            if device == \"cuda\": torch.cuda.empty_cache()\n",
        "\n",
        "# 5. Summary\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"GRAPH STRUCTURE COMPARISON RESULTS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"{'k':<5} | {'Edges':<10} | {'SMAPE (%)':<12} | {'RMSE':<10}\")\n",
        "print(\"-\" * 45)\n",
        "for res in sorted(graph_results, key=lambda x: x['smape']):\n",
        "    print(f\"{res['k']:<5} | {res['edges']:<10} | {res['smape']:<12.2f} | {res['rmse']:<10.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711,
          "referenced_widgets": [
            "ad42459caeed47619c39fa63e21d4dcc",
            "4c03e40590ab4f38a4b9436fdf90fb4c",
            "923e9a4cc3094a508ff9762ad5990ce3",
            "10e68214a498465baa9ef0c507e62b47",
            "f2f38d75cd4d430d9b766238c6889643",
            "8b64051c5a794788b656df5cd471f814",
            "350335642cfe4bfb8068e6b834c94250",
            "8d3a7d757d25475fb2092e73dab185fc",
            "fc945d13ce154c8894c295bf91ce66e8",
            "fb9dca9af4154f24a7f53cf82bd307f2",
            "42f60fc7e63746238d27350b05d28be5"
          ]
        },
        "id": "BnABSsgZs1HE",
        "outputId": "dfc8bb4f-9b71-4376-df62-daba6f34c3f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "COMPARING GRAPH STRUCTURES (k=5, 10, 20) with DCRNN\n",
            "================================================================================\n",
            "Preparing data for Horizon 1...\n",
            "Built 74 samples for horizon=1: X=(74, 12, 1811, 13), y=(74, 1, 1811, 1)\n",
            "Built 17 samples for horizon=1: X=(17, 12, 1811, 13), y=(17, 1, 1811, 1)\n",
            "Built 12 samples for horizon=1: X=(12, 12, 1811, 13), y=(12, 1, 1811, 1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Comparing Graphs:   0%|          | 0/90 [00:00<?, ?epoch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad42459caeed47619c39fa63e21d4dcc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------------------------------------------------------\n",
            "Testing Graph k=5\n",
            "Loading from: /content/drive/MyDrive/Colab Notebooks/master_thesis_gdrive/sebs_keyword_graph_knn_k5\n",
            "------------------------------------------------------------\n",
            "  > Loaded Graph: 9055 edges\n",
            "  > Result (k=5): Val Loss=0.3637 | Test SMAPE=30.47%\n",
            "\n",
            "------------------------------------------------------------\n",
            "Testing Graph k=10\n",
            "Loading from: /content/drive/MyDrive/Colab Notebooks/master_thesis_gdrive/sebs_keyword_graph_knn\n",
            "------------------------------------------------------------\n",
            "  > Loaded Graph: 18110 edges\n",
            "  > Result (k=10): Val Loss=0.3628 | Test SMAPE=30.26%\n",
            "\n",
            "------------------------------------------------------------\n",
            "Testing Graph k=20\n",
            "Loading from: /content/drive/MyDrive/Colab Notebooks/master_thesis_gdrive/sebs_keyword_graph_knn_k20\n",
            "------------------------------------------------------------\n",
            "  > Loaded Graph: 36220 edges\n",
            "  > Result (k=20): Val Loss=0.3629 | Test SMAPE=30.39%\n",
            "\n",
            "================================================================================\n",
            "GRAPH STRUCTURE COMPARISON RESULTS\n",
            "================================================================================\n",
            "k     | Edges      | SMAPE (%)    | RMSE      \n",
            "---------------------------------------------\n",
            "10    | 18110      | 30.26        | 1.4089    \n",
            "20    | 36220      | 30.39        | 1.4051    \n",
            "5     | 9055       | 30.47        | 1.4074    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('hello world')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tqbtGM3mFL0",
        "outputId": "2b6ebe20-343f-4a41-8344-a162f566ae61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello world\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import platform\n",
        "print(platform.python_version())"
      ],
      "metadata": {
        "id": "JlA_D7jYXU6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "830057e6-45e6-45f3-aac7-a655542325b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.12.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sQI_KtLA3RBm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6d12be1d440144e6b052e07dfbf786f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7eed69e8425a4871a58a5d8777b63948",
              "IPY_MODEL_f2bfe842d6cc4e1186f8edd439f962f0",
              "IPY_MODEL_4ddee7437a7c4cfebb13078a04569bbf"
            ],
            "layout": "IPY_MODEL_c1e67bfc7184492a9c3cbfd5d5d8af13"
          }
        },
        "7eed69e8425a4871a58a5d8777b63948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0927e67b51d64e36942cceea0cba549a",
            "placeholder": "​",
            "style": "IPY_MODEL_a0ecbc244c3944d4b0a62a0c9fbb877f",
            "value": "Overall Progress: 100%"
          }
        },
        "f2bfe842d6cc4e1186f8edd439f962f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_feb5308c3473418fa80a6a12cb83e52a",
            "max": 2400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72ea1ac523924a5da67f62561e023d40",
            "value": 2400
          }
        },
        "4ddee7437a7c4cfebb13078a04569bbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19cdc414aa204359910e7dcf23905c53",
            "placeholder": "​",
            "style": "IPY_MODEL_e061f4dd96374b31aeb2ce1fe414d587",
            "value": " 2400/2400 [2:07:55&lt;00:00,  8.74s/epoch, model=GraphWaveNet, val_loss=0.4984]"
          }
        },
        "c1e67bfc7184492a9c3cbfd5d5d8af13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0927e67b51d64e36942cceea0cba549a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0ecbc244c3944d4b0a62a0c9fbb877f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "feb5308c3473418fa80a6a12cb83e52a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72ea1ac523924a5da67f62561e023d40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19cdc414aa204359910e7dcf23905c53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e061f4dd96374b31aeb2ce1fe414d587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad42459caeed47619c39fa63e21d4dcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c03e40590ab4f38a4b9436fdf90fb4c",
              "IPY_MODEL_923e9a4cc3094a508ff9762ad5990ce3",
              "IPY_MODEL_10e68214a498465baa9ef0c507e62b47"
            ],
            "layout": "IPY_MODEL_f2f38d75cd4d430d9b766238c6889643"
          }
        },
        "4c03e40590ab4f38a4b9436fdf90fb4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b64051c5a794788b656df5cd471f814",
            "placeholder": "​",
            "style": "IPY_MODEL_350335642cfe4bfb8068e6b834c94250",
            "value": "Comparing Graphs: 100%"
          }
        },
        "923e9a4cc3094a508ff9762ad5990ce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d3a7d757d25475fb2092e73dab185fc",
            "max": 90,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc945d13ce154c8894c295bf91ce66e8",
            "value": 90
          }
        },
        "10e68214a498465baa9ef0c507e62b47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb9dca9af4154f24a7f53cf82bd307f2",
            "placeholder": "​",
            "style": "IPY_MODEL_42f60fc7e63746238d27350b05d28be5",
            "value": " 90/90 [15:37&lt;00:00, 10.34s/epoch, model=DCRNN, val_loss=0.3629]"
          }
        },
        "f2f38d75cd4d430d9b766238c6889643": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b64051c5a794788b656df5cd471f814": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "350335642cfe4bfb8068e6b834c94250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d3a7d757d25475fb2092e73dab185fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc945d13ce154c8894c295bf91ce66e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb9dca9af4154f24a7f53cf82bd307f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42f60fc7e63746238d27350b05d28be5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "960fb7fdadb84671ad4fb32439e3ff3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a32a87bdb964016985114bc30b59406",
              "IPY_MODEL_5a3d815de45445f7bf0441835b4ba74e",
              "IPY_MODEL_4743983a59af437c9c97590228ffd120"
            ],
            "layout": "IPY_MODEL_a9ab538466c24472b2048c73edc2357f"
          }
        },
        "0a32a87bdb964016985114bc30b59406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ec38ba5e009436abaaa5bdb6bba5b04",
            "placeholder": "​",
            "style": "IPY_MODEL_cfe42ededf0648a381a0c91685ffe0b1",
            "value": "MTGNN-semantic: 100%"
          }
        },
        "5a3d815de45445f7bf0441835b4ba74e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4c330934f4849ebb399316b357ddb0b",
            "max": 300,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2227d1580e7748978071cb83fa586cec",
            "value": 300
          }
        },
        "4743983a59af437c9c97590228ffd120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a7c9eb5da1646f2b7f4006e2696d23c",
            "placeholder": "​",
            "style": "IPY_MODEL_b9eaac4044c84470a9793c68babfac8b",
            "value": " 300/300 [00:26&lt;00:00,  6.61epoch/s, model=MTGNN, val_loss=0.5640]"
          }
        },
        "a9ab538466c24472b2048c73edc2357f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ec38ba5e009436abaaa5bdb6bba5b04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfe42ededf0648a381a0c91685ffe0b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4c330934f4849ebb399316b357ddb0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2227d1580e7748978071cb83fa586cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a7c9eb5da1646f2b7f4006e2696d23c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9eaac4044c84470a9793c68babfac8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "397998d761a645ffabb504d9d7183531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c41fd8e9bb4f45c8bd2145b6612f5bbb",
              "IPY_MODEL_f33a71aab77c470ab866fa7d1dfc6350",
              "IPY_MODEL_61e12e4cc34348609f1dd982a0e9fdbd"
            ],
            "layout": "IPY_MODEL_35bf5b09d747453bae968e0b607acdd7"
          }
        },
        "c41fd8e9bb4f45c8bd2145b6612f5bbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5111b963b30d474b8df9d195e41c924f",
            "placeholder": "​",
            "style": "IPY_MODEL_2bf4366bb4bd4ee39eda560b6af333c9",
            "value": "H=1 | GraphWaveNet | Trial 8/8:  98%"
          }
        },
        "f33a71aab77c470ab866fa7d1dfc6350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59e33131d1994dbdb807a53df409b466",
            "max": 360,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9eaa669ab1643fcbfb5b9ffd2f26375",
            "value": 352
          }
        },
        "61e12e4cc34348609f1dd982a0e9fdbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ae9d9d8ac2349c6837838dab21a5247",
            "placeholder": "​",
            "style": "IPY_MODEL_e32c47b1274a40f19e5a39188100629b",
            "value": " 352/360 [1:13:01&lt;00:28,  3.62s/epoch, mae=0.3663]"
          }
        },
        "35bf5b09d747453bae968e0b607acdd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5111b963b30d474b8df9d195e41c924f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bf4366bb4bd4ee39eda560b6af333c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59e33131d1994dbdb807a53df409b466": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9eaa669ab1643fcbfb5b9ffd2f26375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ae9d9d8ac2349c6837838dab21a5247": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e32c47b1274a40f19e5a39188100629b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9af5cc4c9ae4256aeb6c6a4bbea376a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4153808e8e1456bbc00dddcccb9d034",
              "IPY_MODEL_05c874e2286a425cac8e620b5864512e",
              "IPY_MODEL_bfef678ab65e4fdab6d39697d12b6853"
            ],
            "layout": "IPY_MODEL_dd215c916baf45a2b320ce417fda7b1e"
          }
        },
        "e4153808e8e1456bbc00dddcccb9d034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_007473e3684e4c61a12bfbd3a2b6eff6",
            "placeholder": "​",
            "style": "IPY_MODEL_27ba761443074c7f8f167ae032bb9ee9",
            "value": "Total Progress: 100%"
          }
        },
        "05c874e2286a425cac8e620b5864512e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e20f7afd156a4978851fd64c20f0840a",
            "max": 720,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c578e2850cde4f4cbb841fccd194808b",
            "value": 720
          }
        },
        "bfef678ab65e4fdab6d39697d12b6853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db8bcdb5044d46ecba54c8b5708e7ee7",
            "placeholder": "​",
            "style": "IPY_MODEL_f90c7d700cea403698ae9275edda5376",
            "value": " 720/720 [1:12:31&lt;00:00,  2.89s/epoch, model=GraphWaveNet, val_loss=0.4806]"
          }
        },
        "dd215c916baf45a2b320ce417fda7b1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "007473e3684e4c61a12bfbd3a2b6eff6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27ba761443074c7f8f167ae032bb9ee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e20f7afd156a4978851fd64c20f0840a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c578e2850cde4f4cbb841fccd194808b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db8bcdb5044d46ecba54c8b5708e7ee7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f90c7d700cea403698ae9275edda5376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
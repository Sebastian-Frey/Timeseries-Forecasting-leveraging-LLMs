{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPNSaKTwGnj2xtr1tL1beeb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sebastian-Frey/Timeseries-Forecasting-leveraging-LLMs/blob/main/6_Method3/chronos_geo_augmented_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data and model preparation"
      ],
      "metadata": {
        "id": "KtxoPrEXifjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from country_matcher import add_location_columns\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "df_parquet = pd.read_parquet(\"weekly_aggregated_by_week_keyword.parquet\")\n",
        "\n",
        "# normalize to lowercase for a safe match\n",
        "df_parquet[\"keyword\"] = df_parquet[\"keyword\"].astype(str).str.strip()\n",
        "excluded_set = {k.lower() for k in EXCLUDED_KEYWORDS}\n",
        "\n",
        "df_parquet = df_parquet[\n",
        "    ~df_parquet[\"keyword\"].str.lower().isin(excluded_set)\n",
        "].copy()\n",
        "\n",
        "# ============================\n",
        "# 1) CONVERT WEEK -> ISO DATE\n",
        "# ============================\n",
        "\n",
        "df_parquet[\"week\"] = df_parquet[\"week\"].astype(str).str.strip()\n",
        "\n",
        "# Convert \"WW-YYYY\" ‚Üí \"YYYYWW\"\n",
        "df_parquet[\"week_iso\"] = df_parquet[\"week\"].apply(\n",
        "    lambda w: w.split(\"-\")[1] + w.split(\"-\")[0]\n",
        ")\n",
        "\n",
        "# Fix week 00 if present\n",
        "df_parquet[\"week_iso\"] = df_parquet[\"week_iso\"].apply(\n",
        "    lambda w: w[:-2] + \"01\" if w.endswith(\"00\") else w\n",
        ")\n",
        "\n",
        "# Add Monday and parse to datetime\n",
        "df_parquet[\"week_str\"] = df_parquet[\"week_iso\"] + \"-1\"\n",
        "df_parquet[\"date\"] = pd.to_datetime(df_parquet[\"week_str\"], format=\"%G%V-%u\", errors=\"coerce\")\n",
        "\n",
        "df_parquet = df_parquet.dropna(subset=[\"date\"]).copy()\n",
        "\n",
        "# ============================\n",
        "# 2) AVERAGE DUPLICATES per (keyword, date)\n",
        "# ============================\n",
        "\n",
        "num_cols = df_parquet.select_dtypes(include=\"number\").columns.tolist()\n",
        "\n",
        "df_parquet = (\n",
        "    df_parquet.groupby([\"keyword\", \"date\"], as_index=False)[num_cols]\n",
        "      .mean()\n",
        ")\n",
        "\n",
        "# ============================\n",
        "# 3) GLOBAL TIME WINDOW\n",
        "# ============================\n",
        "\n",
        "global_min = df_parquet[\"date\"].min()\n",
        "global_max = df_parquet[\"date\"].max()\n",
        "\n",
        "full_idx = pd.date_range(start=global_min, end=global_max, freq=\"W-MON\")\n",
        "print(\"GLOBAL TIME WINDOW:\", global_min, \"‚Üí\", global_max)\n",
        "\n",
        "# ============================\n",
        "# 4) REINDEX EACH KEYWORD TO FULL WINDOW\n",
        "# ============================\n",
        "\n",
        "def reindex_one_keyword(g):\n",
        "    g = g.set_index(\"date\").reindex(full_idx)\n",
        "    g.index.name = \"date\"\n",
        "    g[\"keyword\"] = g[\"keyword\"].iloc[0]  # restore keyword column\n",
        "    return g.reset_index()\n",
        "\n",
        "df_parquet_full = (\n",
        "    df_parquet.groupby(\"keyword\", group_keys=False)\n",
        "      .apply(reindex_one_keyword)\n",
        "      .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "# ============================\n",
        "# 5) FILL NaNs USING KEYWORD MEAN\n",
        "# ============================\n",
        "\n",
        "for c in num_cols:\n",
        "    df_parquet_full[c] = df_parquet_full[c].fillna(\n",
        "        df_parquet_full.groupby(\"keyword\")[c].transform(\"mean\")\n",
        "    )\n",
        "\n",
        "print(\"FINAL SHAPE:\", df_parquet_full.shape)\n",
        "df_parquet_full.head()\n",
        "\n",
        "# ============================\n",
        "# 5b) ADD GEO COLUMNS WITH COUNTRY_MATCHER + PROGRESS BAR\n",
        "# ============================\n",
        "\n",
        "all_keywords = df_parquet_full[\"keyword\"].dropna().unique().tolist()\n",
        "total_kws = len(all_keywords)\n",
        "print(f\"Enriching {total_kws} keywords with geo info...\")\n",
        "\n",
        "pbar = tqdm(total=total_kws)\n",
        "\n",
        "def progress_cb(current, total):\n",
        "    # current and total come from add_location_columns\n",
        "    # we just sync them to the tqdm bar\n",
        "    pbar.n = current\n",
        "    pbar.refresh()\n",
        "\n",
        "df_parquet_full = add_location_columns(\n",
        "    df_parquet_full,\n",
        "    keywords=all_keywords,\n",
        "    progress_callback=progress_cb,\n",
        "    batch_size=10,   # callback every 10 keywords (tweak if you want)\n",
        ")\n",
        "\n",
        "pbar.close()\n",
        "\n",
        "print(\"\\nAdded geo columns:\")\n",
        "print(df_parquet_full[[\"keyword\", \"detected_city\", \"detected_country\", \"detected_continent\"]].head())\n",
        "\n",
        "# ============================\n",
        "# 5c) ENCODE GEO COLUMNS AS NUMERIC IDS\n",
        "# ============================\n",
        "\n",
        "city_values       = df_parquet_full[\"detected_city\"].dropna().unique()\n",
        "country_values    = df_parquet_full[\"detected_country\"].dropna().unique()\n",
        "continent_values  = df_parquet_full[\"detected_continent\"].dropna().unique()\n",
        "\n",
        "city_to_id = {name: i for i, name in enumerate(sorted(city_values), start=1)}\n",
        "country_to_id = {name: i for i, name in enumerate(sorted(country_values), start=1)}\n",
        "continent_to_id = {name: i for i, name in enumerate(sorted(continent_values), start=1)}\n",
        "\n",
        "df_parquet_full[\"detected_city_id\"] = (\n",
        "    df_parquet_full[\"detected_city\"].map(city_to_id).fillna(0).astype(\"int32\")\n",
        ")\n",
        "df_parquet_full[\"detected_country_id\"] = (\n",
        "    df_parquet_full[\"detected_country\"].map(country_to_id).fillna(0).astype(\"int32\")\n",
        ")\n",
        "df_parquet_full[\"detected_continent_id\"] = (\n",
        "    df_parquet_full[\"detected_continent\"].map(continent_to_id).fillna(0).astype(\"int32\")\n",
        ")\n",
        "\n",
        "print(\"\\nSample with string geo columns:\")\n",
        "print(\n",
        "    df_parquet_full[\n",
        "        [\"keyword\", \"detected_city\", \"detected_country\", \"detected_continent\"]\n",
        "    ].head().to_string(index=False)\n",
        ")\n",
        "\n",
        "print(\"\\nSample with numeric geo IDs:\")\n",
        "print(\n",
        "    df_parquet_full[\n",
        "        [\"keyword\", \"detected_city_id\", \"detected_country_id\", \"detected_continent_id\"]\n",
        "    ].head().to_string(index=False)\n",
        ")\n",
        "\n",
        "# ============================\n",
        "# 6) CLEAN NaN / EMPTY KEYWORDS BEFORE CHRONOS\n",
        "# ============================\n",
        "\n",
        "print(\"Rows in df_parquet_full BEFORE cleaning:\", len(df_parquet_full))\n",
        "print(\"NaN in keyword BEFORE:\", df_parquet_full[\"keyword\"].isna().sum())\n",
        "\n",
        "# 1) drop rows with keyword = NaN\n",
        "df_parquet_full = df_parquet_full[df_parquet_full[\"keyword\"].notna()].copy()\n",
        "\n",
        "# 2) drop rows with keyword = \"\" or only spaces\n",
        "df_parquet_full = df_parquet_full[\n",
        "    df_parquet_full[\"keyword\"].astype(str).str.strip() != \"\"\n",
        "].copy()\n",
        "\n",
        "# 3) (optional) make sure date and target are non-null too\n",
        "df_parquet_full = df_parquet_full[df_parquet_full[\"date\"].notna()].copy()\n",
        "df_parquet_full = df_parquet_full[df_parquet_full[\"cpc_week\"].notna()].copy()\n",
        "\n",
        "print(\"Rows in df_parquet_full AFTER cleaning:\", len(df_parquet_full))\n",
        "print(\"NaN in keyword AFTER:\", df_parquet_full[\"keyword\"].isna().sum())\n",
        "print(\"Distinct keywords AFTER:\", df_parquet_full[\"keyword\"].nunique())\n",
        "\n",
        "# ============================\n",
        "# 7) KEYWORD INSPECTION TOOL\n",
        "# ============================\n",
        "\n",
        "def inspect_keyword(keyword, plot_col=\"cpc_week\"):\n",
        "    df_parquet_k = df_parquet_full[df_parquet_full[\"keyword\"].str.lower() == keyword.lower()].copy()\n",
        "\n",
        "    if df_parquet_k.empty:\n",
        "        print(f\"Keyword not found: {keyword}\")\n",
        "        return df_parquet_k\n",
        "\n",
        "    print(\"\\n==============================\")\n",
        "    print(\"     INSPECTION:\", keyword)\n",
        "    print(\"==============================\")\n",
        "    print(\"Rows:\", len(df_parquet_k))\n",
        "    print(\"Date range:\", df_parquet_k[\"date\"].min(), \"‚Üí\", df_parquet_k[\"date\"].max())\n",
        "    print(\"\\nNulls per column:\")\n",
        "    print(df_parquet_k.isna().sum())\n",
        "\n",
        "    if plot_col in df_parquet_k.columns:\n",
        "        print(f\"\\nMean value used for '{plot_col}' imputation:\",\n",
        "              df_parquet_k[plot_col].mean())\n",
        "\n",
        "    print(\"\\nHEAD (first 10 rows):\")\n",
        "    print(df_parquet_k.head(10).to_string())\n",
        "\n",
        "    # plot\n",
        "    if plot_col in df_parquet_k.columns:\n",
        "        plt.figure(figsize=(12,4))\n",
        "        plt.plot(df_parquet_k[\"date\"], df_parquet_k[plot_col])\n",
        "        plt.title(f\"{keyword} ‚Äì {plot_col} over time\")\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    return df_parquet_k\n",
        "\n",
        "# ============================\n",
        "# 7) EXAMPLE\n",
        "# ============================\n",
        "\n",
        "inspect_keyword(\"24 hour rent\")\n"
      ],
      "metadata": {
        "id": "7myhSeodQpmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 7) PANEL FOR CHRONOS (ALL KEYWORDS)\n",
        "# ============================\n",
        "\n",
        "df_kw_loop = df_parquet_full.copy()\n",
        "\n",
        "print(\"Total rows in df_kw_loop (all keywords):\", len(df_kw_loop))\n",
        "print(\"Total distinct keywords:\", df_kw_loop[\"keyword\"].nunique())\n",
        "\n",
        "all_keywords_full = sorted(\n",
        "    df_kw_loop[\"keyword\"]\n",
        "    .astype(str)\n",
        "    .str.strip()\n",
        "    .unique()\n",
        ")\n",
        "print(f\"Total keywords in full panel: {len(all_keywords_full)}\")\n"
      ],
      "metadata": {
        "id": "9mmQpZ-bNpRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from chronos import Chronos2Pipeline\n",
        "\n",
        "device_map = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "pipeline = Chronos2Pipeline.from_pretrained(\n",
        "    \"s3://autogluon/chronos-2\",\n",
        "    device_map=device_map,\n",
        ")\n"
      ],
      "metadata": {
        "id": "tO85bByHOU1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the keywords to plot"
      ],
      "metadata": {
        "id": "K2ooR4EnjSJQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zero-shot model"
      ],
      "metadata": {
        "id": "erDfeEv7YjW9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Without geo-variables"
      ],
      "metadata": {
        "id": "_sznrj2F8xoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from chronos import Chronos2Pipeline\n",
        "\n",
        "# =========================================\n",
        "# 8) ZERO-SHOT BASELINE OVER MULTIPLE HORIZONS\n",
        "# =========================================\n",
        "\n",
        "ID_COL     = \"keyword\"\n",
        "TIME_COL   = \"date\"\n",
        "TARGET_COL = \"cpc_week\"\n",
        "\n",
        "PRED_LENGTHS = [1, 6, 12]\n",
        "metrics_zero_by_horizon = {}\n",
        "\n",
        "# ---- PLOT CONFIG (you will fill KEYWORDS_TO_PLOT later) ----\n",
        "N_PLOT_DEFAULT   = 3\n",
        "RANDOM_SEED      = 42\n",
        "\n",
        "def get_keywords_to_plot(all_keywords, keywords_to_plot=None, n_plot_default=3, seed=42):\n",
        "    all_keywords = [str(k).strip() for k in all_keywords if pd.notna(k)]\n",
        "    all_set = {k.lower() for k in all_keywords}\n",
        "\n",
        "    # user-provided list\n",
        "    if keywords_to_plot is not None and len(keywords_to_plot) > 0:\n",
        "        chosen, missing = [], []\n",
        "        for k in keywords_to_plot:\n",
        "            kk = str(k).strip()\n",
        "            if kk.lower() in all_set:\n",
        "                chosen.append(kk)\n",
        "            else:\n",
        "                missing.append(kk)\n",
        "\n",
        "        if missing:\n",
        "            print(\"‚ö†Ô∏è Requested plot keywords not found in test-set keywords (skipped):\")\n",
        "            for m in missing:\n",
        "                print(\" -\", m)\n",
        "\n",
        "        return chosen\n",
        "\n",
        "    # fallback random sample\n",
        "    if len(all_keywords) == 0:\n",
        "        return []\n",
        "\n",
        "    np.random.seed(seed)\n",
        "    n_plot = min(n_plot_default, len(all_keywords))\n",
        "    return list(np.random.choice(all_keywords, size=n_plot, replace=False))\n",
        "\n",
        "\n",
        "for PRED_LEN in PRED_LENGTHS:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"üîµ ZERO-SHOT CHRONOS-2 ‚Äì PREDICTION HORIZON = {PRED_LEN} weeks\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # ============================\n",
        "    # 9) GLOBAL TRAIN / TEST SPLIT\n",
        "    # ============================\n",
        "\n",
        "    max_date  = df_kw_loop[TIME_COL].max()\n",
        "    train_end = max_date - pd.Timedelta(weeks=PRED_LEN)\n",
        "\n",
        "    train_panel = df_kw_loop[df_kw_loop[TIME_COL] <= train_end].copy()\n",
        "    test_panel  = df_kw_loop[df_kw_loop[TIME_COL] >  train_end].copy()\n",
        "\n",
        "    # üëá EXCLUDE GEO VARIABLES ONLY IN THIS ZERO-SHOT SETUP\n",
        "    cols_to_drop = [\n",
        "        \"detected_city_id\",\n",
        "        \"detected_country_id\",\n",
        "        \"detected_continent_id\",\n",
        "    ]\n",
        "\n",
        "    train_panel = train_panel.drop(columns=cols_to_drop, errors=\"ignore\")\n",
        "    test_panel  = test_panel.drop(columns=cols_to_drop, errors=\"ignore\")\n",
        "\n",
        "    # ensure keyword is consistently string (prevents sorted/type issues)\n",
        "    train_panel[ID_COL] = train_panel[ID_COL].astype(str).str.strip()\n",
        "    test_panel[ID_COL]  = test_panel[ID_COL].astype(str).str.strip()\n",
        "\n",
        "    print(\"Train range:\", train_panel[TIME_COL].min(), \"‚Üí\", train_panel[TIME_COL].max())\n",
        "    print(\"Test  range:\",  test_panel[TIME_COL].min(),  \"‚Üí\", test_panel[TIME_COL].max())\n",
        "\n",
        "    # ============================\n",
        "    # 10) ZERO-SHOT FORECAST WITH BASE MODEL\n",
        "    # ============================\n",
        "\n",
        "    pred_df_zero = pipeline.predict_df(\n",
        "        train_panel,\n",
        "        prediction_length=PRED_LEN,\n",
        "        quantile_levels=[0.1, 0.5, 0.9],\n",
        "        id_column=ID_COL,\n",
        "        timestamp_column=TIME_COL,\n",
        "        target=TARGET_COL,\n",
        "    )\n",
        "\n",
        "    # Keep only forecast horizon\n",
        "    pred_df_zero = pred_df_zero[pred_df_zero[TIME_COL] > train_end].copy()\n",
        "\n",
        "    print(\"Zero-shot prediction sample:\")\n",
        "    print(pred_df_zero.head().to_string(index=False))\n",
        "\n",
        "    # ============================\n",
        "    # 11) METRICS PER KEYWORD (ZERO-SHOT)\n",
        "    #     (computed over ALL keywords that appear in the test set)\n",
        "    # ============================\n",
        "\n",
        "    all_keywords = (\n",
        "        test_panel[ID_COL]\n",
        "        .dropna()\n",
        "        .astype(str)\n",
        "        .str.strip()\n",
        "        .unique()\n",
        "        .tolist()\n",
        "    )\n",
        "\n",
        "    records = []\n",
        "\n",
        "    for kw in all_keywords:\n",
        "        # actuals in test period\n",
        "        test_kw = test_panel[test_panel[ID_COL].str.lower() == kw.lower()].copy()\n",
        "        if test_kw.empty:\n",
        "            continue\n",
        "\n",
        "        # predictions for this keyword\n",
        "        pred_kw = pred_df_zero[pred_df_zero[ID_COL].str.lower() == kw.lower()].copy()\n",
        "        pred_kw = pred_kw.sort_values(TIME_COL)\n",
        "\n",
        "        # align by date\n",
        "        merged = test_kw[[TIME_COL, TARGET_COL]].merge(\n",
        "            pred_kw[[TIME_COL, \"0.5\"]],\n",
        "            on=TIME_COL,\n",
        "            how=\"inner\",\n",
        "        )\n",
        "\n",
        "        if merged.empty:\n",
        "            continue\n",
        "\n",
        "        y_true = merged[TARGET_COL].values\n",
        "        y_pred = merged[\"0.5\"].values\n",
        "\n",
        "        # MAE\n",
        "        mae  = np.mean(np.abs(y_true - y_pred))\n",
        "\n",
        "        # MAPE (as fraction, not %)\n",
        "        denom = np.where(y_true == 0, 1e-6, y_true)\n",
        "        mape = np.mean(np.abs((y_true - y_pred) / denom))\n",
        "\n",
        "        # sMAPE (also as fraction, not %)\n",
        "        denom_smape = np.abs(y_true) + np.abs(y_pred)\n",
        "        denom_smape = np.where(denom_smape == 0, 1e-6, denom_smape)\n",
        "        smape = np.mean(2.0 * np.abs(y_true - y_pred) / denom_smape)\n",
        "\n",
        "        # RMSE\n",
        "        rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
        "\n",
        "        records.append({\n",
        "            \"keyword\": kw,\n",
        "            \"mae\": mae,\n",
        "            \"mape\": mape,\n",
        "            \"smape\": smape,\n",
        "            \"rmse\": rmse,\n",
        "        })\n",
        "\n",
        "\n",
        "    metrics_zero = pd.DataFrame(records).sort_values(\"mae\").reset_index(drop=True)\n",
        "    metrics_zero_by_horizon[PRED_LEN] = metrics_zero\n",
        "\n",
        "    print(f\"\\n=== ZERO-SHOT MODEL ‚Äì METRICS PER KEYWORD (horizon={PRED_LEN}) ===\")\n",
        "    print(metrics_zero.head(20).to_string(index=False))\n",
        "\n",
        "    # === ZERO-SHOT MODEL ‚Äì AGGREGATED METRICS (MEAN ¬± STD) ===\n",
        "\n",
        "    mean_smape_zero = metrics_zero[\"smape\"].mean()\n",
        "    std_smape_zero  = metrics_zero[\"smape\"].std()\n",
        "\n",
        "    mean_rmse_zero = metrics_zero[\"rmse\"].mean()\n",
        "    std_rmse_zero  = metrics_zero[\"rmse\"].std()\n",
        "\n",
        "    print(f\"\\n=== ZERO-SHOT MODEL ‚Äì AGGREGATED METRICS (horizon={PRED_LEN}) ===\")\n",
        "    print(f\"sMAPE (mean ¬± std) : {mean_smape_zero:.4f} ¬± {std_smape_zero:.4f}\")\n",
        "    print(f\"RMSE  (mean ¬± std) : {mean_rmse_zero:.4f} ¬± {std_rmse_zero:.4f}\")\n",
        "\n",
        "    # ============================\n",
        "    # 12) PLOT FUNCTION FOR ZERO-SHOT MODEL (THIS HORIZON)\n",
        "    # ============================\n",
        "\n",
        "    def plot_zero_shot_forecast(keyword):\n",
        "        test_kw = test_panel[test_panel[ID_COL].str.lower() == keyword.lower()].copy()\n",
        "        if test_kw.empty:\n",
        "            print(f\"No test data for keyword: {keyword}\")\n",
        "            return\n",
        "\n",
        "        kw_all = df_kw_loop[df_kw_loop[ID_COL].str.lower() == keyword.lower()].copy()\n",
        "        kw_all = kw_all.sort_values(TIME_COL)\n",
        "\n",
        "        pred_kw = pred_df_zero[pred_df_zero[ID_COL].str.lower() == keyword.lower()].copy()\n",
        "        pred_kw = pred_kw.sort_values(TIME_COL)\n",
        "\n",
        "        if pred_kw.empty:\n",
        "            print(f\"No predictions for keyword: {keyword}\")\n",
        "            return\n",
        "\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        # full actual history\n",
        "        plt.plot(\n",
        "            kw_all[TIME_COL],\n",
        "            kw_all[TARGET_COL],\n",
        "            \"o-\",\n",
        "            color=\"black\",\n",
        "            markersize=3,\n",
        "            linewidth=1,\n",
        "            label=\"Actual (full history)\",\n",
        "        )\n",
        "\n",
        "        # forecast median\n",
        "        plt.plot(\n",
        "            pred_kw[TIME_COL],\n",
        "            pred_kw[\"0.5\"],\n",
        "            \"s--\",\n",
        "            color=\"blue\",\n",
        "            linewidth=1.8,\n",
        "            markersize=5,\n",
        "            label=f\"Zero-shot forecast (median, horizon={PRED_LEN})\",\n",
        "        )\n",
        "\n",
        "        # prediction interval\n",
        "        plt.fill_between(\n",
        "            pred_kw[TIME_COL],\n",
        "            pred_kw[\"0.1\"],\n",
        "            pred_kw[\"0.9\"],\n",
        "            alpha=0.25,\n",
        "            label=\"P10‚ÄìP90 interval\",\n",
        "        )\n",
        "\n",
        "        # test actuals\n",
        "        plt.scatter(\n",
        "            test_kw[TIME_COL],\n",
        "            test_kw[TARGET_COL],\n",
        "            color=\"red\",\n",
        "            marker=\"D\",\n",
        "            s=50,\n",
        "            label=\"Test set (actual)\",\n",
        "            zorder=5,\n",
        "        )\n",
        "\n",
        "        # train/test split\n",
        "        plt.axvline(\n",
        "            train_end,\n",
        "            linestyle=\"--\",\n",
        "            color=\"gray\",\n",
        "            alpha=0.7,\n",
        "            label=\"Train/Test split\",\n",
        "        )\n",
        "\n",
        "        plt.title(f\"Zero-shot no geo-variables | {keyword} (horizon={PRED_LEN})\", fontsize=14)\n",
        "        plt.xlabel(\"Week\", fontsize=11)\n",
        "        plt.ylabel(\"Average CPC\", fontsize=11)\n",
        "        plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
        "        plt.legend(fontsize=9)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # ============================\n",
        "    # 13) PLOT SELECTED (OR RANDOM) KEYWORDS FOR THIS HORIZON\n",
        "    # ============================\n",
        "\n",
        "    keywords_to_plot = get_keywords_to_plot(\n",
        "        all_keywords=all_keywords,\n",
        "        keywords_to_plot=KEYWORDS_TO_PLOT,   # <-- you'll set later\n",
        "        n_plot_default=N_PLOT_DEFAULT,\n",
        "        seed=RANDOM_SEED\n",
        "    )\n",
        "\n",
        "    print(f\"\\nPlotting {len(keywords_to_plot)} keywords (zero-shot, horizon={PRED_LEN}):\")\n",
        "    for kw in keywords_to_plot:\n",
        "        print(\" -\", kw)\n",
        "        plot_zero_shot_forecast(kw)\n"
      ],
      "metadata": {
        "id": "EIKIVD4i80bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With geo-variables"
      ],
      "metadata": {
        "id": "BHICIM1R8uqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from chronos import Chronos2Pipeline\n",
        "\n",
        "# =========================================\n",
        "# 8) ZERO-SHOT BASELINE OVER MULTIPLE HORIZONS\n",
        "# =========================================\n",
        "\n",
        "ID_COL     = \"keyword\"\n",
        "TIME_COL   = \"date\"\n",
        "TARGET_COL = \"cpc_week\"\n",
        "\n",
        "PRED_LENGTHS = [1, 6, 12]\n",
        "metrics_zero_by_horizon = {}\n",
        "\n",
        "def get_keywords_to_plot(all_keywords, keywords_to_plot=None, n_plot_default=3, seed=42):\n",
        "    all_keywords = [str(k).strip() for k in all_keywords if pd.notna(k)]\n",
        "    all_set = {k.lower() for k in all_keywords}\n",
        "\n",
        "    # user list\n",
        "    if keywords_to_plot is not None and len(keywords_to_plot) > 0:\n",
        "        chosen, missing = [], []\n",
        "        for k in keywords_to_plot:\n",
        "            kk = str(k).strip()\n",
        "            if kk.lower() in all_set:\n",
        "                chosen.append(kk)\n",
        "            else:\n",
        "                missing.append(kk)\n",
        "\n",
        "        if missing:\n",
        "            print(\"‚ö†Ô∏è Plot keywords NOT found in this horizon test-set keyword list (skipped):\")\n",
        "            for m in missing:\n",
        "                print(\" -\", m)\n",
        "\n",
        "        return chosen\n",
        "\n",
        "    # fallback random\n",
        "    if len(all_keywords) == 0:\n",
        "        return []\n",
        "\n",
        "    np.random.seed(seed)\n",
        "    n_plot = min(n_plot_default, len(all_keywords))\n",
        "    return list(np.random.choice(all_keywords, size=n_plot, replace=False))\n",
        "\n",
        "\n",
        "for PRED_LEN in PRED_LENGTHS:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"üîµ ZERO-SHOT CHRONOS-2 ‚Äì PREDICTION HORIZON = {PRED_LEN} weeks\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # ============================\n",
        "    # 9) GLOBAL TRAIN / TEST SPLIT\n",
        "    # ============================\n",
        "\n",
        "    max_date  = df_kw_loop[TIME_COL].max()\n",
        "    train_end = max_date - pd.Timedelta(weeks=PRED_LEN)\n",
        "\n",
        "    train_panel = df_kw_loop[df_kw_loop[TIME_COL] <= train_end].copy()\n",
        "    test_panel  = df_kw_loop[df_kw_loop[TIME_COL] >  train_end].copy()\n",
        "\n",
        "    # üëá EXCLUDE GEO VARIABLES ONLY IN THIS ZERO-SHOT SETUP (if you want)\n",
        "    cols_to_drop = []\n",
        "    train_panel = train_panel.drop(columns=cols_to_drop, errors=\"ignore\")\n",
        "    test_panel  = test_panel.drop(columns=cols_to_drop, errors=\"ignore\")\n",
        "\n",
        "    # ensure keyword is clean string (prevents float vs str issues)\n",
        "    train_panel[ID_COL] = train_panel[ID_COL].astype(str).str.strip()\n",
        "    test_panel[ID_COL]  = test_panel[ID_COL].astype(str).str.strip()\n",
        "\n",
        "    print(\"Train range:\", train_panel[TIME_COL].min(), \"‚Üí\", train_panel[TIME_COL].max())\n",
        "    print(\"Test  range:\",  test_panel[TIME_COL].min(),  \"‚Üí\", test_panel[TIME_COL].max())\n",
        "\n",
        "    # ============================\n",
        "    # 10) ZERO-SHOT FORECAST WITH BASE MODEL\n",
        "    # ============================\n",
        "\n",
        "    pred_df_zero = pipeline.predict_df(\n",
        "        train_panel,\n",
        "        prediction_length=PRED_LEN,\n",
        "        quantile_levels=[0.1, 0.5, 0.9],\n",
        "        id_column=ID_COL,\n",
        "        timestamp_column=TIME_COL,\n",
        "        target=TARGET_COL,\n",
        "    )\n",
        "\n",
        "    # Keep only forecast horizon\n",
        "    pred_df_zero = pred_df_zero[pred_df_zero[TIME_COL] > train_end].copy()\n",
        "\n",
        "    print(\"Zero-shot prediction sample:\")\n",
        "    print(pred_df_zero.head().to_string(index=False))\n",
        "\n",
        "    # ============================\n",
        "    # 11) METRICS PER KEYWORD (ZERO-SHOT)\n",
        "    #    computed over ALL keywords that appear in THIS test_panel\n",
        "    # ============================\n",
        "\n",
        "    all_keywords = (\n",
        "        test_panel[ID_COL]\n",
        "        .dropna()\n",
        "        .astype(str)\n",
        "        .str.strip()\n",
        "        .unique()\n",
        "        .tolist()\n",
        "    )\n",
        "\n",
        "    records = []\n",
        "\n",
        "    for kw in all_keywords:\n",
        "        # actuals in test period\n",
        "        test_kw = test_panel[test_panel[ID_COL].str.lower() == kw.lower()].copy()\n",
        "        if test_kw.empty:\n",
        "            continue\n",
        "\n",
        "        # predictions for this keyword\n",
        "        pred_kw = pred_df_zero[pred_df_zero[ID_COL].str.lower() == kw.lower()].copy()\n",
        "        pred_kw = pred_kw.sort_values(TIME_COL)\n",
        "\n",
        "        # align by date\n",
        "        merged = test_kw[[TIME_COL, TARGET_COL]].merge(\n",
        "            pred_kw[[TIME_COL, \"0.5\"]],\n",
        "            on=TIME_COL,\n",
        "            how=\"inner\",\n",
        "        )\n",
        "\n",
        "        if merged.empty:\n",
        "            continue\n",
        "\n",
        "        y_true = merged[TARGET_COL].values\n",
        "        y_pred = merged[\"0.5\"].values\n",
        "\n",
        "        mae  = np.mean(np.abs(y_true - y_pred))\n",
        "\n",
        "        denom = np.where(y_true == 0, 1e-6, y_true)\n",
        "        mape = np.mean(np.abs((y_true - y_pred) / denom))\n",
        "\n",
        "        denom_smape = np.abs(y_true) + np.abs(y_pred)\n",
        "        denom_smape = np.where(denom_smape == 0, 1e-6, denom_smape)\n",
        "        smape = np.mean(2.0 * np.abs(y_true - y_pred) / denom_smape)\n",
        "\n",
        "        rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
        "\n",
        "        records.append({\n",
        "            \"keyword\": kw,\n",
        "            \"mae\": mae,\n",
        "            \"mape\": mape,\n",
        "            \"smape\": smape,\n",
        "            \"rmse\": rmse,\n",
        "        })\n",
        "\n",
        "    metrics_zero = pd.DataFrame(records).sort_values(\"mae\").reset_index(drop=True)\n",
        "    metrics_zero_by_horizon[PRED_LEN] = metrics_zero\n",
        "\n",
        "    mean_smape = metrics_zero[\"smape\"].mean()\n",
        "    std_smape  = metrics_zero[\"smape\"].std()\n",
        "    mean_rmse  = metrics_zero[\"rmse\"].mean()\n",
        "    std_rmse   = metrics_zero[\"rmse\"].std()\n",
        "\n",
        "    print(f\"\\n=== ZERO-SHOT ‚Äì AGGREGATED METRICS (horizon={PRED_LEN}) ===\")\n",
        "    print(f\"sMAPE (mean ¬± std) : {mean_smape:.4f} ¬± {std_smape:.4f}\")\n",
        "    print(f\"RMSE  (mean ¬± std) : {mean_rmse:.4f} ¬± {std_rmse:.4f}\")\n",
        "\n",
        "    # ============================\n",
        "    # 12) PLOT FUNCTION FOR ZERO-SHOT MODEL (THIS HORIZON)\n",
        "    # ============================\n",
        "\n",
        "    def plot_zero_shot_forecast(keyword):\n",
        "        test_kw = test_panel[test_panel[ID_COL].str.lower() == keyword.lower()].copy()\n",
        "        if test_kw.empty:\n",
        "            print(f\"‚ö†Ô∏è No test data for keyword (h={PRED_LEN}): {keyword}\")\n",
        "            return\n",
        "\n",
        "        kw_all = df_kw_loop[df_kw_loop[ID_COL].str.lower() == keyword.lower()].copy().sort_values(TIME_COL)\n",
        "\n",
        "        pred_kw = pred_df_zero[pred_df_zero[ID_COL].str.lower() == keyword.lower()].copy().sort_values(TIME_COL)\n",
        "        if pred_kw.empty:\n",
        "            print(f\"‚ö†Ô∏è No predictions for keyword (h={PRED_LEN}): {keyword}\")\n",
        "            return\n",
        "\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.plot(\n",
        "            kw_all[TIME_COL],\n",
        "            kw_all[TARGET_COL],\n",
        "            \"o-\",\n",
        "            color=\"black\",\n",
        "            markersize=3,\n",
        "            linewidth=1,\n",
        "            label=\"Actual (full history)\",\n",
        "        )\n",
        "\n",
        "        plt.plot(\n",
        "            pred_kw[TIME_COL],\n",
        "            pred_kw[\"0.5\"],\n",
        "            \"s--\",\n",
        "            color=\"blue\",\n",
        "            linewidth=1.8,\n",
        "            markersize=5,\n",
        "            label=f\"Zero-shot forecast (median, horizon={PRED_LEN})\",\n",
        "        )\n",
        "\n",
        "        plt.fill_between(\n",
        "            pred_kw[TIME_COL],\n",
        "            pred_kw[\"0.1\"],\n",
        "            pred_kw[\"0.9\"],\n",
        "            alpha=0.25,\n",
        "            label=\"P10‚ÄìP90 interval\",\n",
        "        )\n",
        "\n",
        "        plt.scatter(\n",
        "            test_kw[TIME_COL],\n",
        "            test_kw[TARGET_COL],\n",
        "            color=\"red\",\n",
        "            marker=\"D\",\n",
        "            s=50,\n",
        "            label=\"Test set (actual)\",\n",
        "            zorder=5,\n",
        "        )\n",
        "\n",
        "        plt.axvline(\n",
        "            train_end,\n",
        "            linestyle=\"--\",\n",
        "            color=\"gray\",\n",
        "            alpha=0.7,\n",
        "            label=\"Train/Test split\",\n",
        "        )\n",
        "\n",
        "        plt.title(f\"Chronos-2 Zero-shot with geo-variables | {keyword} (horizon={PRED_LEN})\", fontsize=14)\n",
        "        plt.xlabel(\"Week\", fontsize=11)\n",
        "        plt.ylabel(\"Average CPC\", fontsize=11)\n",
        "        plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
        "        plt.legend(fontsize=9)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # ============================\n",
        "    # 13) PLOT YOUR SELECTED KEYWORDS (OR RANDOM FALLBACK)\n",
        "    # ============================\n",
        "\n",
        "    keywords_to_plot = get_keywords_to_plot(\n",
        "        all_keywords=all_keywords,          # use test-set keywords for this horizon\n",
        "        keywords_to_plot=KEYWORDS_TO_PLOT,  # <-- your list\n",
        "        n_plot_default=N_PLOT_DEFAULT,\n",
        "        seed=RANDOM_SEED,\n",
        "    )\n",
        "\n",
        "    print(f\"\\nPlotting {len(keywords_to_plot)} keywords (zero-shot, horizon={PRED_LEN}):\")\n",
        "    for kw in keywords_to_plot:\n",
        "        print(\" -\", kw)\n",
        "        plot_zero_shot_forecast(kw)\n"
      ],
      "metadata": {
        "id": "NmZGS8YkYm6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With covariates model"
      ],
      "metadata": {
        "id": "nb7rBTA5i0mk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Without geo-variables"
      ],
      "metadata": {
        "id": "HwFp80dUsbt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from chronos import Chronos2Pipeline\n",
        "\n",
        "ID_COL     = \"keyword\"\n",
        "TIME_COL   = \"date\"\n",
        "TARGET_COL = \"cpc_week\"\n",
        "\n",
        "# horizons you want to test\n",
        "PRED_LENGTHS = [1, 6, 12]\n",
        "\n",
        "# Option B: keep a default random sample size (used if KEYWORDS_TO_PLOT is None)\n",
        "N_PLOT_DEFAULT = 3\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "# to store metrics per horizon if you want later comparisons\n",
        "metrics_by_horizon = {}\n",
        "\n",
        "def get_keywords_to_plot(all_keywords, keywords_to_plot=None, n_plot_default=3, seed=42):\n",
        "    all_keywords = [str(k).strip() for k in all_keywords if pd.notna(k)]\n",
        "    all_set = {k.lower() for k in all_keywords}\n",
        "\n",
        "    if keywords_to_plot is not None and len(keywords_to_plot) > 0:\n",
        "        chosen, missing = [], []\n",
        "        for k in keywords_to_plot:\n",
        "            kk = str(k).strip()\n",
        "            if kk.lower() in all_set:\n",
        "                chosen.append(kk)\n",
        "            else:\n",
        "                missing.append(kk)\n",
        "\n",
        "        if missing:\n",
        "            print(\"‚ö†Ô∏è Plot keywords NOT found in this horizon test-set keyword list (skipped):\")\n",
        "            for m in missing:\n",
        "                print(\" -\", m)\n",
        "\n",
        "        return chosen\n",
        "\n",
        "    if len(all_keywords) == 0:\n",
        "        return []\n",
        "\n",
        "    np.random.seed(seed)\n",
        "    n_plot = min(n_plot_default, len(all_keywords))\n",
        "    return list(np.random.choice(all_keywords, size=n_plot, replace=False))\n",
        "\n",
        "\n",
        "for PRED_LEN in PRED_LENGTHS:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"üîÆ GLOBAL MODEL ‚Äì PREDICTION HORIZON = {PRED_LEN} weeks\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # ============================\n",
        "    # 9) GLOBAL TRAIN / TEST SPLIT\n",
        "    # ============================\n",
        "    max_date  = df_kw_loop[TIME_COL].max()\n",
        "    train_end = max_date - pd.Timedelta(weeks=PRED_LEN)\n",
        "\n",
        "    train_panel = df_kw_loop[df_kw_loop[TIME_COL] <= train_end].copy()\n",
        "    test_panel  = df_kw_loop[df_kw_loop[TIME_COL] >  train_end].copy()\n",
        "\n",
        "    # ensure keyword is clean string (prevents float vs str issues)\n",
        "    train_panel[ID_COL] = train_panel[ID_COL].astype(str).str.strip()\n",
        "    test_panel[ID_COL]  = test_panel[ID_COL].astype(str).str.strip()\n",
        "\n",
        "    print(\"Train range:\", train_panel[TIME_COL].min(), \"‚Üí\", train_panel[TIME_COL].max())\n",
        "    print(\"Test  range:\",  test_panel[TIME_COL].min(),  \"‚Üí\", test_panel[TIME_COL].max())\n",
        "\n",
        "    # ============================\n",
        "    # 10) BUILD GLOBAL TRAIN INPUTS (NUMERIC COVARIATES)\n",
        "    # ============================\n",
        "    covariate_cols = [\n",
        "        \"impressions_sum\",\n",
        "        \"n_st_branded_search\",\n",
        "        \"n_st_generic_search\",\n",
        "        \"n_dev_desktop\",\n",
        "        \"n_dev_mobile\",\n",
        "        \"n_dev_tablet\",\n",
        "        \"adclicks_sum\",\n",
        "        \"avg_sim_top25_this_week\",\n",
        "        \"avg_sim_top25_last_week\",\n",
        "        \"n_sim_this_week\",\n",
        "        \"n_sim_last_week\",\n",
        "        \"detected_city\",\n",
        "        \"detected_country\",\n",
        "        \"detected_continent\"\n",
        "    ]\n",
        "\n",
        "\n",
        "    inputs = []\n",
        "\n",
        "    for kw, g in train_panel.groupby(ID_COL):\n",
        "        g = g.sort_values(TIME_COL)\n",
        "\n",
        "        # ensure enough history\n",
        "        if len(g) < PRED_LEN + 10:\n",
        "            continue\n",
        "\n",
        "        series = {\n",
        "            \"target\": g[TARGET_COL].values.astype(\"float32\"),\n",
        "            \"past_covariates\": {},\n",
        "            \"future_covariates\": {},\n",
        "        }\n",
        "\n",
        "        for col in covariate_cols:\n",
        "            if col in g.columns and np.issubdtype(g[col].dtype, np.number):\n",
        "                series[\"past_covariates\"][col] = g[col].values.astype(\"float32\")\n",
        "\n",
        "        inputs.append(series)\n",
        "\n",
        "    print(f\"Prepared {len(inputs)} series for global training (horizon={PRED_LEN}).\")\n",
        "\n",
        "    if not inputs:\n",
        "        print(\"‚ùå No series available for training at this horizon. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    # ============================\n",
        "    # 11) GLOBAL FINE-TUNING\n",
        "    # ============================\n",
        "    finetuned_global = pipeline.fit(\n",
        "        inputs=inputs,\n",
        "        prediction_length=PRED_LEN,\n",
        "        num_steps=50,\n",
        "        learning_rate=1e-5,\n",
        "        batch_size=32,\n",
        "        logging_steps=10,\n",
        "    )\n",
        "\n",
        "    # ============================\n",
        "    # 12) GLOBAL FORECAST + METRICS PER KEYWORD\n",
        "    # ============================\n",
        "\n",
        "    pred_df = finetuned_global.predict_df(\n",
        "        train_panel,\n",
        "        prediction_length=PRED_LEN,\n",
        "        quantile_levels=[0.1, 0.5, 0.9],\n",
        "        id_column=ID_COL,\n",
        "        timestamp_column=TIME_COL,\n",
        "        target=TARGET_COL,\n",
        "    )\n",
        "\n",
        "    pred_df = pred_df[pred_df[TIME_COL] > train_end].copy()\n",
        "\n",
        "    print(\"Prediction sample:\")\n",
        "    print(pred_df.head().to_string(index=False))\n",
        "\n",
        "    # keywords to evaluate = all keywords that appear in THIS horizon test set\n",
        "    all_keywords_h = (\n",
        "        test_panel[ID_COL]\n",
        "        .dropna()\n",
        "        .astype(str)\n",
        "        .str.strip()\n",
        "        .unique()\n",
        "        .tolist()\n",
        "    )\n",
        "\n",
        "    records = []\n",
        "\n",
        "    for kw in all_keywords_h:\n",
        "        test_kw = test_panel[test_panel[ID_COL].str.lower() == kw.lower()].copy()\n",
        "        if test_kw.empty:\n",
        "            continue\n",
        "\n",
        "        pred_kw = pred_df[pred_df[ID_COL].str.lower() == kw.lower()].copy().sort_values(TIME_COL)\n",
        "\n",
        "        merged = test_kw[[TIME_COL, TARGET_COL]].merge(\n",
        "            pred_kw[[TIME_COL, \"0.5\"]],\n",
        "            on=TIME_COL,\n",
        "            how=\"inner\",\n",
        "        )\n",
        "        if merged.empty:\n",
        "            continue\n",
        "\n",
        "        y_true = merged[TARGET_COL].values\n",
        "        y_pred = merged[\"0.5\"].values\n",
        "\n",
        "        mae  = np.mean(np.abs(y_true - y_pred))\n",
        "\n",
        "        denom = np.where(y_true == 0, 1e-6, y_true)\n",
        "        mape = np.mean(np.abs((y_true - y_pred) / denom))\n",
        "\n",
        "        denom_smape = np.abs(y_true) + np.abs(y_pred)\n",
        "        denom_smape = np.where(denom_smape == 0, 1e-6, denom_smape)\n",
        "        smape = np.mean(2.0 * np.abs(y_true - y_pred) / denom_smape)\n",
        "\n",
        "        rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
        "\n",
        "        records.append({\"keyword\": kw, \"mae\": mae, \"mape\": mape, \"smape\": smape, \"rmse\": rmse})\n",
        "\n",
        "    metrics_global = pd.DataFrame(records).sort_values(\"mae\").reset_index(drop=True)\n",
        "    metrics_by_horizon[PRED_LEN] = metrics_global\n",
        "\n",
        "    print(f\"\\n=== GLOBAL MODEL ‚Äì METRICS PER KEYWORD (horizon={PRED_LEN}) ===\")\n",
        "    print(metrics_global.head(20).to_string(index=False))\n",
        "\n",
        "    mean_smape = metrics_global[\"smape\"].mean()\n",
        "    std_smape  = metrics_global[\"smape\"].std()\n",
        "    mean_rmse  = metrics_global[\"rmse\"].mean()\n",
        "    std_rmse   = metrics_global[\"rmse\"].std()\n",
        "\n",
        "    print(f\"\\n=== GLOBAL MODEL ‚Äì AGGREGATED METRICS (horizon={PRED_LEN}) ===\")\n",
        "    print(f\"sMAPE (mean ¬± std) : {mean_smape:.4f} ¬± {std_smape:.4f}\")\n",
        "    print(f\"RMSE  (mean ¬± std) : {mean_rmse:.4f} ¬± {std_rmse:.4f}\")\n",
        "\n",
        "    # ============================\n",
        "    # 13) PLOT FUNCTION\n",
        "    # ============================\n",
        "    def plot_global_forecast(keyword):\n",
        "        test_kw = test_panel[test_panel[ID_COL].str.lower() == keyword.lower()].copy()\n",
        "        if test_kw.empty:\n",
        "            print(f\"‚ö†Ô∏è No test data for keyword (h={PRED_LEN}): {keyword}\")\n",
        "            return\n",
        "\n",
        "        kw_all = df_kw_loop[df_kw_loop[ID_COL].str.lower() == keyword.lower()].copy().sort_values(TIME_COL)\n",
        "\n",
        "        pred_kw = pred_df[pred_df[ID_COL].str.lower() == keyword.lower()].copy().sort_values(TIME_COL)\n",
        "        if pred_kw.empty:\n",
        "            print(f\"‚ö†Ô∏è No predictions for keyword (h={PRED_LEN}): {keyword}\")\n",
        "            return\n",
        "\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.plot(\n",
        "            kw_all[TIME_COL],\n",
        "            kw_all[TARGET_COL],\n",
        "            \"o-\",\n",
        "            color=\"black\",\n",
        "            markersize=3,\n",
        "            linewidth=1,\n",
        "            label=\"Actual (full history)\",\n",
        "        )\n",
        "\n",
        "        plt.plot(\n",
        "            pred_kw[TIME_COL],\n",
        "            pred_kw[\"0.5\"],\n",
        "            \"s--\",\n",
        "            color=\"purple\",\n",
        "            linewidth=1.8,\n",
        "            markersize=5,\n",
        "            label=\"Forecast (median)\",\n",
        "        )\n",
        "\n",
        "        plt.fill_between(\n",
        "            pred_kw[TIME_COL],\n",
        "            pred_kw[\"0.1\"],\n",
        "            pred_kw[\"0.9\"],\n",
        "            color=\"purple\",\n",
        "            alpha=0.25,\n",
        "            label=\"P10‚ÄìP90 interval\",\n",
        "        )\n",
        "\n",
        "        plt.scatter(\n",
        "            test_kw[TIME_COL],\n",
        "            test_kw[TARGET_COL],\n",
        "            color=\"red\",\n",
        "            marker=\"D\",\n",
        "            s=50,\n",
        "            label=\"Test set (actual)\",\n",
        "            zorder=5,\n",
        "        )\n",
        "\n",
        "        plt.axvline(\n",
        "            train_end,\n",
        "            linestyle=\"--\",\n",
        "            color=\"gray\",\n",
        "            alpha=0.7,\n",
        "            label=\"Train/Test split\",\n",
        "        )\n",
        "\n",
        "        plt.title(f\"Global Fine-Tuned Model without geo-variables | {keyword} (horizon={PRED_LEN})\", fontsize=14)\n",
        "        plt.xlabel(\"Week\", fontsize=11)\n",
        "        plt.ylabel(\"Average CPC\", fontsize=11)\n",
        "        plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
        "        plt.legend(fontsize=9)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # ============================\n",
        "    # 14) PLOT YOUR SELECTED KEYWORDS (OR RANDOM FALLBACK)\n",
        "    # ============================\n",
        "    keywords_to_plot = get_keywords_to_plot(\n",
        "        all_keywords=all_keywords_h,         # test-set keywords for this horizon\n",
        "        keywords_to_plot=KEYWORDS_TO_PLOT,   # <-- your list\n",
        "        n_plot_default=N_PLOT_DEFAULT,\n",
        "        seed=RANDOM_SEED,\n",
        "    )\n",
        "\n",
        "    print(f\"\\nPlotting {len(keywords_to_plot)} keywords (global, horizon={PRED_LEN}):\")\n",
        "    for kw in keywords_to_plot:\n",
        "        print(\" -\", kw)\n",
        "        plot_global_forecast(kw)\n"
      ],
      "metadata": {
        "id": "1l5pzBrQqYQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With geo-variables"
      ],
      "metadata": {
        "id": "6FsH-ZTWsi1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from chronos import Chronos2Pipeline\n",
        "\n",
        "# Option B: keep a default random sample size (used if KEYWORDS_TO_PLOT is None)\n",
        "N_PLOT_DEFAULT = 3\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "ID_COL     = \"keyword\"\n",
        "TIME_COL   = \"date\"\n",
        "TARGET_COL = \"cpc_week\"\n",
        "\n",
        "# horizons you want to test\n",
        "PRED_LENGTHS = [1, 6, 12]\n",
        "\n",
        "# to store metrics per horizon if you want later comparisons\n",
        "metrics_by_horizon = {}\n",
        "\n",
        "def get_keywords_to_plot(all_keywords, keywords_to_plot=None, n_plot_default=3, seed=42):\n",
        "    all_keywords = [str(k).strip() for k in all_keywords if pd.notna(k)]\n",
        "    all_set = {k.lower() for k in all_keywords}\n",
        "\n",
        "    if keywords_to_plot is not None and len(keywords_to_plot) > 0:\n",
        "        chosen, missing = [], []\n",
        "        for k in keywords_to_plot:\n",
        "            kk = str(k).strip()\n",
        "            if kk.lower() in all_set:\n",
        "                chosen.append(kk)\n",
        "            else:\n",
        "                missing.append(kk)\n",
        "\n",
        "        if missing:\n",
        "            print(\"‚ö†Ô∏è Plot keywords NOT found in this horizon test-set keyword list (skipped):\")\n",
        "            for m in missing:\n",
        "                print(\" -\", m)\n",
        "\n",
        "        return chosen\n",
        "\n",
        "    if len(all_keywords) == 0:\n",
        "        return []\n",
        "\n",
        "    np.random.seed(seed)\n",
        "    n_plot = min(n_plot_default, len(all_keywords))\n",
        "    return list(np.random.choice(all_keywords, size=n_plot, replace=False))\n",
        "\n",
        "\n",
        "for PRED_LEN in PRED_LENGTHS:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"üîÆ GLOBAL MODEL ‚Äì PREDICTION HORIZON = {PRED_LEN} weeks\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # ============================\n",
        "    # 9) GLOBAL TRAIN / TEST SPLIT\n",
        "    # ============================\n",
        "    max_date  = df_kw_loop[TIME_COL].max()\n",
        "    train_end = max_date - pd.Timedelta(weeks=PRED_LEN)\n",
        "\n",
        "    train_panel = df_kw_loop[df_kw_loop[TIME_COL] <= train_end].copy()\n",
        "    test_panel  = df_kw_loop[df_kw_loop[TIME_COL] >  train_end].copy()\n",
        "\n",
        "    # ensure keyword is clean string (prevents float vs str issues)\n",
        "    train_panel[ID_COL] = train_panel[ID_COL].astype(str).str.strip()\n",
        "    test_panel[ID_COL]  = test_panel[ID_COL].astype(str).str.strip()\n",
        "\n",
        "    print(\"Train range:\", train_panel[TIME_COL].min(), \"‚Üí\", train_panel[TIME_COL].max())\n",
        "    print(\"Test  range:\",  test_panel[TIME_COL].min(),  \"‚Üí\", test_panel[TIME_COL].max())\n",
        "\n",
        "    # ============================\n",
        "    # 10) BUILD GLOBAL TRAIN INPUTS (NUMERIC COVARIATES)\n",
        "    # ============================\n",
        "    covariate_cols = [\n",
        "        \"impressions_sum\",\n",
        "        \"n_st_branded_search\",\n",
        "        \"n_st_generic_search\",\n",
        "        \"n_dev_desktop\",\n",
        "        \"n_dev_mobile\",\n",
        "        \"n_dev_tablet\",\n",
        "        \"adclicks_sum\",\n",
        "        \"avg_sim_top25_this_week\",\n",
        "        \"avg_sim_top25_last_week\",\n",
        "        \"n_sim_this_week\",\n",
        "        \"n_sim_last_week\",\n",
        "        \"detected_city_id\",\n",
        "        \"detected_country_id\",\n",
        "        \"detected_continent_id\"\n",
        "    ]\n",
        "\n",
        "\n",
        "    inputs = []\n",
        "\n",
        "    for kw, g in train_panel.groupby(ID_COL):\n",
        "        g = g.sort_values(TIME_COL)\n",
        "\n",
        "        # ensure enough history\n",
        "        if len(g) < PRED_LEN + 10:\n",
        "            continue\n",
        "\n",
        "        series = {\n",
        "            \"target\": g[TARGET_COL].values.astype(\"float32\"),\n",
        "            \"past_covariates\": {},\n",
        "            \"future_covariates\": {},\n",
        "        }\n",
        "\n",
        "        for col in covariate_cols:\n",
        "            if col in g.columns and np.issubdtype(g[col].dtype, np.number):\n",
        "                series[\"past_covariates\"][col] = g[col].values.astype(\"float32\")\n",
        "\n",
        "        inputs.append(series)\n",
        "\n",
        "    print(f\"Prepared {len(inputs)} series for global training (horizon={PRED_LEN}).\")\n",
        "\n",
        "    if not inputs:\n",
        "        print(\"‚ùå No series available for training at this horizon. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    # ============================\n",
        "    # 11) GLOBAL FINE-TUNING\n",
        "    # ============================\n",
        "    finetuned_global = pipeline.fit(\n",
        "        inputs=inputs,\n",
        "        prediction_length=PRED_LEN,\n",
        "        num_steps=50,\n",
        "        learning_rate=1e-5,\n",
        "        batch_size=32,\n",
        "        logging_steps=10,\n",
        "    )\n",
        "\n",
        "    # ============================\n",
        "    # 12) GLOBAL FORECAST + METRICS PER KEYWORD\n",
        "    # ============================\n",
        "\n",
        "    pred_df = finetuned_global.predict_df(\n",
        "        train_panel,\n",
        "        prediction_length=PRED_LEN,\n",
        "        quantile_levels=[0.1, 0.5, 0.9],\n",
        "        id_column=ID_COL,\n",
        "        timestamp_column=TIME_COL,\n",
        "        target=TARGET_COL,\n",
        "    )\n",
        "\n",
        "    pred_df = pred_df[pred_df[TIME_COL] > train_end].copy()\n",
        "\n",
        "    print(\"Prediction sample:\")\n",
        "    print(pred_df.head().to_string(index=False))\n",
        "\n",
        "    # keywords to evaluate = all keywords that appear in THIS horizon test set\n",
        "    all_keywords_h = (\n",
        "        test_panel[ID_COL]\n",
        "        .dropna()\n",
        "        .astype(str)\n",
        "        .str.strip()\n",
        "        .unique()\n",
        "        .tolist()\n",
        "    )\n",
        "\n",
        "    records = []\n",
        "\n",
        "    for kw in all_keywords_h:\n",
        "        test_kw = test_panel[test_panel[ID_COL].str.lower() == kw.lower()].copy()\n",
        "        if test_kw.empty:\n",
        "            continue\n",
        "\n",
        "        pred_kw = pred_df[pred_df[ID_COL].str.lower() == kw.lower()].copy().sort_values(TIME_COL)\n",
        "\n",
        "        merged = test_kw[[TIME_COL, TARGET_COL]].merge(\n",
        "            pred_kw[[TIME_COL, \"0.5\"]],\n",
        "            on=TIME_COL,\n",
        "            how=\"inner\",\n",
        "        )\n",
        "        if merged.empty:\n",
        "            continue\n",
        "\n",
        "        y_true = merged[TARGET_COL].values\n",
        "        y_pred = merged[\"0.5\"].values\n",
        "\n",
        "        mae  = np.mean(np.abs(y_true - y_pred))\n",
        "\n",
        "        denom = np.where(y_true == 0, 1e-6, y_true)\n",
        "        mape = np.mean(np.abs((y_true - y_pred) / denom))\n",
        "\n",
        "        denom_smape = np.abs(y_true) + np.abs(y_pred)\n",
        "        denom_smape = np.where(denom_smape == 0, 1e-6, denom_smape)\n",
        "        smape = np.mean(2.0 * np.abs(y_true - y_pred) / denom_smape)\n",
        "\n",
        "        rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
        "\n",
        "        records.append({\"keyword\": kw, \"mae\": mae, \"mape\": mape, \"smape\": smape, \"rmse\": rmse})\n",
        "\n",
        "    metrics_global = pd.DataFrame(records).sort_values(\"mae\").reset_index(drop=True)\n",
        "    metrics_by_horizon[PRED_LEN] = metrics_global\n",
        "\n",
        "    print(f\"\\n=== GLOBAL MODEL ‚Äì METRICS PER KEYWORD (horizon={PRED_LEN}) ===\")\n",
        "    print(metrics_global.head(20).to_string(index=False))\n",
        "\n",
        "    mean_smape = metrics_global[\"smape\"].mean()\n",
        "    std_smape  = metrics_global[\"smape\"].std()\n",
        "    mean_rmse  = metrics_global[\"rmse\"].mean()\n",
        "    std_rmse   = metrics_global[\"rmse\"].std()\n",
        "\n",
        "    print(f\"\\n=== GLOBAL MODEL ‚Äì AGGREGATED METRICS (horizon={PRED_LEN}) ===\")\n",
        "    print(f\"sMAPE (mean ¬± std) : {mean_smape:.4f} ¬± {std_smape:.4f}\")\n",
        "    print(f\"RMSE  (mean ¬± std) : {mean_rmse:.4f} ¬± {std_rmse:.4f}\")\n",
        "\n",
        "    # ============================\n",
        "    # 13) PLOT FUNCTION\n",
        "    # ============================\n",
        "    def plot_global_forecast(keyword):\n",
        "        test_kw = test_panel[test_panel[ID_COL].str.lower() == keyword.lower()].copy()\n",
        "        if test_kw.empty:\n",
        "            print(f\"‚ö†Ô∏è No test data for keyword (h={PRED_LEN}): {keyword}\")\n",
        "            return\n",
        "\n",
        "        kw_all = df_kw_loop[df_kw_loop[ID_COL].str.lower() == keyword.lower()].copy().sort_values(TIME_COL)\n",
        "\n",
        "        pred_kw = pred_df[pred_df[ID_COL].str.lower() == keyword.lower()].copy().sort_values(TIME_COL)\n",
        "        if pred_kw.empty:\n",
        "            print(f\"‚ö†Ô∏è No predictions for keyword (h={PRED_LEN}): {keyword}\")\n",
        "            return\n",
        "\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.plot(\n",
        "            kw_all[TIME_COL],\n",
        "            kw_all[TARGET_COL],\n",
        "            \"o-\",\n",
        "            color=\"black\",\n",
        "            markersize=3,\n",
        "            linewidth=1,\n",
        "            label=\"Actual (full history)\",\n",
        "        )\n",
        "\n",
        "        plt.plot(\n",
        "            pred_kw[TIME_COL],\n",
        "            pred_kw[\"0.5\"],\n",
        "            \"s--\",\n",
        "            color=\"purple\",\n",
        "            linewidth=1.8,\n",
        "            markersize=5,\n",
        "            label=\"Forecast (median)\",\n",
        "        )\n",
        "\n",
        "        plt.fill_between(\n",
        "            pred_kw[TIME_COL],\n",
        "            pred_kw[\"0.1\"],\n",
        "            pred_kw[\"0.9\"],\n",
        "            color=\"purple\",\n",
        "            alpha=0.25,\n",
        "            label=\"P10‚ÄìP90 interval\",\n",
        "        )\n",
        "\n",
        "        plt.scatter(\n",
        "            test_kw[TIME_COL],\n",
        "            test_kw[TARGET_COL],\n",
        "            color=\"red\",\n",
        "            marker=\"D\",\n",
        "            s=50,\n",
        "            label=\"Test set (actual)\",\n",
        "            zorder=5,\n",
        "        )\n",
        "\n",
        "        plt.axvline(\n",
        "            train_end,\n",
        "            linestyle=\"--\",\n",
        "            color=\"gray\",\n",
        "            alpha=0.7,\n",
        "            label=\"Train/Test split\",\n",
        "        )\n",
        "\n",
        "        plt.title(f\"Global Fine-Tuned Model with geo-variables | {keyword} (horizon={PRED_LEN})\", fontsize=14)\n",
        "        plt.xlabel(\"Week\", fontsize=11)\n",
        "        plt.ylabel(\"Average CPC\", fontsize=11)\n",
        "        plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
        "        plt.legend(fontsize=9)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # ============================\n",
        "    # 14) PLOT YOUR SELECTED KEYWORDS (OR RANDOM FALLBACK)\n",
        "    # ============================\n",
        "    all_keywords_full = (\n",
        "    df_kw_loop[ID_COL].dropna().astype(str).str.strip().unique().tolist())\n",
        "\n",
        "    keywords_to_plot = get_keywords_to_plot(\n",
        "        all_keywords=all_keywords_full,         # ‚úÖ match against full dataset\n",
        "        keywords_to_plot=KEYWORDS_TO_PLOT,      # ‚úÖ your list\n",
        "        n_plot_default=N_PLOT_DEFAULT,\n",
        "        seed=RANDOM_SEED,\n",
        "    )\n",
        "\n",
        "\n",
        "    print(f\"\\nPlotting {len(keywords_to_plot)} keywords (global, horizon={PRED_LEN}):\")\n",
        "    for kw in keywords_to_plot:\n",
        "        print(\" -\", kw)\n",
        "        plot_global_forecast(kw)\n"
      ],
      "metadata": {
        "id": "wQalhhlc0mhl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
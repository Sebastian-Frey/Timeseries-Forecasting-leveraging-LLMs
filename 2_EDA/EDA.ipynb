{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPjeSabHU2ZEwFFxu4oW2Yd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sebastian-Frey/Timeseries-Forecasting-leveraging-LLMs/blob/main/2_EDA/EDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global EDA"
      ],
      "metadata": {
        "id": "FFl-hdVU88Uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import skew\n",
        "\n",
        "vars_to_summarize = [\"cpc_week\", \"impressions_sum\", \"adclicks_sum\", \"adcost_sum\",\n",
        "    \"n_dev_desktop\", \"n_dev_mobile\", \"n_dev_tablet\",\n",
        "    \"avg_sim_top25_this_week\", \"avg_sim_top25_last_week\",\n",
        "    \"n_st_branded_search\", \"n_st_generic_search\",\n",
        "]\n",
        "\n",
        "rows = []\n",
        "\n",
        "for col in vars_to_summarize:\n",
        "    x = df_parquet[col].dropna()\n",
        "\n",
        "    p01 = x.quantile(0.01)\n",
        "    p25 = x.quantile(0.25)\n",
        "    p75 = x.quantile(0.75)\n",
        "    p99 = x.quantile(0.99)\n",
        "\n",
        "    rows.append({\n",
        "        \"variable\": col,\n",
        "        \"mean\": x.mean(),\n",
        "        \"median\": x.median(),\n",
        "        \"std\": x.std(),\n",
        "        \"min\": x.min(),\n",
        "        \"max\": x.max(),\n",
        "        \"skew\": skew(x),\n",
        "        \"p01\": p01,\n",
        "        \"p25\": p25,\n",
        "        \"p75\": p75,\n",
        "        \"p99\": p99,\n",
        "        \"coef_var\": x.std() / x.mean()\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(rows).round(4)\n",
        "summary_df\n"
      ],
      "metadata": {
        "id": "FQEQxuXO2c7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def trimmed_boxplot(df, col, ax, title_suffix=\"— Boxplot\"):\n",
        "    \"\"\"\n",
        "    Boxplot with grid + robust trimming.\n",
        "    If the variable has very few distinct values (e.g. 0,1,2) we skip trimming.\n",
        "    \"\"\"\n",
        "    data = df[col].dropna()\n",
        "\n",
        "    if data.nunique() > 5:\n",
        "        q1, q3 = data.quantile([0.25, 0.75])\n",
        "        iqr = q3 - q1\n",
        "        low = q1 - 1.5 * iqr\n",
        "        high = q3 + 1.5 * iqr\n",
        "        data = data[(data >= low) & (data <= high)]\n",
        "\n",
        "    sns.boxplot(x=data, ax=ax, color=\"steelblue\")\n",
        "    ax.set_title(f\"{col} {title_suffix}\")\n",
        "    ax.set_xlabel(col)\n",
        "    ax.grid(True, axis=\"x\", linestyle=\"--\", alpha=0.4)  # grid inside boxplot"
      ],
      "metadata": {
        "id": "M0LwMnfbgYhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ensure week is datetime\n",
        "df_parquet[\"week\"] = pd.to_datetime(df_parquet[\"week\"])\n",
        "\n",
        "# 1. Min and max dates\n",
        "min_date = df_parquet[\"week\"].min()\n",
        "max_date = df_parquet[\"week\"].max()\n",
        "\n",
        "# 2. All weeks that SHOULD exist in the time range\n",
        "all_weeks = pd.date_range(start=min_date, end=max_date, freq=\"W-MON\")\n",
        "\n",
        "# 3. Weeks that DO exist in the dataset\n",
        "existing_weeks = df_parquet[\"week\"].unique()\n",
        "\n",
        "# 4. Missing weeks\n",
        "missing_weeks = sorted(set(all_weeks) - set(existing_weeks))\n",
        "n_missing = len(missing_weeks)\n",
        "\n",
        "# 5. Pretty printing\n",
        "print(\"============ DATASET TEMPORAL SUMMARY ============\")\n",
        "print(f\"• Earliest week:           {min_date.date()}\")\n",
        "print(f\"• Latest week:             {max_date.date()}\")\n",
        "print(f\"• Total weeks in range:    {len(all_weeks)}\")\n",
        "print(f\"• Weeks present in data:   {len(existing_weeks)}\")\n",
        "print(f\"• Missing (empty) weeks:   {n_missing}\")\n",
        "print(f\"• Missing weeks (%):       {100 * n_missing / len(all_weeks):.2f}%\")\n",
        "print(\"===================================================\")\n",
        "\n",
        "# If you want to print the list of missing weeks:\n",
        "# for w in missing_weeks: print(w.date())\n"
      ],
      "metadata": {
        "id": "QiCSAiT1z7GA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ========= GROUP 1 – cpc_week, impressions_sum, adclicks_sum, adcost_sum =========\n",
        "cols1 = [\"cpc_week\", \"impressions_sum\", \"adclicks_sum\", \"adcost_sum\"]\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
        "axes = axes.flatten()  # <--- flatten 2x2 array into 1D list of Axes\n",
        "\n",
        "for col, ax in zip(cols1, axes):\n",
        "    trimmed_boxplot(df_parquet, col, ax)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "E-FYsrCPjxYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device_weekly = df_parquet.groupby(\"week_dt\")[[\n",
        "    \"n_dev_desktop\", \"n_dev_mobile\", \"n_dev_tablet\"\n",
        "]].sum()\n",
        "\n",
        "device_share_weekly = device_weekly.div(device_weekly.sum(axis=1), axis=0)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "device_share_weekly.plot(ax=plt.gca())\n",
        "\n",
        "plt.title(\"Weekly Device Share Over Time\")\n",
        "plt.ylabel(\"Share\")\n",
        "plt.xlabel(\"Week\")\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uEbrqzJszhl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "vars_outliers = [\"cpc_week\", \"adcost_sum\", \"impressions_sum\", \"adclicks_sum\"]\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for col, ax in zip(vars_outliers, axes):\n",
        "    x = df_parquet[col]\n",
        "    z = (x - x.mean()) / x.std()\n",
        "\n",
        "    sns.stripplot(\n",
        "        x=x,\n",
        "        hue=z > 3,        # highlight extreme outliers (Z > 3)\n",
        "        palette=[\"steelblue\", \"red\"],\n",
        "        ax=ax,\n",
        "        alpha=0.5,\n",
        "        jitter=0.3,\n",
        "        size=3\n",
        "    )\n",
        "\n",
        "    ax.set_title(f\"Outlier Strip Plot: {col}\", fontsize=12)\n",
        "    ax.set_xlabel(col)\n",
        "    ax.set_ylabel(\"\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qOAmN7LhlKYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_parquet[[\"impressions_sum\",\"adclicks_sum\",\"adcost_sum\",\"cpc_week\"]].describe(percentiles=[0.9, 0.95, 0.99])\n"
      ],
      "metadata": {
        "id": "ETSMROkolymr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ===== 1. SELECT ONLY NUMERICAL COLUMNS =====\n",
        "num_df = df_parquet.select_dtypes(include=[np.number])\n",
        "\n",
        "# ===== 2. COMPUTE CORRELATION MATRIX =====\n",
        "corr = num_df.corr()\n",
        "\n",
        "# ===== 3. CREATE MASK FOR LOWER TRIANGLE =====\n",
        "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "\n",
        "# ===== 4. PLOT (LIKE THE EXAMPLE) =====\n",
        "plt.figure(figsize=(12, 10))\n",
        "\n",
        "sns.heatmap(\n",
        "    corr,\n",
        "    mask=mask,\n",
        "    annot=True,\n",
        "    fmt=\".2f\",\n",
        "    cmap=\"viridis\",\n",
        "    linewidths=0.5,\n",
        "    cbar_kws={\"shrink\": 0.8},\n",
        "    square=True\n",
        ")\n",
        "\n",
        "plt.title(\"Correlation Matrix of Numerical Features\", fontsize=16)\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JMSrWcSkdPPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA aggregated per keyword"
      ],
      "metadata": {
        "id": "nb7rBTA5i0mk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Variables\n",
        "num_vars = [\n",
        "    \"cpc_week\", \"impressions_sum\", \"adclicks_sum\", \"adcost_sum\",\n",
        "    \"n_dev_desktop\", \"n_dev_mobile\", \"n_dev_tablet\",\n",
        "    \"avg_sim_top25_this_week\", \"avg_sim_top25_last_week\",\n",
        "    \"n_st_branded_search\", \"n_st_generic_search\"\n",
        "]\n",
        "\n",
        "# Keyword-level mean and std\n",
        "kw_means = df_parquet.groupby(\"keyword\")[num_vars].mean()\n",
        "kw_stds  = df_parquet.groupby(\"keyword\")[num_vars].std()\n",
        "\n",
        "# Keyword-level coef_var\n",
        "kw_cv = kw_stds / kw_means.replace(0, np.nan)\n",
        "\n",
        "# Build the insightful table\n",
        "insight_table = pd.DataFrame({\n",
        "    \"mean_of_means\": kw_means.mean(),\n",
        "    \"std_of_means\": kw_means.std(),\n",
        "    \"mean_of_coef_var\": kw_cv.mean(),\n",
        "    \"std_of_coef_var\": kw_cv.std()\n",
        "}).round(4)\n",
        "\n",
        "insight_table\n"
      ],
      "metadata": {
        "id": "bntWKoM4QblA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ===== 1. CONVERT WEEK STRING TO REAL DATETIME =====\n",
        "# week format is \"WW-YYYY\" → convert to \"YYYY-WW-1\" meaning Monday of that ISO week\n",
        "df_parquet[\"week_str\"] = df_parquet[\"week\"].apply(lambda w: f\"{w.split('-')[1]}-W{w.split('-')[0]}-1\")\n",
        "df_parquet[\"week_dt\"] = pd.to_datetime(df_parquet[\"week_str\"], format=\"%G-W%V-%u\")\n",
        "\n",
        "# ===== 2. COUNT ROWS PER WEEK IN CHRONO ORDER =====\n",
        "week_counts = (\n",
        "    df_parquet.groupby(\"week_dt\")\n",
        "              .size()\n",
        "              .reset_index(name=\"n_keywords\")\n",
        "              .sort_values(\"week_dt\")\n",
        ")\n",
        "\n",
        "# ===== 3. CLEAN LINE PLOT WITH FEWER X-TICKS =====\n",
        "plt.figure(figsize=(14,5))\n",
        "sns.lineplot(\n",
        "    data=week_counts,\n",
        "    x=\"week_dt\",\n",
        "    y=\"n_keywords\",\n",
        "    marker=\"o\"\n",
        ")\n",
        "\n",
        "plt.title(\"Number of Keywords per Week\", fontsize=14)\n",
        "plt.xlabel(\"Week\")\n",
        "plt.ylabel(\"Count\")\n",
        "\n",
        "# Show only every 6th week label (or adjust as needed)\n",
        "plt.xticks(week_counts[\"week_dt\"][::6], rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PyPA29-TfEZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_calendar = df_parquet.groupby(\"week_dt\").size().reset_index(name=\"count\")\n",
        "df_calendar[\"year\"] = df_calendar[\"week_dt\"].dt.year\n",
        "df_calendar[\"week\"] = df_calendar[\"week_dt\"].dt.isocalendar().week\n",
        "\n",
        "pivot_cal = df_calendar.pivot(index=\"week\", columns=\"year\", values=\"count\")\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(pivot_cal, cmap=\"Blues\", linewidths=0.3)\n",
        "\n",
        "plt.title(\"Calendar Heatmap of Dataset Availability (Observations per Week)\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"ISO Week Number\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4Hmn4SLJzjij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ===== RECOMPUTE EVERYTHING =====\n",
        "\n",
        "# 1. Count number of weeks per keyword\n",
        "keyword_lengths = (\n",
        "    df_parquet.groupby(\"keyword\")[\"week_dt\"]\n",
        "              .nunique()\n",
        "              .reset_index(name=\"n_weeks\")\n",
        ")\n",
        "\n",
        "# 2. Count how many keywords have each series length\n",
        "length_distribution = (\n",
        "    keyword_lengths.groupby(\"n_weeks\")\n",
        "                   .size()\n",
        "                   .reset_index(name=\"n_keywords\")\n",
        "                   .sort_values(\"n_weeks\", ascending=False)\n",
        ")\n",
        "\n",
        "# ===== 3. PLOT WITH GRID + LABELS =====\n",
        "plt.figure(figsize=(12,6))\n",
        "\n",
        "ax = sns.barplot(\n",
        "    data=length_distribution,\n",
        "    x=\"n_weeks\",\n",
        "    y=\"n_keywords\",\n",
        "    color=\"steelblue\"\n",
        ")\n",
        "\n",
        "# Add labels on bars\n",
        "for p in ax.patches:\n",
        "    height = p.get_height()\n",
        "    ax.annotate(\n",
        "        f'{int(height)}',\n",
        "        (p.get_x() + p.get_width() / 2, height),\n",
        "        ha='center', va='bottom', fontsize=9\n",
        "    )\n",
        "\n",
        "# Add grid (y-axis for readability)\n",
        "ax.yaxis.grid(True, linestyle='--', alpha=0.4)\n",
        "ax.set_axisbelow(True)\n",
        "\n",
        "plt.title(\"Distribution of Time-Series Lengths (Weeks per Keyword)\")\n",
        "plt.xlabel(\"Number of Weeks in Time Series\")\n",
        "plt.ylabel(\"Number of Keywords\")\n",
        "plt.xticks(rotation=90)\n",
        "pl\n"
      ],
      "metadata": {
        "id": "gngvsOrdfFcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 2) Plot: Volatility vs Mean WITH LINES\n",
        "# ============================\n",
        "\n",
        "var = \"cpc_week\"   # <-- change here to plot another variable\n",
        "\n",
        "x_vals = keyword_means[var]\n",
        "y_vals = keyword_coef_var[var]\n",
        "\n",
        "# Reference lines\n",
        "x_ref = x_vals.median()   # or x_vals.mean()\n",
        "y_ref = y_vals.median()   # or y_vals.mean()\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "\n",
        "sns.scatterplot(\n",
        "    x=x_vals,\n",
        "    y=y_vals,\n",
        "    alpha=0.4,\n",
        "    s=22,\n",
        "    color=\"steelblue\"\n",
        ")\n",
        "\n",
        "# Add vertical quadrant line\n",
        "plt.axvline(x=x_ref, color=\"darkred\", linestyle=\"--\", linewidth=1.2, label=f\"Median mean = {x_ref:.2f}\")\n",
        "\n",
        "# Add horizontal quadrant line\n",
        "plt.axhline(y=y_ref, color=\"darkgreen\", linestyle=\"--\", linewidth=1.2, label=f\"Median CV = {y_ref:.2f}\")\n",
        "\n",
        "plt.xlabel(f\"{var} – Keyword Mean\")\n",
        "plt.ylabel(f\"{var} – Keyword Coef. Var (Volatility)\")\n",
        "plt.title(f\"Keyword Heterogeneity: Mean vs Volatility ({var})\")\n",
        "\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5QkvhA6prTCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Compute keyword-level mean CPC\n",
        "cpc_keyword_mean = keyword_means[\"cpc_week\"]\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(\n",
        "    cpc_keyword_mean,\n",
        "    bins=40,\n",
        "    kde=True,\n",
        "    color=\"steelblue\"\n",
        ")\n",
        "\n",
        "plt.title(\"Distribution of Mean CPC Across Keywords\")\n",
        "plt.xlabel(\"Mean CPC per Keyword\")\n",
        "plt.ylabel(\"Number of Keywords\")\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "a7v3CBZ5vyCP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}